prompt_template: "Given this AI generated output:\n'{context}'\nPerform an analysis and respond with enough detail for me to implement the same logic, do not repeat the code in the response, and include your reasoning step by step. \n### Instruction:\n {query}\n### Response:"
inference_model:
  model_import_path: "ctransformers.AutoModelForCausalLM"
  model_inference_function: "from_pretrained"
  model_params:
    model_path: "./models/wizardcoder-python-13b-v1.0.Q4_0.gguf"
    model_type: "llama"
    local_files_only: true
    #model_path: "TheBloke/WizardCoder-Guanaco-15B-V1.1-GGML"
    #model_type: "gpt_bigcode"
    #local_files_only: false
    #model_path: "TheBloke/Starcoderplus-Guanaco-GPT4-15B-V1.0-GGML"
    #model_type: "gpt_bigcode"
    #local_files_only: false
    #model_path: "TheBloke/Octocoder-GGML"
    #model_type: "gpt_bigcode"
    #local_files_only: false  

    ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)
    #avx2 and gpu_layers are not compatible 
    #lib: "avx2"
    threads: 28
    batch_size: 128 
    context_length: 16000
    max_new_tokens: 8092
    gpu_layers: 100
    reset: true