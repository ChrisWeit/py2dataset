[
    {
        "instruction": "What are the dependencies of the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport yaml\nimport importlib\nfrom typing import Dict, List \nfrom pathlib import Path\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"What are the dependencies of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"internal_code_graph\",\n            \"text\": \"What is the call code graph of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"What functions are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },      \n        {\n            \"id\": \"file_classes\",\n            \"text\": \"What classes are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        }, \n        {\n            \"id\": \"function_returns\",\n            \"text\": \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {   \n            \"id\": \"file_purpose\",\n            \"text\": \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible \n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 8400,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except: # get default questions if can't read questions_pathname file \n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\": \n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else: \n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")    \n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return instantiate_model(model_config['inference_model']), model_config['prompt_template']\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "json, pathlib, importlib, os, logging, typing, yaml"
    },
    {
        "instruction": "What is the call code graph of the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport yaml\nimport importlib\nfrom typing import Dict, List \nfrom pathlib import Path\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"What are the dependencies of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"internal_code_graph\",\n            \"text\": \"What is the call code graph of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"What functions are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },      \n        {\n            \"id\": \"file_classes\",\n            \"text\": \"What classes are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        }, \n        {\n            \"id\": \"function_returns\",\n            \"text\": \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {   \n            \"id\": \"file_purpose\",\n            \"text\": \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible \n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 8400,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except: # get default questions if can't read questions_pathname file \n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\": \n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else: \n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")    \n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return instantiate_model(model_config['inference_model']), model_config['prompt_template']\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "{'nodes': ['get_default_questions', 'get_default_model_config', 'get_output_dir', 'get_questions', 'instantiate_model', 'get_model', 'write_questions_file', 'write_model_config_file', 'os.path.abspath', 'os.makedirs', 'logging.info', 'os.path.join', 'os.getcwd', 'open', 'json.load', \"model_config['model_import_path'].rsplit\", 'getattr', 'importlib.import_module', 'inference_function', 'model_params.pop', 'ModelClass', 'yaml.safe_load', 'Path(output_dir).is_dir', 'Path', 'json.dump', 'yaml.dump'], 'edges': [{'source': 'get_output_dir', 'target': 'os.path.abspath', 'target_inputs': ['output_dir or OUTPUT_DIR']}, {'source': 'get_output_dir', 'target': 'os.makedirs', 'target_inputs': ['output_dir']}, {'source': 'get_output_dir', 'target': 'logging.info', 'target_inputs': [\"f'Using output directory: {output_dir}'\"]}, {'source': 'get_questions', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'QUESTIONS_FILE']}, {'source': 'get_questions', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_questions', 'target': 'open', 'target_inputs': ['questions_pathname', \"'r'\"]}, {'source': 'get_questions', 'target': 'json.load', 'target_inputs': ['f']}, {'source': 'get_questions', 'target': 'logging.info', 'target_inputs': [\"f'Questions file not valid: {questions_pathname} Using default questions'\"]}, {'source': 'get_questions', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'instantiate_model', 'target': \"model_config['model_import_path'].rsplit\", 'target_inputs': [\"'.'\", '1']}, {'source': 'instantiate_model', 'target': 'getattr', 'target_inputs': ['ModelClass', 'inference_function_name']}, {'source': 'instantiate_model', 'target': 'importlib.import_module', 'target_inputs': ['module_name']}, {'source': 'instantiate_model', 'target': 'inference_function', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'model_params.pop', 'target_inputs': [\"'model_path'\"]}, {'source': 'instantiate_model', 'target': 'ModelClass', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'logging.info', 'target_inputs': [\"f'Failed to instantiate the model. Error: {e}'\"]}, {'source': 'get_model', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'MODEL_CONFIG_FILE']}, {'source': 'get_model', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_model', 'target': 'open', 'target_inputs': ['model_config_pathname', \"'r'\"]}, {'source': 'get_model', 'target': 'yaml.safe_load', 'target_inputs': ['config_file']}, {'source': 'get_model', 'target': 'logging.info', 'target_inputs': [\"f'Model config file not valid: {model_config_pathname} Using default model config'\"]}, {'source': 'get_model', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'get_model', 'target': 'instantiate_model', 'target_inputs': [\"model_config['inference_model']\"], 'target_returns': ['model', 'None']}, {'source': 'write_questions_file', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'write_questions_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_questions_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, QUESTIONS_FILE)', \"'w'\"]}, {'source': 'write_questions_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'QUESTIONS_FILE']}, {'source': 'write_questions_file', 'target': 'json.dump', 'target_inputs': ['questions', 'file']}, {'source': 'write_model_config_file', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'write_model_config_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_model_config_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, MODEL_CONFIG_FILE)', \"'w'\"]}, {'source': 'write_model_config_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'MODEL_CONFIG_FILE']}, {'source': 'write_model_config_file', 'target': 'yaml.dump', 'target_inputs': ['model_config', 'file']}]}"
    },
    {
        "instruction": "What functions are defined in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport yaml\nimport importlib\nfrom typing import Dict, List \nfrom pathlib import Path\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"What are the dependencies of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"internal_code_graph\",\n            \"text\": \"What is the call code graph of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"What functions are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },      \n        {\n            \"id\": \"file_classes\",\n            \"text\": \"What classes are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        }, \n        {\n            \"id\": \"function_returns\",\n            \"text\": \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {   \n            \"id\": \"file_purpose\",\n            \"text\": \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible \n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 8400,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except: # get default questions if can't read questions_pathname file \n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\": \n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else: \n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")    \n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return instantiate_model(model_config['inference_model']), model_config['prompt_template']\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "get_default_questions, instantiate_model, write_model_config_file, write_questions_file, get_questions, get_default_model_config, get_output_dir, get_model"
    },
    {
        "instruction": "What are the inputs to the function: 'get_output_dir' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "output_dir"
    },
    {
        "instruction": "What are the inputs to the function: 'get_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except:\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "questions_pathname"
    },
    {
        "instruction": "What are the inputs to the function: 'instantiate_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "model_config"
    },
    {
        "instruction": "What are the inputs to the function: 'get_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return (instantiate_model(model_config['inference_model']), model_config['prompt_template'])",
        "output": "model_config_pathname"
    },
    {
        "instruction": "What are the inputs to the function: 'write_questions_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "output_dir"
    },
    {
        "instruction": "What are the inputs to the function: 'write_model_config_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "output_dir"
    },
    {
        "instruction": "What is the docstring of the function: 'get_default_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies', 'text': \"What are the dependencies of the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'internal_code_graph', 'text': \"What is the call code graph of the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'entire_code_graph', 'text': \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_functions', 'text': \"What functions are defined in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_classes', 'text': \"What classes are defined in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'function_inputs', 'text': \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_docstring', 'text': \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_calls', 'text': \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_variables', 'text': \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_returns', 'text': \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'class_methods', 'text': \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_docstring', 'text': \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_attributes', 'text': \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_variables', 'text': \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_inheritance', 'text': \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'method_inputs', 'text': \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_docstring', 'text': \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_calls', 'text': \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_returns', 'text': \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'file_purpose', 'text': \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\", 'type': 'file'}]\n    return questions",
        "output": "Return default question list Args: None Returns: ListDict: The default question list"
    },
    {
        "instruction": "What is the docstring of the function: 'get_default_model_config' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {'prompt_template': \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\", 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF', 'model_type': 'llama', 'local_files_only': False, 'threads': 28, 'batch_size': 128, 'context_length': 8400, 'max_new_tokens': 8092, 'gpu_layers': 100, 'reset': True}}}\n    return model_config",
        "output": "Return default model config dict Args: None Returns: Dict: The default model config dictionary"
    },
    {
        "instruction": "What is the docstring of the function: 'get_output_dir' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "Returns the appropriate output directory. Args: output_dir str: The directory to write the output to. Returns: str: The absolute path of the provided output_dir if it exists or can be created."
    },
    {
        "instruction": "What is the docstring of the function: 'get_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except:\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "Get questions from file or default Args: questions_pathname str: The pathname of the questions file Returns: ListDict: The list of questions"
    },
    {
        "instruction": "What is the docstring of the function: 'instantiate_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "or None if error., Imports and instantiates a model based on the provided configuration. Args: model_config dict: model configuration dictionary. Returns: object: An instance of the specified model class"
    },
    {
        "instruction": "What is the docstring of the function: 'get_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return (instantiate_model(model_config['inference_model']), model_config['prompt_template'])",
        "output": "Returns an instantiated model and prompt template based on the model configuration. Agrs: model_config_pathname str: The pathname of the model config file Returns: Tupleobject, str: The instantiated model and prompt template"
    },
    {
        "instruction": "What is the docstring of the function: 'write_questions_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "Writes the default questions to a file in JSON format. Args: output_dir str: The directory to write the questions file to. Returns: None"
    },
    {
        "instruction": "What is the docstring of the function: 'write_model_config_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "Writes the default model config to a file in YAML format. Args: output_dir str: The directory to write the model config file to. Returns: None"
    },
    {
        "instruction": "What calls are made in the function: 'get_output_dir' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "os.makedirs, logging.info, os.path.abspath"
    },
    {
        "instruction": "What calls are made in the function: 'get_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except:\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "get_default_questions, json.load, os.getcwd, logging.info, os.path.join, open"
    },
    {
        "instruction": "What calls are made in the function: 'instantiate_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "inference_function, ModelClass, model_params.pop, model_configmodel_import_path.rsplit, importlib.import_module, logging.info, getattr"
    },
    {
        "instruction": "What calls are made in the function: 'get_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return (instantiate_model(model_config['inference_model']), model_config['prompt_template'])",
        "output": "get_default_model_config, instantiate_model, os.getcwd, logging.info, os.path.join, yaml.safe_load, open"
    },
    {
        "instruction": "What calls are made in the function: 'write_questions_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "get_default_questions, json.dump, Pathoutput_dir.is_dir, os.getcwd, Path, os.path.join, open"
    },
    {
        "instruction": "What calls are made in the function: 'write_model_config_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "Pathoutput_dir.is_dir, os.getcwd, Path, os.path.join, get_default_model_config, yaml.dump, open"
    },
    {
        "instruction": "What variables are defined in the function: 'get_default_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies', 'text': \"What are the dependencies of the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'internal_code_graph', 'text': \"What is the call code graph of the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'entire_code_graph', 'text': \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_functions', 'text': \"What functions are defined in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_classes', 'text': \"What classes are defined in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'function_inputs', 'text': \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_docstring', 'text': \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_calls', 'text': \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_variables', 'text': \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_returns', 'text': \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'class_methods', 'text': \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_docstring', 'text': \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_attributes', 'text': \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_variables', 'text': \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_inheritance', 'text': \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'method_inputs', 'text': \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_docstring', 'text': \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_calls', 'text': \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_returns', 'text': \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'file_purpose', 'text': \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\", 'type': 'file'}]\n    return questions",
        "output": "questions"
    },
    {
        "instruction": "What variables are defined in the function: 'get_default_model_config' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {'prompt_template': \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\", 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF', 'model_type': 'llama', 'local_files_only': False, 'threads': 28, 'batch_size': 128, 'context_length': 8400, 'max_new_tokens': 8092, 'gpu_layers': 100, 'reset': True}}}\n    return model_config",
        "output": "model_config"
    },
    {
        "instruction": "What variables are defined in the function: 'get_output_dir' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "output_dir"
    },
    {
        "instruction": "What variables are defined in the function: 'get_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except:\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "questions, questions_pathname"
    },
    {
        "instruction": "What variables are defined in the function: 'instantiate_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "model_params, inference_function, ModelClass, model, inference_function_name"
    },
    {
        "instruction": "What variables are defined in the function: 'get_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return (instantiate_model(model_config['inference_model']), model_config['prompt_template'])",
        "output": "model_config_pathname, model_config"
    },
    {
        "instruction": "What variables are defined in the function: 'write_questions_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "questions, output_dir"
    },
    {
        "instruction": "What variables are defined in the function: 'write_model_config_file' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "output_dir, model_config"
    },
    {
        "instruction": "What are the returned items from the function: 'get_default_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies', 'text': \"What are the dependencies of the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'internal_code_graph', 'text': \"What is the call code graph of the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'entire_code_graph', 'text': \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_functions', 'text': \"What functions are defined in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_classes', 'text': \"What classes are defined in the Python file: '{filename}'?\", 'type': 'file'}, {'id': 'function_inputs', 'text': \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_docstring', 'text': \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_calls', 'text': \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_variables', 'text': \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_returns', 'text': \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\", 'type': 'function'}, {'id': 'class_methods', 'text': \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_docstring', 'text': \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_attributes', 'text': \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_variables', 'text': \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_inheritance', 'text': \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'class'}, {'id': 'method_inputs', 'text': \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_docstring', 'text': \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_calls', 'text': \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_returns', 'text': \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\", 'type': 'method'}, {'id': 'file_purpose', 'text': \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\", 'type': 'file'}]\n    return questions",
        "output": "questions"
    },
    {
        "instruction": "What are the returned items from the function: 'get_default_model_config' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {'prompt_template': \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\", 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF', 'model_type': 'llama', 'local_files_only': False, 'threads': 28, 'batch_size': 128, 'context_length': 8400, 'max_new_tokens': 8092, 'gpu_layers': 100, 'reset': True}}}\n    return model_config",
        "output": "model_config"
    },
    {
        "instruction": "What are the returned items from the function: 'get_output_dir' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "output_dir"
    },
    {
        "instruction": "What are the returned items from the function: 'get_questions' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except:\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "questions"
    },
    {
        "instruction": "What are the returned items from the function: 'instantiate_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "model, None"
    },
    {
        "instruction": "What are the returned items from the function: 'get_model' in the Python file: 'py2dataset.get_py2dataset_params.py'?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return (instantiate_model(model_config['inference_model']), model_config['prompt_template'])",
        "output": "instantiate_modelmodel_configinference_model, model_configprompt_template"
    },
    {
        "instruction": "1) Describe the purpose and processing summary of the Python file: 'py2dataset.get_py2dataset_params.py; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport yaml\nimport importlib\nfrom typing import Dict, List \nfrom pathlib import Path\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"What are the dependencies of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"internal_code_graph\",\n            \"text\": \"What is the call code graph of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"What functions are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },      \n        {\n            \"id\": \"file_classes\",\n            \"text\": \"What classes are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        }, \n        {\n            \"id\": \"function_returns\",\n            \"text\": \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {   \n            \"id\": \"file_purpose\",\n            \"text\": \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible \n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 8400,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except: # get default questions if can't read questions_pathname file \n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\": \n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else: \n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")    \n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return instantiate_model(model_config['inference_model']), model_config['prompt_template']\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "The `get_default_questions` function returns a list of default questions with ids, texts, and types for use in the py2dataset program. It validates that each question is a dictionary and has all three keys specified in [req01]. \nThe `get_default_model_config` function returns a dictionary representing the default model configuration used by the `py2dataset` program. The prompt template is set to a default value, but can be customized based on user input. \nThe `get_output_dir` function takes an optional output directory and verifies whether it exists or creates a new directory using Path(). The specified OUTPUT_DIR global variable serves as a default. This allows users the ability to pass a non-valid file path when running the program, and ensures that there is always a valid output directory for writing files. \nThe `get_questions` function accepts an optional questions_pathname argument, but defaults to QUESTIONS_FILE in the current working directory if it is not provided or invalid. It then checks if the file exists and is valid JSON format using json.load(). If it fails, it returns default questions from get_default_questions() instead. \nThe `instantiate_model` function takes a model_config dictionary as an argument and imports the specified module and class from the model_config. It then instantiates the model using the provided configuration based on the import path and parameters. If there is an error, it returns None. \nThe `get_model` function accepts an optional model_config_pathname argument and defaults to MODEL_CONFIG_FILE in the current working directory if not provided or invalid. It then validates and imports a new dictionary config and updates default prompt using the appropriate global variable based on whether an updated output was received in its signature, [req08] using Path() validation check with `output_dir.is_dir()`. If it fails to load, it defaults to the default model configuration and uses yaml.safe_load(). It returns an instantiated model object along with a prompt template. \nThe `write_questions_file` function accepts an optional output directory and writes the default questions to QUESTIONS_FILE in that directory or the current working directory if none is specified using open(). It defaults to Path().exists() for checking the directory path before writing to avoid creating unwanted directories or errors. \nThe `write_model_config_file` function accepts an optional output directory and writes the default model configuration to MODEL_CONFIG_FILE in that directory or the current working directory if none is specified using open(). It defaults to Path().exists() for checking the directory path before writing to avoid creating unwanted directories or errors. \nThe `get_output_dir` function uses os.path.abspath() to ensure that the output directory is an absolute path, and then creates it if it does not exist using os.makedirs(). It logs a message indicating which directory was used for output. \nThe `get_questions` function accepts an optional questions_pathname argument and checks whether it exists or not. If it fails to load, it defaults to the default questions file in the current working directory. It then validates that each question is a dictionary with all three keys specified in [req01]. \nThe `instantiate_model` function imports the module and class from the model_config dictionary using importlib.import_module() and getattr(). It then instantiates the model object based on whether the \"model_inference_function\" value is specified or not. The latter allows users to select their desired Hugging Face API, ct-transformers specifically in this case. \nThe `get_model` function accepts an optional model_config_pathname argument and defaults to MODEL_CONFIG_FILE in the current working directory if it is not provided or invalid. It then validates that the file exists using yaml.safe_load() before loading a new dictionary config and updating default prompt using the appropriate global variable based on whether an updated output was received in its signature, [req08] using Path(). If it fails to load, it defaults to the default model configuration. It returns an instantiated model object along with a prompt template specified by the user or the default prompt. \nThe `write_questions_file` function writes the default questions to QUESTIONS_FILE in the provided output directory using json.dump(). If no output directory is provided, it defaults to the current working directory. \nThe `write_model_config_file` function also takes an optional output_dir and creates a default YAML config file in the provided path or current directory. This allows for user-specific settings such as different prompts or model parameters."
    }
]