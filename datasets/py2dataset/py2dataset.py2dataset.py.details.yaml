file_info:
  file_code: "\"\"\"\nFor each Python file within given directory, generate, save,\
    \ and return datasets that include responses to questions about the code.\nRequirements:\n\
    [req00] The extract_python_data function shall:\n    a. Accept parameters for\
    \ the Python file path, base name, model configuration pathname, questions dictionary,\
    \ and use of LLM.\n    b. Use the 'get_python_file_details' function to get the\
    \ Python file details.\n    c. If the use_llm parameter is True, instantiate the\
    \ LLM using the 'get_model' function.\n    d. Use the 'get_python_datasets' function\
    \ to get the instruct.json datasets.\n    e. Return the file details and instruct.json\
    \ dataset.\n[req01] The process_python_directories function shall:\n    a. Accept\
    \ parameters for the starting directory, output directory, model configuration\
    \ pathname, questions dictionary, and use of LLM.\n    b. Search for all Python\
    \ files within the given directory and its subdirectories using a glob pattern.\n\
    \    c. For each Python file, call the extract_python_data function to get the\
    \ file details and instruct.json dataset.\n    d. For valid Python file datasets,\
    \ call the save_python_data function to save the file details and instruct.json\
    \ dataset.\n    e. Combine all of the instruct.json files together using the 'combine_json_files'\
    \ function.\n    f. Return the combined datasets.\n[req02] The py2dataset function\
    \ shall:\n    a. Accept parameters for the starting directory, output directory,\
    \ questions pathname, model configuration pathname, quiet mode, and use of LLM.\n\
    \    b. Determine the starting directory based on provided or default values.\n\
    \    c. Adjust the logging level based on the quiet flag.\n    d. Call the process_python_directories\
    \ function to process the Python files and generate datasets.\n    e. Return the\
    \ datasets.\n[req03] The main function shall:\n    a. Accept and process command-line\
    \ arguments.\n    b. Determine the parameters for the py2dataset function based\
    \ on the processed command-line arguments.\n    c. Call the py2dataset function\
    \ with the derived parameters.\n\"\"\"\nimport os\nimport sys\nimport gc\nimport\
    \ logging\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Union\n\
    from multiprocessing import Process\n\nfrom get_python_file_details import get_python_file_details\n\
    from get_python_datasets import get_python_datasets\nfrom get_py2dataset_params\
    \ import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output\
    \ import combine_json_files, save_python_data\n\ndef extract_python_data(file_path:\
    \ str, base_name: str, questions: Dict, llm: object, prompt: str) -> Tuple[Union[Dict,\
    \ Tuple], List[Dict], List[Dict]]:\n    \"\"\"\n    Extracts data from a Python\
    \ file.\n    Args:\n        file_path (str): Path to the Python file.\n      \
    \  base_name (str): Base name of the Python file.\n        questions (Dict): Questions\
    \ dictionary to answer about the Python file.\n        llm (object): Large Language\
    \ Model object. If None, use the default prompt.\n        prompt (str): Prompt\
    \ to use for the Large Language Model.\n    Returns:\n        Tuple[Union[Dict,\
    \ Tuple], List[Dict], List[Dict]]: File details dictionary or tuple of file details\
    \ and None, instruct.json dataset.\n    \"\"\"\n    file_details, instruct_list\
    \ = None, None    \n    # use AST to get python file details\n    file_details\
    \ = get_python_file_details(file_path)\n    if file_details is None or isinstance(file_details,\
    \ tuple):\n        return file_details, instruct_list\n\n    # get lists for instruct.json\
    \ for python file\n    instruct_list = get_python_datasets(file_path, file_details,\
    \ base_name, questions, llm, prompt)  \n    return file_details, instruct_list\n\
    \n\ndef process_single_file(pythonfile_path, start_dir, model_config_pathname,\
    \ questions, use_llm, output_dir):\n    \"\"\"\n    Process a single Python file\
    \ to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path\
    \ (str): Path to the Python file.\n        start_dir (str): Starting directory\
    \ to search for Python files.\n        model_config_pathname (str): Path to the\
    \ model configuration file.\n        questions (Dict): Questions dictionary to\
    \ answer about the Python file.\n        use_llm (bool): If True, use a Large\
    \ Language Model for generating JSON answers.\n        output_dir (str): Directory\
    \ to write the output files.\n    Returns:\n        none\n    \"\"\"\n    logging.info(f'Processing:\
    \ {pythonfile_path}')\n    relative_path = pythonfile_path.relative_to(start_dir)\n\
    \    base_name = '.'.join(part for part in relative_path.parts)\n\n    #instantiate\
    \ llm and prompt if use_llm is True \n    #do this for each file to aviod multiprocessing\
    \ pickling problem\n    llm, prompt = get_model(model_config_pathname) if use_llm\
    \ else (None, '')\n\n    # get and save file_details and instruct_list\n    file_details,\
    \ instruct_list = extract_python_data(pythonfile_path, base_name, questions, llm,\
    \ prompt)\n    if file_details is None or isinstance(file_details, tuple):\n \
    \       return\n    save_python_data(file_details, instruct_list, relative_path,\
    \ output_dir)\n\n\ndef process_python_directories(start_dir: str, output_dir:\
    \ str, model_config_pathname: str, questions: Dict, \n                       \
    \        use_llm: bool) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Processes all\
    \ Python files in the provided directory and subdirectories.\n    Args:\n    \
    \    start_dir (str): Starting directory to search for Python files.\n       \
    \ output_dir (str): Directory to write the output files.\n        model_config_pathname\
    \ (str): Path to the model configuration file.\n        questions (Dict): Questions\
    \ dictionary to answer about each Python file.\n        use_llm (bool): If True,\
    \ use the LLM model to generate answers for JSON..\n    Returns:\n        Dict[str,\
    \ List[Dict]]: Datasets dictionary.\n    \"\"\"\n    datasets = {}\n    for pythonfile_path\
    \ in Path(start_dir).rglob('[!_]*.py'):\n\n        if pythonfile_path.is_dir():\n\
    \            continue\n\n        # spawn a new child process to manage python\
    \ memory leaks\n        proc = Process(target=process_single_file, args=(pythonfile_path,\
    \ start_dir, model_config_pathname, questions, use_llm, output_dir))\n       \
    \ proc.start()\n        proc.join()\n        \n    # combine all of the instruct.json\
    \ files together\n    datasets = combine_json_files(output_dir)   \n    return\
    \ datasets\n\n\ndef py2dataset(start_dir: str = '', output_dir: str = '', questions_pathname:\
    \ str = '', model_config_pathname: str = '', \n               use_llm: bool =\
    \ False, quiet: bool = False) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process\
    \ Python files to generate question-answer pairs and instructions.\n    Args:\n\
    \        start_dir (str, optional): Starting directory to search for Python files.\
    \ Defaults to current working directory.\n        output_dir (str, optional):\
    \ Directory to write the output files.\n        questions_pathname (str, optional):\
    \ Path to the questions file.\n        model_config_pathname (str, optional):\
    \ Path to the model configuration file.\n        use_llm (bool, optional): If\
    \ True, use a Large Language Model for generating JSON answers. Defaults to False.\n\
    \        quiet (bool, optional): Limit logging output. Defaults to False.\n  \
    \  Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n\
    \    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n    else:\n\
    \        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\
    \  # Increase the recursion limit for AST\n    \n    # if start dir is empty or\
    \ not a valid directory, use current working directory\n    if start_dir == ''\
    \ :\n        logging.info('No valid start path provided. Using current working\
    \ directory.')\n        start_dir = os.getcwd()    \n    start_dir = os.path.abspath(start_dir)\n\
    \    \n    output_dir = get_output_dir(output_dir)\n    questions = get_questions(questions_pathname)\n\
    \n    datasets = process_python_directories(start_dir, output_dir, model_config_pathname,\
    \ questions, use_llm)\n    return datasets\n\ndef main():\n    \"\"\"\n    Command-line\
    \ entry point for processing Python files and generating datasets.\n    Args:\n\
    \        --start_dir (str, optional): Starting directory to search for Python\
    \ files. Defaults to the current working directory.\n        --output_dir (str,\
    \ optional): Directory to write the output files. Defaults to the 'datasets' directory\
    \ in the current working directory.\n        --questions_pathname (str, optional):\
    \ Path to the questions file. If not provided, defaults defined in 'get_py2dataset_params.py'\
    \ will be used.\n        --model_config_pathname (str, optional): Path to the\
    \ model configuration file. If not provided, defaults defined in 'get_py2dataset_params.py'\
    \ will be used.\n        --use_llm (bool, optional): Use a Large Language Model\
    \ for generating JSON answers. Defaults to False.\n        --quiet (bool, optional):\
    \ Limit logging output. If provided, only warnings and errors will be logged.\
    \ Defaults to False.\n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n  \
    \  start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname\
    \ = ''\n    use_llm = False\n    quiet = False\n\n    if '--start_dir' in arg_string:\
    \    \n        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n\
    \        arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n   \
    \ if '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir\
    \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir\
    \ {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n      \
    \  model_config_pathname = arg_string.split('--model_config_pathname ')[1].split('\
    \ ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}',\
    \ '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname\
    \ = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string\
    \ = arg_string.replace(f'--questions_pathname {questions_pathname}', '') \n  \
    \  if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string =\
    \ arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n     \
    \   quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n\n \
    \   py2dataset(start_dir, output_dir, questions_pathname, model_config_pathname,\
    \ use_llm, quiet)\n\nif __name__ == \"__main__\":\n    main()"
  file_ast: 'Module(body=[Expr(value=Constant(value="\nFor each Python file within
    given directory, generate, save, and return datasets that include responses to
    questions about the code.\nRequirements:\n[req00] The extract_python_data function
    shall:\n    a. Accept parameters for the Python file path, base name, model configuration
    pathname, questions dictionary, and use of LLM.\n    b. Use the ''get_python_file_details''
    function to get the Python file details.\n    c. If the use_llm parameter is True,
    instantiate the LLM using the ''get_model'' function.\n    d. Use the ''get_python_datasets''
    function to get the instruct.json datasets.\n    e. Return the file details and
    instruct.json dataset.\n[req01] The process_python_directories function shall:\n    a.
    Accept parameters for the starting directory, output directory, model configuration
    pathname, questions dictionary, and use of LLM.\n    b. Search for all Python
    files within the given directory and its subdirectories using a glob pattern.\n    c.
    For each Python file, call the extract_python_data function to get the file details
    and instruct.json dataset.\n    d. For valid Python file datasets, call the save_python_data
    function to save the file details and instruct.json dataset.\n    e. Combine all
    of the instruct.json files together using the ''combine_json_files'' function.\n    f.
    Return the combined datasets.\n[req02] The py2dataset function shall:\n    a.
    Accept parameters for the starting directory, output directory, questions pathname,
    model configuration pathname, quiet mode, and use of LLM.\n    b. Determine the
    starting directory based on provided or default values.\n    c. Adjust the logging
    level based on the quiet flag.\n    d. Call the process_python_directories function
    to process the Python files and generate datasets.\n    e. Return the datasets.\n[req03]
    The main function shall:\n    a. Accept and process command-line arguments.\n    b.
    Determine the parameters for the py2dataset function based on the processed command-line
    arguments.\n    c. Call the py2dataset function with the derived parameters.\n")),
    Import(names=[alias(name=''os'')]), Import(names=[alias(name=''sys'')]), Import(names=[alias(name=''gc'')]),
    Import(names=[alias(name=''logging'')]), ImportFrom(module=''pathlib'', names=[alias(name=''Path'')],
    level=0), ImportFrom(module=''typing'', names=[alias(name=''Dict''), alias(name=''List''),
    alias(name=''Tuple''), alias(name=''Union'')], level=0), ImportFrom(module=''multiprocessing'',
    names=[alias(name=''Process'')], level=0), ImportFrom(module=''get_python_file_details'',
    names=[alias(name=''get_python_file_details'')], level=0), ImportFrom(module=''get_python_datasets'',
    names=[alias(name=''get_python_datasets'')], level=0), ImportFrom(module=''get_py2dataset_params'',
    names=[alias(name=''get_questions''), alias(name=''get_model''), alias(name=''get_output_dir'')],
    level=0), ImportFrom(module=''save_py2dataset_output'', names=[alias(name=''combine_json_files''),
    alias(name=''save_python_data'')], level=0), FunctionDef(name=''extract_python_data'',
    args=arguments(posonlyargs=[], args=[arg(arg=''file_path'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''base_name'', annotation=Name(id=''str'', ctx=Load())),
    arg(arg=''questions'', annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''llm'',
    annotation=Name(id=''object'', ctx=Load())), arg(arg=''prompt'', annotation=Name(id=''str'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Extracts
    data from a Python file.\n    Args:\n        file_path (str): Path to the Python
    file.\n        base_name (str): Base name of the Python file.\n        questions
    (Dict): Questions dictionary to answer about the Python file.\n        llm (object):
    Large Language Model object. If None, use the default prompt.\n        prompt
    (str): Prompt to use for the Large Language Model.\n    Returns:\n        Tuple[Union[Dict,
    Tuple], List[Dict], List[Dict]]: File details dictionary or tuple of file details
    and None, instruct.json dataset.\n    '')), Assign(targets=[Tuple(elts=[Name(id=''file_details'',
    ctx=Store()), Name(id=''instruct_list'', ctx=Store())], ctx=Store())], value=Tuple(elts=[Constant(value=None),
    Constant(value=None)], ctx=Load())), Assign(targets=[Name(id=''file_details'',
    ctx=Store())], value=Call(func=Name(id=''get_python_file_details'', ctx=Load()),
    args=[Name(id=''file_path'', ctx=Load())], keywords=[])), If(test=BoolOp(op=Or(),
    values=[Compare(left=Name(id=''file_details'', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]),
    Call(func=Name(id=''isinstance'', ctx=Load()), args=[Name(id=''file_details'',
    ctx=Load()), Name(id=''tuple'', ctx=Load())], keywords=[])]), body=[Return(value=Tuple(elts=[Name(id=''file_details'',
    ctx=Load()), Name(id=''instruct_list'', ctx=Load())], ctx=Load()))], orelse=[]),
    Assign(targets=[Name(id=''instruct_list'', ctx=Store())], value=Call(func=Name(id=''get_python_datasets'',
    ctx=Load()), args=[Name(id=''file_path'', ctx=Load()), Name(id=''file_details'',
    ctx=Load()), Name(id=''base_name'', ctx=Load()), Name(id=''questions'', ctx=Load()),
    Name(id=''llm'', ctx=Load()), Name(id=''prompt'', ctx=Load())], keywords=[])),
    Return(value=Tuple(elts=[Name(id=''file_details'', ctx=Load()), Name(id=''instruct_list'',
    ctx=Load())], ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''Tuple'',
    ctx=Load()), slice=Tuple(elts=[Subscript(value=Name(id=''Union'', ctx=Load()),
    slice=Tuple(elts=[Name(id=''Dict'', ctx=Load()), Name(id=''Tuple'', ctx=Load())],
    ctx=Load()), ctx=Load()), Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
    ctx=Load()), ctx=Load()), Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
    ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())), FunctionDef(name=''process_single_file'',
    args=arguments(posonlyargs=[], args=[arg(arg=''pythonfile_path''), arg(arg=''start_dir''),
    arg(arg=''model_config_pathname''), arg(arg=''questions''), arg(arg=''use_llm''),
    arg(arg=''output_dir'')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Process
    a single Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path
    (str): Path to the Python file.\n        start_dir (str): Starting directory to
    search for Python files.\n        model_config_pathname (str): Path to the model
    configuration file.\n        questions (Dict): Questions dictionary to answer
    about the Python file.\n        use_llm (bool): If True, use a Large Language
    Model for generating JSON answers.\n        output_dir (str): Directory to write
    the output files.\n    Returns:\n        none\n    '')), Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Processing:
    ''), FormattedValue(value=Name(id=''pythonfile_path'', ctx=Load()), conversion=-1)])],
    keywords=[])), Assign(targets=[Name(id=''relative_path'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''pythonfile_path'',
    ctx=Load()), attr=''relative_to'', ctx=Load()), args=[Name(id=''start_dir'', ctx=Load())],
    keywords=[])), Assign(targets=[Name(id=''base_name'', ctx=Store())], value=Call(func=Attribute(value=Constant(value=''.''),
    attr=''join'', ctx=Load()), args=[GeneratorExp(elt=Name(id=''part'', ctx=Load()),
    generators=[comprehension(target=Name(id=''part'', ctx=Store()), iter=Attribute(value=Name(id=''relative_path'',
    ctx=Load()), attr=''parts'', ctx=Load()), ifs=[], is_async=0)])], keywords=[])),
    Assign(targets=[Tuple(elts=[Name(id=''llm'', ctx=Store()), Name(id=''prompt'',
    ctx=Store())], ctx=Store())], value=IfExp(test=Name(id=''use_llm'', ctx=Load()),
    body=Call(func=Name(id=''get_model'', ctx=Load()), args=[Name(id=''model_config_pathname'',
    ctx=Load())], keywords=[]), orelse=Tuple(elts=[Constant(value=None), Constant(value='''')],
    ctx=Load()))), Assign(targets=[Tuple(elts=[Name(id=''file_details'', ctx=Store()),
    Name(id=''instruct_list'', ctx=Store())], ctx=Store())], value=Call(func=Name(id=''extract_python_data'',
    ctx=Load()), args=[Name(id=''pythonfile_path'', ctx=Load()), Name(id=''base_name'',
    ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''llm'', ctx=Load()),
    Name(id=''prompt'', ctx=Load())], keywords=[])), If(test=BoolOp(op=Or(), values=[Compare(left=Name(id=''file_details'',
    ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), Call(func=Name(id=''isinstance'',
    ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''tuple'', ctx=Load())],
    keywords=[])]), body=[Return()], orelse=[]), Expr(value=Call(func=Name(id=''save_python_data'',
    ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''instruct_list'',
    ctx=Load()), Name(id=''relative_path'', ctx=Load()), Name(id=''output_dir'', ctx=Load())],
    keywords=[]))], decorator_list=[]), FunctionDef(name=''process_python_directories'',
    args=arguments(posonlyargs=[], args=[arg(arg=''start_dir'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load())),
    arg(arg=''model_config_pathname'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''questions'',
    annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''use_llm'', annotation=Name(id=''bool'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Processes
    all Python files in the provided directory and subdirectories.\n    Args:\n        start_dir
    (str): Starting directory to search for Python files.\n        output_dir (str):
    Directory to write the output files.\n        model_config_pathname (str): Path
    to the model configuration file.\n        questions (Dict): Questions dictionary
    to answer about each Python file.\n        use_llm (bool): If True, use the LLM
    model to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]:
    Datasets dictionary.\n    '')), Assign(targets=[Name(id=''datasets'', ctx=Store())],
    value=Dict(keys=[], values=[])), For(target=Name(id=''pythonfile_path'', ctx=Store()),
    iter=Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''start_dir'',
    ctx=Load())], keywords=[]), attr=''rglob'', ctx=Load()), args=[Constant(value=''[!_]*.py'')],
    keywords=[]), body=[If(test=Call(func=Attribute(value=Name(id=''pythonfile_path'',
    ctx=Load()), attr=''is_dir'', ctx=Load()), args=[], keywords=[]), body=[Continue()],
    orelse=[]), Assign(targets=[Name(id=''proc'', ctx=Store())], value=Call(func=Name(id=''Process'',
    ctx=Load()), args=[], keywords=[keyword(arg=''target'', value=Name(id=''process_single_file'',
    ctx=Load())), keyword(arg=''args'', value=Tuple(elts=[Name(id=''pythonfile_path'',
    ctx=Load()), Name(id=''start_dir'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load()),
    Name(id=''output_dir'', ctx=Load())], ctx=Load()))])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
    ctx=Load()), attr=''start'', ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
    ctx=Load()), attr=''join'', ctx=Load()), args=[], keywords=[]))], orelse=[]),
    Assign(targets=[Name(id=''datasets'', ctx=Store())], value=Call(func=Name(id=''combine_json_files'',
    ctx=Load()), args=[Name(id=''output_dir'', ctx=Load())], keywords=[])), Return(value=Name(id=''datasets'',
    ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''Dict'', ctx=Load()),
    slice=Tuple(elts=[Name(id=''str'', ctx=Load()), Subscript(value=Name(id=''List'',
    ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())),
    FunctionDef(name=''py2dataset'', args=arguments(posonlyargs=[], args=[arg(arg=''start_dir'',
    annotation=Name(id=''str'', ctx=Load())), arg(arg=''output_dir'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''questions_pathname'', annotation=Name(id=''str'', ctx=Load())),
    arg(arg=''model_config_pathname'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''use_llm'',
    annotation=Name(id=''bool'', ctx=Load())), arg(arg=''quiet'', annotation=Name(id=''bool'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=''''),
    Constant(value=''''), Constant(value=''''), Constant(value=''''), Constant(value=False),
    Constant(value=False)]), body=[Expr(value=Constant(value=''\n    Process Python
    files to generate question-answer pairs and instructions.\n    Args:\n        start_dir
    (str, optional): Starting directory to search for Python files. Defaults to current
    working directory.\n        output_dir (str, optional): Directory to write the
    output files.\n        questions_pathname (str, optional): Path to the questions
    file.\n        model_config_pathname (str, optional): Path to the model configuration
    file.\n        use_llm (bool, optional): If True, use a Large Language Model for
    generating JSON answers. Defaults to False.\n        quiet (bool, optional): Limit
    logging output. Defaults to False.\n    Returns:\n        Dict[str, List[Dict]]:
    Datasets dictionary.\n    '')), If(test=Name(id=''quiet'', ctx=Load()), body=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
    ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''WARNING'',
    ctx=Load())], keywords=[]))], orelse=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
    ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''INFO'',
    ctx=Load())], keywords=[]))]), Expr(value=Call(func=Attribute(value=Name(id=''sys'',
    ctx=Load()), attr=''setrecursionlimit'', ctx=Load()), args=[Constant(value=3000)],
    keywords=[])), If(test=Compare(left=Name(id=''start_dir'', ctx=Load()), ops=[Eq()],
    comparators=[Constant(value='''')]), body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[Constant(value=''No valid start
    path provided. Using current working directory.'')], keywords=[])), Assign(targets=[Name(id=''start_dir'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''os'', ctx=Load()), attr=''getcwd'',
    ctx=Load()), args=[], keywords=[]))], orelse=[]), Assign(targets=[Name(id=''start_dir'',
    ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''path'', ctx=Load()), attr=''abspath'', ctx=Load()), args=[Name(id=''start_dir'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''output_dir'', ctx=Store())],
    value=Call(func=Name(id=''get_output_dir'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''questions'', ctx=Store())],
    value=Call(func=Name(id=''get_questions'', ctx=Load()), args=[Name(id=''questions_pathname'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''datasets'', ctx=Store())],
    value=Call(func=Name(id=''process_python_directories'', ctx=Load()), args=[Name(id=''start_dir'',
    ctx=Load()), Name(id=''output_dir'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load())],
    keywords=[])), Return(value=Name(id=''datasets'', ctx=Load()))], decorator_list=[],
    returns=Subscript(value=Name(id=''Dict'', ctx=Load()), slice=Tuple(elts=[Name(id=''str'',
    ctx=Load()), Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
    ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())), FunctionDef(name=''main'',
    args=arguments(posonlyargs=[], args=[], kwonlyargs=[], kw_defaults=[], defaults=[]),
    body=[Expr(value=Constant(value="\n    Command-line entry point for processing
    Python files and generating datasets.\n    Args:\n        --start_dir (str, optional):
    Starting directory to search for Python files. Defaults to the current working
    directory.\n        --output_dir (str, optional): Directory to write the output
    files. Defaults to the ''datasets'' directory in the current working directory.\n        --questions_pathname
    (str, optional): Path to the questions file. If not provided, defaults defined
    in ''get_py2dataset_params.py'' will be used.\n        --model_config_pathname
    (str, optional): Path to the model configuration file. If not provided, defaults
    defined in ''get_py2dataset_params.py'' will be used.\n        --use_llm (bool,
    optional): Use a Large Language Model for generating JSON answers. Defaults to
    False.\n        --quiet (bool, optional): Limit logging output. If provided, only
    warnings and errors will be logged. Defaults to False.\n    ")), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Constant(value='' ''), attr=''join'',
    ctx=Load()), args=[Subscript(value=Attribute(value=Name(id=''sys'', ctx=Load()),
    attr=''argv'', ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())],
    keywords=[])), Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''output_dir'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''questions_pathname'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''model_config_pathname'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''use_llm'', ctx=Store())], value=Constant(value=False)),
    Assign(targets=[Name(id=''quiet'', ctx=Store())], value=Constant(value=False)),
    If(test=Compare(left=Constant(value=''--start_dir''), ops=[In()], comparators=[Name(id=''arg_string'',
    ctx=Load())]), body=[Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--start_dir '')],
    keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--start_dir
    ''), FormattedValue(value=Name(id=''start_dir'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--output_dir''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''output_dir'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--output_dir
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--output_dir
    ''), FormattedValue(value=Name(id=''output_dir'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--model_config_pathname''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''model_config_pathname'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--model_config_pathname
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--model_config_pathname
    ''), FormattedValue(value=Name(id=''model_config_pathname'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--questions_pathname''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''questions_pathname'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--questions_pathname
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--questions_pathname
    ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--use_llm''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''use_llm'',
    ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''--use_llm''), Constant(value='''')],
    keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--quiet''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''quiet'',
    ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''--quiet''), Constant(value='''')],
    keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''py2dataset'', ctx=Load()),
    args=[Name(id=''start_dir'', ctx=Load()), Name(id=''output_dir'', ctx=Load()),
    Name(id=''questions_pathname'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''use_llm'', ctx=Load()), Name(id=''quiet'', ctx=Load())],
    keywords=[]))], decorator_list=[]), If(test=Compare(left=Name(id=''__name__'',
    ctx=Load()), ops=[Eq()], comparators=[Constant(value=''__main__'')]), body=[Expr(value=Call(func=Name(id=''main'',
    ctx=Load()), args=[], keywords=[]))], orelse=[])], type_ignores=[])'
  file_dependencies:
  - logging
  - os
  - get_python_file_details
  - sys
  - get_python_datasets
  - typing
  - multiprocessing
  - save_py2dataset_output
  - pathlib
  - gc
  - get_py2dataset_params
  file_functions:
  - extract_python_data
  - process_single_file
  - process_python_directories
  - py2dataset
  - main
  file_classes: []
  file_summary: '{dependencies: [logging, os, get_python_file_details, sys, get_python_datasets,
    typing, multiprocessing, save_py2dataset_output, pathlib, gc, get_py2dataset_params],
    function_defs: [{extract_python_data: {inputs: [file_path, base_name, questions,
    llm, prompt], calls: [get_python_file_details, isinstance, get_python_datasets],
    call_inputs: {get_python_file_details: [file_path], isinstance: [file_details,
    tuple], get_python_datasets: [file_path, file_details, base_name, questions, llm,
    prompt]}, returns: [(file_details, instruct_list), (file_details, instruct_list)]}},
    {process_single_file: {inputs: [pythonfile_path, start_dir, model_config_pathname,
    questions, use_llm, output_dir], calls: [logging.info, pythonfile_path.relative_to,
    ''.''.join, get_model, extract_python_data, isinstance, save_python_data], call_inputs:
    {logging.info: [f''Processing: {pythonfile_path}''], pythonfile_path.relative_to:
    [start_dir], ''.''.join: [(part for part in relative_path.parts)], get_model:
    [model_config_pathname], extract_python_data: [pythonfile_path, base_name, questions,
    llm, prompt], isinstance: [file_details, tuple], save_python_data: [file_details,
    instruct_list, relative_path, output_dir]}, returns: [None]}}, {process_python_directories:
    {inputs: [start_dir, output_dir, model_config_pathname, questions, use_llm], calls:
    [Path(start_dir).rglob, Path, pythonfile_path.is_dir, Process, proc.start, proc.join,
    combine_json_files], call_inputs: {Path(start_dir).rglob: [''[!_]*.py''], Path:
    [start_dir], pythonfile_path.is_dir: [], Process: [], proc.start: [], proc.join:
    [], combine_json_files: [output_dir]}, returns: [datasets]}}, {py2dataset: {inputs:
    [start_dir, output_dir, questions_pathname, model_config_pathname, use_llm, quiet],
    calls: [logging.getLogger().setLevel, logging.getLogger, sys.setrecursionlimit,
    logging.info, os.getcwd, os.path.abspath, get_output_dir, get_questions, process_python_directories],
    call_inputs: {logging.getLogger().setLevel: [logging.INFO], logging.getLogger:
    [], sys.setrecursionlimit: [3000], logging.info: [''No valid start path provided.
    Using current working directory.''], os.getcwd: [], os.path.abspath: [start_dir],
    get_output_dir: [output_dir], get_questions: [questions_pathname], process_python_directories:
    [start_dir, output_dir, model_config_pathname, questions, use_llm]}, returns:
    [datasets]}}, {main: {inputs: [], calls: ['' ''.join, arg_string.split(''--start_dir
    '')[1].split, arg_string.split, arg_string.replace, arg_string.split(''--output_dir
    '')[1].split, arg_string.split(''--model_config_pathname '')[1].split, arg_string.split(''--questions_pathname
    '')[1].split, py2dataset], call_inputs: {'' ''.join: [sys.argv[1:]], arg_string.split(''--start_dir
    '')[1].split: ['' ''], arg_string.split: [''--questions_pathname ''], arg_string.replace:
    [''--quiet'', ''''], arg_string.split(''--output_dir '')[1].split: ['' ''], arg_string.split(''--model_config_pathname
    '')[1].split: ['' ''], arg_string.split(''--questions_pathname '')[1].split: [''
    ''], py2dataset: [start_dir, output_dir, questions_pathname, model_config_pathname,
    use_llm, quiet]}, returns: []}}], class_defs: []}'
  entire_code_graph:
    nodes:
    - extract_python_data
    - process_single_file
    - process_python_directories
    - py2dataset
    - main
    - get_python_file_details
    - isinstance
    - get_python_datasets
    - logging.info
    - pythonfile_path.relative_to
    - '''.''.join'
    - get_model
    - save_python_data
    - Path(start_dir).rglob
    - Path
    - pythonfile_path.is_dir
    - Process
    - proc.start
    - proc.join
    - combine_json_files
    - logging.getLogger().setLevel
    - logging.getLogger
    - sys.setrecursionlimit
    - os.getcwd
    - os.path.abspath
    - get_output_dir
    - get_questions
    - ''' ''.join'
    - arg_string.split('--start_dir ')[1].split
    - arg_string.split
    - arg_string.replace
    - arg_string.split('--output_dir ')[1].split
    - arg_string.split('--model_config_pathname ')[1].split
    - arg_string.split('--questions_pathname ')[1].split
    edges:
    - source: extract_python_data
      target: get_python_file_details
      target_inputs:
      - file_path
    - source: extract_python_data
      target: isinstance
      target_inputs:
      - file_details
      - tuple
    - source: extract_python_data
      target: get_python_datasets
      target_inputs:
      - file_path
      - file_details
      - base_name
      - questions
      - llm
      - prompt
    - source: process_single_file
      target: logging.info
      target_inputs:
      - 'f''Processing: {pythonfile_path}'''
    - source: process_single_file
      target: pythonfile_path.relative_to
      target_inputs:
      - start_dir
    - source: process_single_file
      target: '''.''.join'
      target_inputs:
      - (part for part in relative_path.parts)
    - source: process_single_file
      target: get_model
      target_inputs:
      - model_config_pathname
    - source: process_single_file
      target: extract_python_data
      target_inputs:
      - pythonfile_path
      - base_name
      - questions
      - llm
      - prompt
      target_returns:
      - (file_details, instruct_list)
    - source: process_single_file
      target: isinstance
      target_inputs:
      - file_details
      - tuple
    - source: process_single_file
      target: save_python_data
      target_inputs:
      - file_details
      - instruct_list
      - relative_path
      - output_dir
    - source: process_python_directories
      target: Path(start_dir).rglob
      target_inputs:
      - '''[!_]*.py'''
    - source: process_python_directories
      target: Path
      target_inputs:
      - start_dir
    - source: process_python_directories
      target: pythonfile_path.is_dir
      target_inputs: []
    - source: process_python_directories
      target: Process
      target_inputs: []
    - source: process_python_directories
      target: proc.start
      target_inputs: []
    - source: process_python_directories
      target: proc.join
      target_inputs: []
    - source: process_python_directories
      target: combine_json_files
      target_inputs:
      - output_dir
    - source: py2dataset
      target: logging.getLogger().setLevel
      target_inputs:
      - logging.INFO
    - source: py2dataset
      target: logging.getLogger
      target_inputs: []
    - source: py2dataset
      target: sys.setrecursionlimit
      target_inputs:
      - '3000'
    - source: py2dataset
      target: logging.info
      target_inputs:
      - '''No valid start path provided. Using current working directory.'''
    - source: py2dataset
      target: os.getcwd
      target_inputs: []
    - source: py2dataset
      target: os.path.abspath
      target_inputs:
      - start_dir
    - source: py2dataset
      target: get_output_dir
      target_inputs:
      - output_dir
    - source: py2dataset
      target: get_questions
      target_inputs:
      - questions_pathname
    - source: py2dataset
      target: process_python_directories
      target_inputs:
      - start_dir
      - output_dir
      - model_config_pathname
      - questions
      - use_llm
      target_returns:
      - datasets
    - source: main
      target: ''' ''.join'
      target_inputs:
      - sys.argv[1:]
    - source: main
      target: arg_string.split('--start_dir ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split
      target_inputs:
      - '''--questions_pathname '''
    - source: main
      target: arg_string.replace
      target_inputs:
      - '''--quiet'''
      - ''''''
    - source: main
      target: arg_string.split('--output_dir ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split('--model_config_pathname ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split('--questions_pathname ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: py2dataset
      target_inputs:
      - start_dir
      - output_dir
      - questions_pathname
      - model_config_pathname
      - use_llm
      - quiet
      target_returns:
      - datasets
functions:
  extract_python_data:
    function_name: extract_python_data
    function_code: "def extract_python_data(file_path: str, base_name: str, questions:\
      \ Dict, llm: object, prompt: str) -> Tuple[Union[Dict, Tuple], List[Dict], List[Dict]]:\n\
      \    \"\"\"\n    Extracts data from a Python file.\n    Args:\n        file_path\
      \ (str): Path to the Python file.\n        base_name (str): Base name of the\
      \ Python file.\n        questions (Dict): Questions dictionary to answer about\
      \ the Python file.\n        llm (object): Large Language Model object. If None,\
      \ use the default prompt.\n        prompt (str): Prompt to use for the Large\
      \ Language Model.\n    Returns:\n        Tuple[Union[Dict, Tuple], List[Dict],\
      \ List[Dict]]: File details dictionary or tuple of file details and None, instruct.json\
      \ dataset.\n    \"\"\"\n    file_details, instruct_list = (None, None)\n   \
      \ file_details = get_python_file_details(file_path)\n    if file_details is\
      \ None or isinstance(file_details, tuple):\n        return (file_details, instruct_list)\n\
      \    instruct_list = get_python_datasets(file_path, file_details, base_name,\
      \ questions, llm, prompt)\n    return (file_details, instruct_list)"
    function_ast: 'FunctionDef(name=''extract_python_data'', args=arguments(posonlyargs=[],
      args=[arg(arg=''file_path'', annotation=Name(id=''str'', ctx=Load(), lineno=41,
      col_offset=35, end_lineno=41, end_col_offset=38), lineno=41, col_offset=24,
      end_lineno=41, end_col_offset=38), arg(arg=''base_name'', annotation=Name(id=''str'',
      ctx=Load(), lineno=41, col_offset=51, end_lineno=41, end_col_offset=54), lineno=41,
      col_offset=40, end_lineno=41, end_col_offset=54), arg(arg=''questions'', annotation=Name(id=''Dict'',
      ctx=Load(), lineno=41, col_offset=67, end_lineno=41, end_col_offset=71), lineno=41,
      col_offset=56, end_lineno=41, end_col_offset=71), arg(arg=''llm'', annotation=Name(id=''object'',
      ctx=Load(), lineno=41, col_offset=78, end_lineno=41, end_col_offset=84), lineno=41,
      col_offset=73, end_lineno=41, end_col_offset=84), arg(arg=''prompt'', annotation=Name(id=''str'',
      ctx=Load(), lineno=41, col_offset=94, end_lineno=41, end_col_offset=97), lineno=41,
      col_offset=86, end_lineno=41, end_col_offset=97)], kwonlyargs=[], kw_defaults=[],
      defaults=[]), body=[Expr(value=Constant(value=''\n    Extracts data from a Python
      file.\n    Args:\n        file_path (str): Path to the Python file.\n        base_name
      (str): Base name of the Python file.\n        questions (Dict): Questions dictionary
      to answer about the Python file.\n        llm (object): Large Language Model
      object. If None, use the default prompt.\n        prompt (str): Prompt to use
      for the Large Language Model.\n    Returns:\n        Tuple[Union[Dict, Tuple],
      List[Dict], List[Dict]]: File details dictionary or tuple of file details and
      None, instruct.json dataset.\n    '', lineno=42, col_offset=4, end_lineno=52,
      end_col_offset=7), lineno=42, col_offset=4, end_lineno=52, end_col_offset=7),
      Assign(targets=[Tuple(elts=[Name(id=''file_details'', ctx=Store(), lineno=53,
      col_offset=4, end_lineno=53, end_col_offset=16), Name(id=''instruct_list'',
      ctx=Store(), lineno=53, col_offset=18, end_lineno=53, end_col_offset=31)], ctx=Store(),
      lineno=53, col_offset=4, end_lineno=53, end_col_offset=31)], value=Tuple(elts=[Constant(value=None,
      lineno=53, col_offset=34, end_lineno=53, end_col_offset=38), Constant(value=None,
      lineno=53, col_offset=40, end_lineno=53, end_col_offset=44)], ctx=Load(), lineno=53,
      col_offset=34, end_lineno=53, end_col_offset=44), lineno=53, col_offset=4, end_lineno=53,
      end_col_offset=44), Assign(targets=[Name(id=''file_details'', ctx=Store(), lineno=55,
      col_offset=4, end_lineno=55, end_col_offset=16)], value=Call(func=Name(id=''get_python_file_details'',
      ctx=Load(), lineno=55, col_offset=19, end_lineno=55, end_col_offset=42), args=[Name(id=''file_path'',
      ctx=Load(), lineno=55, col_offset=43, end_lineno=55, end_col_offset=52)], keywords=[],
      lineno=55, col_offset=19, end_lineno=55, end_col_offset=53), lineno=55, col_offset=4,
      end_lineno=55, end_col_offset=53), If(test=BoolOp(op=Or(), values=[Compare(left=Name(id=''file_details'',
      ctx=Load(), lineno=56, col_offset=7, end_lineno=56, end_col_offset=19), ops=[Is()],
      comparators=[Constant(value=None, lineno=56, col_offset=23, end_lineno=56, end_col_offset=27)],
      lineno=56, col_offset=7, end_lineno=56, end_col_offset=27), Call(func=Name(id=''isinstance'',
      ctx=Load(), lineno=56, col_offset=31, end_lineno=56, end_col_offset=41), args=[Name(id=''file_details'',
      ctx=Load(), lineno=56, col_offset=42, end_lineno=56, end_col_offset=54), Name(id=''tuple'',
      ctx=Load(), lineno=56, col_offset=56, end_lineno=56, end_col_offset=61)], keywords=[],
      lineno=56, col_offset=31, end_lineno=56, end_col_offset=62)], lineno=56, col_offset=7,
      end_lineno=56, end_col_offset=62), body=[Return(value=Tuple(elts=[Name(id=''file_details'',
      ctx=Load(), lineno=57, col_offset=15, end_lineno=57, end_col_offset=27), Name(id=''instruct_list'',
      ctx=Load(), lineno=57, col_offset=29, end_lineno=57, end_col_offset=42)], ctx=Load(),
      lineno=57, col_offset=15, end_lineno=57, end_col_offset=42), lineno=57, col_offset=8,
      end_lineno=57, end_col_offset=42)], orelse=[], lineno=56, col_offset=4, end_lineno=57,
      end_col_offset=42), Assign(targets=[Name(id=''instruct_list'', ctx=Store(),
      lineno=60, col_offset=4, end_lineno=60, end_col_offset=17)], value=Call(func=Name(id=''get_python_datasets'',
      ctx=Load(), lineno=60, col_offset=20, end_lineno=60, end_col_offset=39), args=[Name(id=''file_path'',
      ctx=Load(), lineno=60, col_offset=40, end_lineno=60, end_col_offset=49), Name(id=''file_details'',
      ctx=Load(), lineno=60, col_offset=51, end_lineno=60, end_col_offset=63), Name(id=''base_name'',
      ctx=Load(), lineno=60, col_offset=65, end_lineno=60, end_col_offset=74), Name(id=''questions'',
      ctx=Load(), lineno=60, col_offset=76, end_lineno=60, end_col_offset=85), Name(id=''llm'',
      ctx=Load(), lineno=60, col_offset=87, end_lineno=60, end_col_offset=90), Name(id=''prompt'',
      ctx=Load(), lineno=60, col_offset=92, end_lineno=60, end_col_offset=98)], keywords=[],
      lineno=60, col_offset=20, end_lineno=60, end_col_offset=99), lineno=60, col_offset=4,
      end_lineno=60, end_col_offset=99), Return(value=Tuple(elts=[Name(id=''file_details'',
      ctx=Load(), lineno=61, col_offset=11, end_lineno=61, end_col_offset=23), Name(id=''instruct_list'',
      ctx=Load(), lineno=61, col_offset=25, end_lineno=61, end_col_offset=38)], ctx=Load(),
      lineno=61, col_offset=11, end_lineno=61, end_col_offset=38), lineno=61, col_offset=4,
      end_lineno=61, end_col_offset=38)], decorator_list=[], returns=Subscript(value=Name(id=''Tuple'',
      ctx=Load(), lineno=41, col_offset=102, end_lineno=41, end_col_offset=107), slice=Tuple(elts=[Subscript(value=Name(id=''Union'',
      ctx=Load(), lineno=41, col_offset=108, end_lineno=41, end_col_offset=113), slice=Tuple(elts=[Name(id=''Dict'',
      ctx=Load(), lineno=41, col_offset=114, end_lineno=41, end_col_offset=118), Name(id=''Tuple'',
      ctx=Load(), lineno=41, col_offset=120, end_lineno=41, end_col_offset=125)],
      ctx=Load(), lineno=41, col_offset=114, end_lineno=41, end_col_offset=125), ctx=Load(),
      lineno=41, col_offset=108, end_lineno=41, end_col_offset=126), Subscript(value=Name(id=''List'',
      ctx=Load(), lineno=41, col_offset=128, end_lineno=41, end_col_offset=132), slice=Name(id=''Dict'',
      ctx=Load(), lineno=41, col_offset=133, end_lineno=41, end_col_offset=137), ctx=Load(),
      lineno=41, col_offset=128, end_lineno=41, end_col_offset=138), Subscript(value=Name(id=''List'',
      ctx=Load(), lineno=41, col_offset=140, end_lineno=41, end_col_offset=144), slice=Name(id=''Dict'',
      ctx=Load(), lineno=41, col_offset=145, end_lineno=41, end_col_offset=149), ctx=Load(),
      lineno=41, col_offset=140, end_lineno=41, end_col_offset=150)], ctx=Load(),
      lineno=41, col_offset=108, end_lineno=41, end_col_offset=150), ctx=Load(), lineno=41,
      col_offset=102, end_lineno=41, end_col_offset=151), lineno=41, col_offset=0,
      end_lineno=61, end_col_offset=38)'
    function_docstring: "Extracts data from a Python file.\nArgs:\n    file_path (str):\
      \ Path to the Python file.\n    base_name (str): Base name of the Python file.\n\
      \    questions (Dict): Questions dictionary to answer about the Python file.\n\
      \    llm (object): Large Language Model object. If None, use the default prompt.\n\
      \    prompt (str): Prompt to use for the Large Language Model.\nReturns:\n \
      \   Tuple[Union[Dict, Tuple], List[Dict], List[Dict]]: File details dictionary\
      \ or tuple of file details and None, instruct.json dataset."
    function_inputs:
    - file_path
    - base_name
    - questions
    - llm
    - prompt
    function_defaults: []
    function_returns:
    - (file_details, instruct_list)
    - (file_details, instruct_list)
    function_calls:
    - get_python_file_details
    - isinstance
    - get_python_datasets
    function_call_inputs:
      get_python_file_details:
      - file_path
      isinstance:
      - file_details
      - tuple
      get_python_datasets:
      - file_path
      - file_details
      - base_name
      - questions
      - llm
      - prompt
    function_variables:
    - file_details
    - instruct_list
    function_decorators: []
    function_annotations: []
    function_properties: []
  process_single_file:
    function_name: process_single_file
    function_code: "def process_single_file(pythonfile_path, start_dir, model_config_pathname,\
      \ questions, use_llm, output_dir):\n    \"\"\"\n    Process a single Python\
      \ file to generate question-answer pairs and instructions.\n    Args:\n    \
      \    pythonfile_path (str): Path to the Python file.\n        start_dir (str):\
      \ Starting directory to search for Python files.\n        model_config_pathname\
      \ (str): Path to the model configuration file.\n        questions (Dict): Questions\
      \ dictionary to answer about the Python file.\n        use_llm (bool): If True,\
      \ use a Large Language Model for generating JSON answers.\n        output_dir\
      \ (str): Directory to write the output files.\n    Returns:\n        none\n\
      \    \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path\
      \ = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join((part for\
      \ part in relative_path.parts))\n    llm, prompt = get_model(model_config_pathname)\
      \ if use_llm else (None, '')\n    file_details, instruct_list = extract_python_data(pythonfile_path,\
      \ base_name, questions, llm, prompt)\n    if file_details is None or isinstance(file_details,\
      \ tuple):\n        return\n    save_python_data(file_details, instruct_list,\
      \ relative_path, output_dir)"
    function_ast: 'FunctionDef(name=''process_single_file'', args=arguments(posonlyargs=[],
      args=[arg(arg=''pythonfile_path'', lineno=64, col_offset=24, end_lineno=64,
      end_col_offset=39), arg(arg=''start_dir'', lineno=64, col_offset=41, end_lineno=64,
      end_col_offset=50), arg(arg=''model_config_pathname'', lineno=64, col_offset=52,
      end_lineno=64, end_col_offset=73), arg(arg=''questions'', lineno=64, col_offset=75,
      end_lineno=64, end_col_offset=84), arg(arg=''use_llm'', lineno=64, col_offset=86,
      end_lineno=64, end_col_offset=93), arg(arg=''output_dir'', lineno=64, col_offset=95,
      end_lineno=64, end_col_offset=105)], kwonlyargs=[], kw_defaults=[], defaults=[]),
      body=[Expr(value=Constant(value=''\n    Process a single Python file to generate
      question-answer pairs and instructions.\n    Args:\n        pythonfile_path
      (str): Path to the Python file.\n        start_dir (str): Starting directory
      to search for Python files.\n        model_config_pathname (str): Path to the
      model configuration file.\n        questions (Dict): Questions dictionary to
      answer about the Python file.\n        use_llm (bool): If True, use a Large
      Language Model for generating JSON answers.\n        output_dir (str): Directory
      to write the output files.\n    Returns:\n        none\n    '', lineno=65, col_offset=4,
      end_lineno=76, end_col_offset=7), lineno=65, col_offset=4, end_lineno=76, end_col_offset=7),
      Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load(), lineno=77,
      col_offset=4, end_lineno=77, end_col_offset=11), attr=''info'', ctx=Load(),
      lineno=77, col_offset=4, end_lineno=77, end_col_offset=16), args=[JoinedStr(values=[Constant(value=''Processing:
      '', lineno=77, col_offset=17, end_lineno=77, end_col_offset=49), FormattedValue(value=Name(id=''pythonfile_path'',
      ctx=Load(), lineno=77, col_offset=32, end_lineno=77, end_col_offset=47), conversion=-1,
      lineno=77, col_offset=17, end_lineno=77, end_col_offset=49)], lineno=77, col_offset=17,
      end_lineno=77, end_col_offset=49)], keywords=[], lineno=77, col_offset=4, end_lineno=77,
      end_col_offset=50), lineno=77, col_offset=4, end_lineno=77, end_col_offset=50),
      Assign(targets=[Name(id=''relative_path'', ctx=Store(), lineno=78, col_offset=4,
      end_lineno=78, end_col_offset=17)], value=Call(func=Attribute(value=Name(id=''pythonfile_path'',
      ctx=Load(), lineno=78, col_offset=20, end_lineno=78, end_col_offset=35), attr=''relative_to'',
      ctx=Load(), lineno=78, col_offset=20, end_lineno=78, end_col_offset=47), args=[Name(id=''start_dir'',
      ctx=Load(), lineno=78, col_offset=48, end_lineno=78, end_col_offset=57)], keywords=[],
      lineno=78, col_offset=20, end_lineno=78, end_col_offset=58), lineno=78, col_offset=4,
      end_lineno=78, end_col_offset=58), Assign(targets=[Name(id=''base_name'', ctx=Store(),
      lineno=79, col_offset=4, end_lineno=79, end_col_offset=13)], value=Call(func=Attribute(value=Constant(value=''.'',
      lineno=79, col_offset=16, end_lineno=79, end_col_offset=19), attr=''join'',
      ctx=Load(), lineno=79, col_offset=16, end_lineno=79, end_col_offset=24), args=[GeneratorExp(elt=Name(id=''part'',
      ctx=Load(), lineno=79, col_offset=25, end_lineno=79, end_col_offset=29), generators=[comprehension(target=Name(id=''part'',
      ctx=Store(), lineno=79, col_offset=34, end_lineno=79, end_col_offset=38), iter=Attribute(value=Name(id=''relative_path'',
      ctx=Load(), lineno=79, col_offset=42, end_lineno=79, end_col_offset=55), attr=''parts'',
      ctx=Load(), lineno=79, col_offset=42, end_lineno=79, end_col_offset=61), ifs=[],
      is_async=0)], lineno=79, col_offset=24, end_lineno=79, end_col_offset=62)],
      keywords=[], lineno=79, col_offset=16, end_lineno=79, end_col_offset=62), lineno=79,
      col_offset=4, end_lineno=79, end_col_offset=62), Assign(targets=[Tuple(elts=[Name(id=''llm'',
      ctx=Store(), lineno=83, col_offset=4, end_lineno=83, end_col_offset=7), Name(id=''prompt'',
      ctx=Store(), lineno=83, col_offset=9, end_lineno=83, end_col_offset=15)], ctx=Store(),
      lineno=83, col_offset=4, end_lineno=83, end_col_offset=15)], value=IfExp(test=Name(id=''use_llm'',
      ctx=Load(), lineno=83, col_offset=54, end_lineno=83, end_col_offset=61), body=Call(func=Name(id=''get_model'',
      ctx=Load(), lineno=83, col_offset=18, end_lineno=83, end_col_offset=27), args=[Name(id=''model_config_pathname'',
      ctx=Load(), lineno=83, col_offset=28, end_lineno=83, end_col_offset=49)], keywords=[],
      lineno=83, col_offset=18, end_lineno=83, end_col_offset=50), orelse=Tuple(elts=[Constant(value=None,
      lineno=83, col_offset=68, end_lineno=83, end_col_offset=72), Constant(value='''',
      lineno=83, col_offset=74, end_lineno=83, end_col_offset=76)], ctx=Load(), lineno=83,
      col_offset=67, end_lineno=83, end_col_offset=77), lineno=83, col_offset=18,
      end_lineno=83, end_col_offset=77), lineno=83, col_offset=4, end_lineno=83, end_col_offset=77),
      Assign(targets=[Tuple(elts=[Name(id=''file_details'', ctx=Store(), lineno=86,
      col_offset=4, end_lineno=86, end_col_offset=16), Name(id=''instruct_list'',
      ctx=Store(), lineno=86, col_offset=18, end_lineno=86, end_col_offset=31)], ctx=Store(),
      lineno=86, col_offset=4, end_lineno=86, end_col_offset=31)], value=Call(func=Name(id=''extract_python_data'',
      ctx=Load(), lineno=86, col_offset=34, end_lineno=86, end_col_offset=53), args=[Name(id=''pythonfile_path'',
      ctx=Load(), lineno=86, col_offset=54, end_lineno=86, end_col_offset=69), Name(id=''base_name'',
      ctx=Load(), lineno=86, col_offset=71, end_lineno=86, end_col_offset=80), Name(id=''questions'',
      ctx=Load(), lineno=86, col_offset=82, end_lineno=86, end_col_offset=91), Name(id=''llm'',
      ctx=Load(), lineno=86, col_offset=93, end_lineno=86, end_col_offset=96), Name(id=''prompt'',
      ctx=Load(), lineno=86, col_offset=98, end_lineno=86, end_col_offset=104)], keywords=[],
      lineno=86, col_offset=34, end_lineno=86, end_col_offset=105), lineno=86, col_offset=4,
      end_lineno=86, end_col_offset=105), If(test=BoolOp(op=Or(), values=[Compare(left=Name(id=''file_details'',
      ctx=Load(), lineno=87, col_offset=7, end_lineno=87, end_col_offset=19), ops=[Is()],
      comparators=[Constant(value=None, lineno=87, col_offset=23, end_lineno=87, end_col_offset=27)],
      lineno=87, col_offset=7, end_lineno=87, end_col_offset=27), Call(func=Name(id=''isinstance'',
      ctx=Load(), lineno=87, col_offset=31, end_lineno=87, end_col_offset=41), args=[Name(id=''file_details'',
      ctx=Load(), lineno=87, col_offset=42, end_lineno=87, end_col_offset=54), Name(id=''tuple'',
      ctx=Load(), lineno=87, col_offset=56, end_lineno=87, end_col_offset=61)], keywords=[],
      lineno=87, col_offset=31, end_lineno=87, end_col_offset=62)], lineno=87, col_offset=7,
      end_lineno=87, end_col_offset=62), body=[Return(lineno=88, col_offset=8, end_lineno=88,
      end_col_offset=14)], orelse=[], lineno=87, col_offset=4, end_lineno=88, end_col_offset=14),
      Expr(value=Call(func=Name(id=''save_python_data'', ctx=Load(), lineno=89, col_offset=4,
      end_lineno=89, end_col_offset=20), args=[Name(id=''file_details'', ctx=Load(),
      lineno=89, col_offset=21, end_lineno=89, end_col_offset=33), Name(id=''instruct_list'',
      ctx=Load(), lineno=89, col_offset=35, end_lineno=89, end_col_offset=48), Name(id=''relative_path'',
      ctx=Load(), lineno=89, col_offset=50, end_lineno=89, end_col_offset=63), Name(id=''output_dir'',
      ctx=Load(), lineno=89, col_offset=65, end_lineno=89, end_col_offset=75)], keywords=[],
      lineno=89, col_offset=4, end_lineno=89, end_col_offset=76), lineno=89, col_offset=4,
      end_lineno=89, end_col_offset=76)], decorator_list=[], lineno=64, col_offset=0,
      end_lineno=89, end_col_offset=76)'
    function_docstring: "Process a single Python file to generate question-answer\
      \ pairs and instructions.\nArgs:\n    pythonfile_path (str): Path to the Python\
      \ file.\n    start_dir (str): Starting directory to search for Python files.\n\
      \    model_config_pathname (str): Path to the model configuration file.\n  \
      \  questions (Dict): Questions dictionary to answer about the Python file.\n\
      \    use_llm (bool): If True, use a Large Language Model for generating JSON\
      \ answers.\n    output_dir (str): Directory to write the output files.\nReturns:\n\
      \    none"
    function_inputs:
    - pythonfile_path
    - start_dir
    - model_config_pathname
    - questions
    - use_llm
    - output_dir
    function_defaults: []
    function_returns:
    - None
    function_calls:
    - logging.info
    - pythonfile_path.relative_to
    - '''.''.join'
    - get_model
    - extract_python_data
    - isinstance
    - save_python_data
    function_call_inputs:
      logging.info:
      - 'f''Processing: {pythonfile_path}'''
      pythonfile_path.relative_to:
      - start_dir
      '''.''.join':
      - (part for part in relative_path.parts)
      get_model:
      - model_config_pathname
      extract_python_data:
      - pythonfile_path
      - base_name
      - questions
      - llm
      - prompt
      isinstance:
      - file_details
      - tuple
      save_python_data:
      - file_details
      - instruct_list
      - relative_path
      - output_dir
    function_variables:
    - base_name
    - relative_path
    function_decorators: []
    function_annotations: []
    function_properties: []
  process_python_directories:
    function_name: process_python_directories
    function_code: "def process_python_directories(start_dir: str, output_dir: str,\
      \ model_config_pathname: str, questions: Dict, use_llm: bool) -> Dict[str, List[Dict]]:\n\
      \    \"\"\"\n    Processes all Python files in the provided directory and subdirectories.\n\
      \    Args:\n        start_dir (str): Starting directory to search for Python\
      \ files.\n        output_dir (str): Directory to write the output files.\n \
      \       model_config_pathname (str): Path to the model configuration file.\n\
      \        questions (Dict): Questions dictionary to answer about each Python\
      \ file.\n        use_llm (bool): If True, use the LLM model to generate answers\
      \ for JSON..\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n\
      \    \"\"\"\n    datasets = {}\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n\
      \        if pythonfile_path.is_dir():\n            continue\n        proc =\
      \ Process(target=process_single_file, args=(pythonfile_path, start_dir, model_config_pathname,\
      \ questions, use_llm, output_dir))\n        proc.start()\n        proc.join()\n\
      \    datasets = combine_json_files(output_dir)\n    return datasets"
    function_ast: 'FunctionDef(name=''process_python_directories'', args=arguments(posonlyargs=[],
      args=[arg(arg=''start_dir'', annotation=Name(id=''str'', ctx=Load(), lineno=92,
      col_offset=42, end_lineno=92, end_col_offset=45), lineno=92, col_offset=31,
      end_lineno=92, end_col_offset=45), arg(arg=''output_dir'', annotation=Name(id=''str'',
      ctx=Load(), lineno=92, col_offset=59, end_lineno=92, end_col_offset=62), lineno=92,
      col_offset=47, end_lineno=92, end_col_offset=62), arg(arg=''model_config_pathname'',
      annotation=Name(id=''str'', ctx=Load(), lineno=92, col_offset=87, end_lineno=92,
      end_col_offset=90), lineno=92, col_offset=64, end_lineno=92, end_col_offset=90),
      arg(arg=''questions'', annotation=Name(id=''Dict'', ctx=Load(), lineno=92, col_offset=103,
      end_lineno=92, end_col_offset=107), lineno=92, col_offset=92, end_lineno=92,
      end_col_offset=107), arg(arg=''use_llm'', annotation=Name(id=''bool'', ctx=Load(),
      lineno=93, col_offset=40, end_lineno=93, end_col_offset=44), lineno=93, col_offset=31,
      end_lineno=93, end_col_offset=44)], kwonlyargs=[], kw_defaults=[], defaults=[]),
      body=[Expr(value=Constant(value=''\n    Processes all Python files in the provided
      directory and subdirectories.\n    Args:\n        start_dir (str): Starting
      directory to search for Python files.\n        output_dir (str): Directory to
      write the output files.\n        model_config_pathname (str): Path to the model
      configuration file.\n        questions (Dict): Questions dictionary to answer
      about each Python file.\n        use_llm (bool): If True, use the LLM model
      to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]:
      Datasets dictionary.\n    '', lineno=94, col_offset=4, end_lineno=104, end_col_offset=7),
      lineno=94, col_offset=4, end_lineno=104, end_col_offset=7), Assign(targets=[Name(id=''datasets'',
      ctx=Store(), lineno=105, col_offset=4, end_lineno=105, end_col_offset=12)],
      value=Dict(keys=[], values=[], lineno=105, col_offset=15, end_lineno=105, end_col_offset=17),
      lineno=105, col_offset=4, end_lineno=105, end_col_offset=17), For(target=Name(id=''pythonfile_path'',
      ctx=Store(), lineno=106, col_offset=8, end_lineno=106, end_col_offset=23), iter=Call(func=Attribute(value=Call(func=Name(id=''Path'',
      ctx=Load(), lineno=106, col_offset=27, end_lineno=106, end_col_offset=31), args=[Name(id=''start_dir'',
      ctx=Load(), lineno=106, col_offset=32, end_lineno=106, end_col_offset=41)],
      keywords=[], lineno=106, col_offset=27, end_lineno=106, end_col_offset=42),
      attr=''rglob'', ctx=Load(), lineno=106, col_offset=27, end_lineno=106, end_col_offset=48),
      args=[Constant(value=''[!_]*.py'', lineno=106, col_offset=49, end_lineno=106,
      end_col_offset=59)], keywords=[], lineno=106, col_offset=27, end_lineno=106,
      end_col_offset=60), body=[If(test=Call(func=Attribute(value=Name(id=''pythonfile_path'',
      ctx=Load(), lineno=108, col_offset=11, end_lineno=108, end_col_offset=26), attr=''is_dir'',
      ctx=Load(), lineno=108, col_offset=11, end_lineno=108, end_col_offset=33), args=[],
      keywords=[], lineno=108, col_offset=11, end_lineno=108, end_col_offset=35),
      body=[Continue(lineno=109, col_offset=12, end_lineno=109, end_col_offset=20)],
      orelse=[], lineno=108, col_offset=8, end_lineno=109, end_col_offset=20), Assign(targets=[Name(id=''proc'',
      ctx=Store(), lineno=112, col_offset=8, end_lineno=112, end_col_offset=12)],
      value=Call(func=Name(id=''Process'', ctx=Load(), lineno=112, col_offset=15,
      end_lineno=112, end_col_offset=22), args=[], keywords=[keyword(arg=''target'',
      value=Name(id=''process_single_file'', ctx=Load(), lineno=112, col_offset=30,
      end_lineno=112, end_col_offset=49), lineno=112, col_offset=23, end_lineno=112,
      end_col_offset=49), keyword(arg=''args'', value=Tuple(elts=[Name(id=''pythonfile_path'',
      ctx=Load(), lineno=112, col_offset=57, end_lineno=112, end_col_offset=72), Name(id=''start_dir'',
      ctx=Load(), lineno=112, col_offset=74, end_lineno=112, end_col_offset=83), Name(id=''model_config_pathname'',
      ctx=Load(), lineno=112, col_offset=85, end_lineno=112, end_col_offset=106),
      Name(id=''questions'', ctx=Load(), lineno=112, col_offset=108, end_lineno=112,
      end_col_offset=117), Name(id=''use_llm'', ctx=Load(), lineno=112, col_offset=119,
      end_lineno=112, end_col_offset=126), Name(id=''output_dir'', ctx=Load(), lineno=112,
      col_offset=128, end_lineno=112, end_col_offset=138)], ctx=Load(), lineno=112,
      col_offset=56, end_lineno=112, end_col_offset=139), lineno=112, col_offset=51,
      end_lineno=112, end_col_offset=139)], lineno=112, col_offset=15, end_lineno=112,
      end_col_offset=140), lineno=112, col_offset=8, end_lineno=112, end_col_offset=140),
      Expr(value=Call(func=Attribute(value=Name(id=''proc'', ctx=Load(), lineno=113,
      col_offset=8, end_lineno=113, end_col_offset=12), attr=''start'', ctx=Load(),
      lineno=113, col_offset=8, end_lineno=113, end_col_offset=18), args=[], keywords=[],
      lineno=113, col_offset=8, end_lineno=113, end_col_offset=20), lineno=113, col_offset=8,
      end_lineno=113, end_col_offset=20), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
      ctx=Load(), lineno=114, col_offset=8, end_lineno=114, end_col_offset=12), attr=''join'',
      ctx=Load(), lineno=114, col_offset=8, end_lineno=114, end_col_offset=17), args=[],
      keywords=[], lineno=114, col_offset=8, end_lineno=114, end_col_offset=19), lineno=114,
      col_offset=8, end_lineno=114, end_col_offset=19)], orelse=[], lineno=106, col_offset=4,
      end_lineno=114, end_col_offset=19), Assign(targets=[Name(id=''datasets'', ctx=Store(),
      lineno=117, col_offset=4, end_lineno=117, end_col_offset=12)], value=Call(func=Name(id=''combine_json_files'',
      ctx=Load(), lineno=117, col_offset=15, end_lineno=117, end_col_offset=33), args=[Name(id=''output_dir'',
      ctx=Load(), lineno=117, col_offset=34, end_lineno=117, end_col_offset=44)],
      keywords=[], lineno=117, col_offset=15, end_lineno=117, end_col_offset=45),
      lineno=117, col_offset=4, end_lineno=117, end_col_offset=45), Return(value=Name(id=''datasets'',
      ctx=Load(), lineno=118, col_offset=11, end_lineno=118, end_col_offset=19), lineno=118,
      col_offset=4, end_lineno=118, end_col_offset=19)], decorator_list=[], returns=Subscript(value=Name(id=''Dict'',
      ctx=Load(), lineno=93, col_offset=49, end_lineno=93, end_col_offset=53), slice=Tuple(elts=[Name(id=''str'',
      ctx=Load(), lineno=93, col_offset=54, end_lineno=93, end_col_offset=57), Subscript(value=Name(id=''List'',
      ctx=Load(), lineno=93, col_offset=59, end_lineno=93, end_col_offset=63), slice=Name(id=''Dict'',
      ctx=Load(), lineno=93, col_offset=64, end_lineno=93, end_col_offset=68), ctx=Load(),
      lineno=93, col_offset=59, end_lineno=93, end_col_offset=69)], ctx=Load(), lineno=93,
      col_offset=54, end_lineno=93, end_col_offset=69), ctx=Load(), lineno=93, col_offset=49,
      end_lineno=93, end_col_offset=70), lineno=92, col_offset=0, end_lineno=118,
      end_col_offset=19)'
    function_docstring: "Processes all Python files in the provided directory and\
      \ subdirectories.\nArgs:\n    start_dir (str): Starting directory to search\
      \ for Python files.\n    output_dir (str): Directory to write the output files.\n\
      \    model_config_pathname (str): Path to the model configuration file.\n  \
      \  questions (Dict): Questions dictionary to answer about each Python file.\n\
      \    use_llm (bool): If True, use the LLM model to generate answers for JSON..\n\
      Returns:\n    Dict[str, List[Dict]]: Datasets dictionary."
    function_inputs:
    - start_dir
    - output_dir
    - model_config_pathname
    - questions
    - use_llm
    function_defaults: []
    function_returns:
    - datasets
    function_calls:
    - Path(start_dir).rglob
    - Path
    - pythonfile_path.is_dir
    - Process
    - proc.start
    - proc.join
    - combine_json_files
    function_call_inputs:
      Path(start_dir).rglob:
      - '''[!_]*.py'''
      Path:
      - start_dir
      pythonfile_path.is_dir: []
      Process: []
      proc.start: []
      proc.join: []
      combine_json_files:
      - output_dir
    function_variables:
    - proc
    - datasets
    function_decorators: []
    function_annotations: []
    function_properties: []
  py2dataset:
    function_name: py2dataset
    function_code: "def py2dataset(start_dir: str='', output_dir: str='', questions_pathname:\
      \ str='', model_config_pathname: str='', use_llm: bool=False, quiet: bool=False)\
      \ -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process Python files to generate\
      \ question-answer pairs and instructions.\n    Args:\n        start_dir (str,\
      \ optional): Starting directory to search for Python files. Defaults to current\
      \ working directory.\n        output_dir (str, optional): Directory to write\
      \ the output files.\n        questions_pathname (str, optional): Path to the\
      \ questions file.\n        model_config_pathname (str, optional): Path to the\
      \ model configuration file.\n        use_llm (bool, optional): If True, use\
      \ a Large Language Model for generating JSON answers. Defaults to False.\n \
      \       quiet (bool, optional): Limit logging output. Defaults to False.\n \
      \   Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\
      \n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n   \
      \ else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\n\
      \    if start_dir == '':\n        logging.info('No valid start path provided.\
      \ Using current working directory.')\n        start_dir = os.getcwd()\n    start_dir\
      \ = os.path.abspath(start_dir)\n    output_dir = get_output_dir(output_dir)\n\
      \    questions = get_questions(questions_pathname)\n    datasets = process_python_directories(start_dir,\
      \ output_dir, model_config_pathname, questions, use_llm)\n    return datasets"
    function_ast: 'FunctionDef(name=''py2dataset'', args=arguments(posonlyargs=[],
      args=[arg(arg=''start_dir'', annotation=Name(id=''str'', ctx=Load(), lineno=121,
      col_offset=26, end_lineno=121, end_col_offset=29), lineno=121, col_offset=15,
      end_lineno=121, end_col_offset=29), arg(arg=''output_dir'', annotation=Name(id=''str'',
      ctx=Load(), lineno=121, col_offset=48, end_lineno=121, end_col_offset=51), lineno=121,
      col_offset=36, end_lineno=121, end_col_offset=51), arg(arg=''questions_pathname'',
      annotation=Name(id=''str'', ctx=Load(), lineno=121, col_offset=78, end_lineno=121,
      end_col_offset=81), lineno=121, col_offset=58, end_lineno=121, end_col_offset=81),
      arg(arg=''model_config_pathname'', annotation=Name(id=''str'', ctx=Load(), lineno=121,
      col_offset=111, end_lineno=121, end_col_offset=114), lineno=121, col_offset=88,
      end_lineno=121, end_col_offset=114), arg(arg=''use_llm'', annotation=Name(id=''bool'',
      ctx=Load(), lineno=122, col_offset=24, end_lineno=122, end_col_offset=28), lineno=122,
      col_offset=15, end_lineno=122, end_col_offset=28), arg(arg=''quiet'', annotation=Name(id=''bool'',
      ctx=Load(), lineno=122, col_offset=45, end_lineno=122, end_col_offset=49), lineno=122,
      col_offset=38, end_lineno=122, end_col_offset=49)], kwonlyargs=[], kw_defaults=[],
      defaults=[Constant(value='''', lineno=121, col_offset=32, end_lineno=121, end_col_offset=34),
      Constant(value='''', lineno=121, col_offset=54, end_lineno=121, end_col_offset=56),
      Constant(value='''', lineno=121, col_offset=84, end_lineno=121, end_col_offset=86),
      Constant(value='''', lineno=121, col_offset=117, end_lineno=121, end_col_offset=119),
      Constant(value=False, lineno=122, col_offset=31, end_lineno=122, end_col_offset=36),
      Constant(value=False, lineno=122, col_offset=52, end_lineno=122, end_col_offset=57)]),
      body=[Expr(value=Constant(value=''\n    Process Python files to generate question-answer
      pairs and instructions.\n    Args:\n        start_dir (str, optional): Starting
      directory to search for Python files. Defaults to current working directory.\n        output_dir
      (str, optional): Directory to write the output files.\n        questions_pathname
      (str, optional): Path to the questions file.\n        model_config_pathname
      (str, optional): Path to the model configuration file.\n        use_llm (bool,
      optional): If True, use a Large Language Model for generating JSON answers.
      Defaults to False.\n        quiet (bool, optional): Limit logging output. Defaults
      to False.\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    '',
      lineno=123, col_offset=4, end_lineno=134, end_col_offset=7), lineno=123, col_offset=4,
      end_lineno=134, end_col_offset=7), If(test=Name(id=''quiet'', ctx=Load(), lineno=135,
      col_offset=7, end_lineno=135, end_col_offset=12), body=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load(), lineno=136, col_offset=8, end_lineno=136, end_col_offset=15), attr=''getLogger'',
      ctx=Load(), lineno=136, col_offset=8, end_lineno=136, end_col_offset=25), args=[],
      keywords=[], lineno=136, col_offset=8, end_lineno=136, end_col_offset=27), attr=''setLevel'',
      ctx=Load(), lineno=136, col_offset=8, end_lineno=136, end_col_offset=36), args=[Attribute(value=Name(id=''logging'',
      ctx=Load(), lineno=136, col_offset=37, end_lineno=136, end_col_offset=44), attr=''WARNING'',
      ctx=Load(), lineno=136, col_offset=37, end_lineno=136, end_col_offset=52)],
      keywords=[], lineno=136, col_offset=8, end_lineno=136, end_col_offset=53), lineno=136,
      col_offset=8, end_lineno=136, end_col_offset=53)], orelse=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load(), lineno=138, col_offset=8, end_lineno=138, end_col_offset=15), attr=''getLogger'',
      ctx=Load(), lineno=138, col_offset=8, end_lineno=138, end_col_offset=25), args=[],
      keywords=[], lineno=138, col_offset=8, end_lineno=138, end_col_offset=27), attr=''setLevel'',
      ctx=Load(), lineno=138, col_offset=8, end_lineno=138, end_col_offset=36), args=[Attribute(value=Name(id=''logging'',
      ctx=Load(), lineno=138, col_offset=37, end_lineno=138, end_col_offset=44), attr=''INFO'',
      ctx=Load(), lineno=138, col_offset=37, end_lineno=138, end_col_offset=49)],
      keywords=[], lineno=138, col_offset=8, end_lineno=138, end_col_offset=50), lineno=138,
      col_offset=8, end_lineno=138, end_col_offset=50)], lineno=135, col_offset=4,
      end_lineno=138, end_col_offset=50), Expr(value=Call(func=Attribute(value=Name(id=''sys'',
      ctx=Load(), lineno=139, col_offset=4, end_lineno=139, end_col_offset=7), attr=''setrecursionlimit'',
      ctx=Load(), lineno=139, col_offset=4, end_lineno=139, end_col_offset=25), args=[Constant(value=3000,
      lineno=139, col_offset=26, end_lineno=139, end_col_offset=30)], keywords=[],
      lineno=139, col_offset=4, end_lineno=139, end_col_offset=31), lineno=139, col_offset=4,
      end_lineno=139, end_col_offset=31), If(test=Compare(left=Name(id=''start_dir'',
      ctx=Load(), lineno=142, col_offset=7, end_lineno=142, end_col_offset=16), ops=[Eq()],
      comparators=[Constant(value='''', lineno=142, col_offset=20, end_lineno=142,
      end_col_offset=22)], lineno=142, col_offset=7, end_lineno=142, end_col_offset=22),
      body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load(),
      lineno=143, col_offset=8, end_lineno=143, end_col_offset=15), attr=''info'',
      ctx=Load(), lineno=143, col_offset=8, end_lineno=143, end_col_offset=20), args=[Constant(value=''No
      valid start path provided. Using current working directory.'', lineno=143, col_offset=21,
      end_lineno=143, end_col_offset=85)], keywords=[], lineno=143, col_offset=8,
      end_lineno=143, end_col_offset=86), lineno=143, col_offset=8, end_lineno=143,
      end_col_offset=86), Assign(targets=[Name(id=''start_dir'', ctx=Store(), lineno=144,
      col_offset=8, end_lineno=144, end_col_offset=17)], value=Call(func=Attribute(value=Name(id=''os'',
      ctx=Load(), lineno=144, col_offset=20, end_lineno=144, end_col_offset=22), attr=''getcwd'',
      ctx=Load(), lineno=144, col_offset=20, end_lineno=144, end_col_offset=29), args=[],
      keywords=[], lineno=144, col_offset=20, end_lineno=144, end_col_offset=31),
      lineno=144, col_offset=8, end_lineno=144, end_col_offset=31)], orelse=[], lineno=142,
      col_offset=4, end_lineno=144, end_col_offset=31), Assign(targets=[Name(id=''start_dir'',
      ctx=Store(), lineno=145, col_offset=4, end_lineno=145, end_col_offset=13)],
      value=Call(func=Attribute(value=Attribute(value=Name(id=''os'', ctx=Load(),
      lineno=145, col_offset=16, end_lineno=145, end_col_offset=18), attr=''path'',
      ctx=Load(), lineno=145, col_offset=16, end_lineno=145, end_col_offset=23), attr=''abspath'',
      ctx=Load(), lineno=145, col_offset=16, end_lineno=145, end_col_offset=31), args=[Name(id=''start_dir'',
      ctx=Load(), lineno=145, col_offset=32, end_lineno=145, end_col_offset=41)],
      keywords=[], lineno=145, col_offset=16, end_lineno=145, end_col_offset=42),
      lineno=145, col_offset=4, end_lineno=145, end_col_offset=42), Assign(targets=[Name(id=''output_dir'',
      ctx=Store(), lineno=147, col_offset=4, end_lineno=147, end_col_offset=14)],
      value=Call(func=Name(id=''get_output_dir'', ctx=Load(), lineno=147, col_offset=17,
      end_lineno=147, end_col_offset=31), args=[Name(id=''output_dir'', ctx=Load(),
      lineno=147, col_offset=32, end_lineno=147, end_col_offset=42)], keywords=[],
      lineno=147, col_offset=17, end_lineno=147, end_col_offset=43), lineno=147, col_offset=4,
      end_lineno=147, end_col_offset=43), Assign(targets=[Name(id=''questions'', ctx=Store(),
      lineno=148, col_offset=4, end_lineno=148, end_col_offset=13)], value=Call(func=Name(id=''get_questions'',
      ctx=Load(), lineno=148, col_offset=16, end_lineno=148, end_col_offset=29), args=[Name(id=''questions_pathname'',
      ctx=Load(), lineno=148, col_offset=30, end_lineno=148, end_col_offset=48)],
      keywords=[], lineno=148, col_offset=16, end_lineno=148, end_col_offset=49),
      lineno=148, col_offset=4, end_lineno=148, end_col_offset=49), Assign(targets=[Name(id=''datasets'',
      ctx=Store(), lineno=150, col_offset=4, end_lineno=150, end_col_offset=12)],
      value=Call(func=Name(id=''process_python_directories'', ctx=Load(), lineno=150,
      col_offset=15, end_lineno=150, end_col_offset=41), args=[Name(id=''start_dir'',
      ctx=Load(), lineno=150, col_offset=42, end_lineno=150, end_col_offset=51), Name(id=''output_dir'',
      ctx=Load(), lineno=150, col_offset=53, end_lineno=150, end_col_offset=63), Name(id=''model_config_pathname'',
      ctx=Load(), lineno=150, col_offset=65, end_lineno=150, end_col_offset=86), Name(id=''questions'',
      ctx=Load(), lineno=150, col_offset=88, end_lineno=150, end_col_offset=97), Name(id=''use_llm'',
      ctx=Load(), lineno=150, col_offset=99, end_lineno=150, end_col_offset=106)],
      keywords=[], lineno=150, col_offset=15, end_lineno=150, end_col_offset=107),
      lineno=150, col_offset=4, end_lineno=150, end_col_offset=107), Return(value=Name(id=''datasets'',
      ctx=Load(), lineno=151, col_offset=11, end_lineno=151, end_col_offset=19), lineno=151,
      col_offset=4, end_lineno=151, end_col_offset=19)], decorator_list=[], returns=Subscript(value=Name(id=''Dict'',
      ctx=Load(), lineno=122, col_offset=62, end_lineno=122, end_col_offset=66), slice=Tuple(elts=[Name(id=''str'',
      ctx=Load(), lineno=122, col_offset=67, end_lineno=122, end_col_offset=70), Subscript(value=Name(id=''List'',
      ctx=Load(), lineno=122, col_offset=72, end_lineno=122, end_col_offset=76), slice=Name(id=''Dict'',
      ctx=Load(), lineno=122, col_offset=77, end_lineno=122, end_col_offset=81), ctx=Load(),
      lineno=122, col_offset=72, end_lineno=122, end_col_offset=82)], ctx=Load(),
      lineno=122, col_offset=67, end_lineno=122, end_col_offset=82), ctx=Load(), lineno=122,
      col_offset=62, end_lineno=122, end_col_offset=83), lineno=121, col_offset=0,
      end_lineno=151, end_col_offset=19)'
    function_docstring: "Process Python files to generate question-answer pairs and\
      \ instructions.\nArgs:\n    start_dir (str, optional): Starting directory to\
      \ search for Python files. Defaults to current working directory.\n    output_dir\
      \ (str, optional): Directory to write the output files.\n    questions_pathname\
      \ (str, optional): Path to the questions file.\n    model_config_pathname (str,\
      \ optional): Path to the model configuration file.\n    use_llm (bool, optional):\
      \ If True, use a Large Language Model for generating JSON answers. Defaults\
      \ to False.\n    quiet (bool, optional): Limit logging output. Defaults to False.\n\
      Returns:\n    Dict[str, List[Dict]]: Datasets dictionary."
    function_inputs:
    - start_dir
    - output_dir
    - questions_pathname
    - model_config_pathname
    - use_llm
    - quiet
    function_defaults:
    - ''''''
    - ''''''
    - ''''''
    - ''''''
    - 'False'
    - 'False'
    function_returns:
    - datasets
    function_calls:
    - logging.getLogger().setLevel
    - logging.getLogger
    - sys.setrecursionlimit
    - logging.info
    - os.getcwd
    - os.path.abspath
    - get_output_dir
    - get_questions
    - process_python_directories
    function_call_inputs:
      logging.getLogger().setLevel:
      - logging.INFO
      logging.getLogger: []
      sys.setrecursionlimit:
      - '3000'
      logging.info:
      - '''No valid start path provided. Using current working directory.'''
      os.getcwd: []
      os.path.abspath:
      - start_dir
      get_output_dir:
      - output_dir
      get_questions:
      - questions_pathname
      process_python_directories:
      - start_dir
      - output_dir
      - model_config_pathname
      - questions
      - use_llm
    function_variables:
    - datasets
    - questions
    - start_dir
    - output_dir
    function_decorators: []
    function_annotations: []
    function_properties: []
  main:
    function_name: main
    function_code: "def main():\n    \"\"\"\n    Command-line entry point for processing\
      \ Python files and generating datasets.\n    Args:\n        --start_dir (str,\
      \ optional): Starting directory to search for Python files. Defaults to the\
      \ current working directory.\n        --output_dir (str, optional): Directory\
      \ to write the output files. Defaults to the 'datasets' directory in the current\
      \ working directory.\n        --questions_pathname (str, optional): Path to\
      \ the questions file. If not provided, defaults defined in 'get_py2dataset_params.py'\
      \ will be used.\n        --model_config_pathname (str, optional): Path to the\
      \ model configuration file. If not provided, defaults defined in 'get_py2dataset_params.py'\
      \ will be used.\n        --use_llm (bool, optional): Use a Large Language Model\
      \ for generating JSON answers. Defaults to False.\n        --quiet (bool, optional):\
      \ Limit logging output. If provided, only warnings and errors will be logged.\
      \ Defaults to False.\n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n\
      \    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname\
      \ = ''\n    use_llm = False\n    quiet = False\n    if '--start_dir' in arg_string:\n\
      \        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n   \
      \     arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n    if\
      \ '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir\
      \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir\
      \ {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n    \
      \    model_config_pathname = arg_string.split('--model_config_pathname ')[1].split('\
      \ ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}',\
      \ '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname\
      \ = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string\
      \ = arg_string.replace(f'--questions_pathname {questions_pathname}', '')\n \
      \   if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string\
      \ = arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n \
      \       quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n\
      \    py2dataset(start_dir, output_dir, questions_pathname, model_config_pathname,\
      \ use_llm, quiet)"
    function_ast: 'FunctionDef(name=''main'', args=arguments(posonlyargs=[], args=[],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value="\n    Command-line
      entry point for processing Python files and generating datasets.\n    Args:\n        --start_dir
      (str, optional): Starting directory to search for Python files. Defaults to
      the current working directory.\n        --output_dir (str, optional): Directory
      to write the output files. Defaults to the ''datasets'' directory in the current
      working directory.\n        --questions_pathname (str, optional): Path to the
      questions file. If not provided, defaults defined in ''get_py2dataset_params.py''
      will be used.\n        --model_config_pathname (str, optional): Path to the
      model configuration file. If not provided, defaults defined in ''get_py2dataset_params.py''
      will be used.\n        --use_llm (bool, optional): Use a Large Language Model
      for generating JSON answers. Defaults to False.\n        --quiet (bool, optional):
      Limit logging output. If provided, only warnings and errors will be logged.
      Defaults to False.\n    ", lineno=154, col_offset=4, end_lineno=163, end_col_offset=7),
      lineno=154, col_offset=4, end_lineno=163, end_col_offset=7), Assign(targets=[Name(id=''arg_string'',
      ctx=Store(), lineno=164, col_offset=4, end_lineno=164, end_col_offset=14)],
      value=Call(func=Attribute(value=Constant(value='' '', lineno=164, col_offset=17,
      end_lineno=164, end_col_offset=20), attr=''join'', ctx=Load(), lineno=164, col_offset=17,
      end_lineno=164, end_col_offset=25), args=[Subscript(value=Attribute(value=Name(id=''sys'',
      ctx=Load(), lineno=164, col_offset=26, end_lineno=164, end_col_offset=29), attr=''argv'',
      ctx=Load(), lineno=164, col_offset=26, end_lineno=164, end_col_offset=34), slice=Slice(lower=Constant(value=1,
      lineno=164, col_offset=35, end_lineno=164, end_col_offset=36), lineno=164, col_offset=35,
      end_lineno=164, end_col_offset=37), ctx=Load(), lineno=164, col_offset=26, end_lineno=164,
      end_col_offset=38)], keywords=[], lineno=164, col_offset=17, end_lineno=164,
      end_col_offset=39), lineno=164, col_offset=4, end_lineno=164, end_col_offset=39),
      Assign(targets=[Name(id=''start_dir'', ctx=Store(), lineno=165, col_offset=4,
      end_lineno=165, end_col_offset=13)], value=Constant(value='''', lineno=165,
      col_offset=16, end_lineno=165, end_col_offset=18), lineno=165, col_offset=4,
      end_lineno=165, end_col_offset=18), Assign(targets=[Name(id=''output_dir'',
      ctx=Store(), lineno=166, col_offset=4, end_lineno=166, end_col_offset=14)],
      value=Constant(value='''', lineno=166, col_offset=17, end_lineno=166, end_col_offset=19),
      lineno=166, col_offset=4, end_lineno=166, end_col_offset=19), Assign(targets=[Name(id=''questions_pathname'',
      ctx=Store(), lineno=167, col_offset=4, end_lineno=167, end_col_offset=22)],
      value=Constant(value='''', lineno=167, col_offset=25, end_lineno=167, end_col_offset=27),
      lineno=167, col_offset=4, end_lineno=167, end_col_offset=27), Assign(targets=[Name(id=''model_config_pathname'',
      ctx=Store(), lineno=168, col_offset=4, end_lineno=168, end_col_offset=25)],
      value=Constant(value='''', lineno=168, col_offset=28, end_lineno=168, end_col_offset=30),
      lineno=168, col_offset=4, end_lineno=168, end_col_offset=30), Assign(targets=[Name(id=''use_llm'',
      ctx=Store(), lineno=169, col_offset=4, end_lineno=169, end_col_offset=11)],
      value=Constant(value=False, lineno=169, col_offset=14, end_lineno=169, end_col_offset=19),
      lineno=169, col_offset=4, end_lineno=169, end_col_offset=19), Assign(targets=[Name(id=''quiet'',
      ctx=Store(), lineno=170, col_offset=4, end_lineno=170, end_col_offset=9)], value=Constant(value=False,
      lineno=170, col_offset=12, end_lineno=170, end_col_offset=17), lineno=170, col_offset=4,
      end_lineno=170, end_col_offset=17), If(test=Compare(left=Constant(value=''--start_dir'',
      lineno=172, col_offset=7, end_lineno=172, end_col_offset=20), ops=[In()], comparators=[Name(id=''arg_string'',
      ctx=Load(), lineno=172, col_offset=24, end_lineno=172, end_col_offset=34)],
      lineno=172, col_offset=7, end_lineno=172, end_col_offset=34), body=[Assign(targets=[Name(id=''start_dir'',
      ctx=Store(), lineno=173, col_offset=8, end_lineno=173, end_col_offset=17)],
      value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load(), lineno=173, col_offset=20, end_lineno=173, end_col_offset=30), attr=''split'',
      ctx=Load(), lineno=173, col_offset=20, end_lineno=173, end_col_offset=36), args=[Constant(value=''--start_dir
      '', lineno=173, col_offset=37, end_lineno=173, end_col_offset=51)], keywords=[],
      lineno=173, col_offset=20, end_lineno=173, end_col_offset=52), slice=Constant(value=1,
      lineno=173, col_offset=53, end_lineno=173, end_col_offset=54), ctx=Load(), lineno=173,
      col_offset=20, end_lineno=173, end_col_offset=55), attr=''split'', ctx=Load(),
      lineno=173, col_offset=20, end_lineno=173, end_col_offset=61), args=[Constant(value=''
      '', lineno=173, col_offset=62, end_lineno=173, end_col_offset=65)], keywords=[],
      lineno=173, col_offset=20, end_lineno=173, end_col_offset=66), slice=Constant(value=0,
      lineno=173, col_offset=67, end_lineno=173, end_col_offset=68), ctx=Load(), lineno=173,
      col_offset=20, end_lineno=173, end_col_offset=69), lineno=173, col_offset=8,
      end_lineno=173, end_col_offset=69), Assign(targets=[Name(id=''arg_string'',
      ctx=Store(), lineno=174, col_offset=8, end_lineno=174, end_col_offset=18)],
      value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load(), lineno=174,
      col_offset=21, end_lineno=174, end_col_offset=31), attr=''replace'', ctx=Load(),
      lineno=174, col_offset=21, end_lineno=174, end_col_offset=39), args=[JoinedStr(values=[Constant(value=''--start_dir
      '', lineno=174, col_offset=40, end_lineno=174, end_col_offset=66), FormattedValue(value=Name(id=''start_dir'',
      ctx=Load(), lineno=174, col_offset=55, end_lineno=174, end_col_offset=64), conversion=-1,
      lineno=174, col_offset=40, end_lineno=174, end_col_offset=66)], lineno=174,
      col_offset=40, end_lineno=174, end_col_offset=66), Constant(value='''', lineno=174,
      col_offset=68, end_lineno=174, end_col_offset=70)], keywords=[], lineno=174,
      col_offset=21, end_lineno=174, end_col_offset=71), lineno=174, col_offset=8,
      end_lineno=174, end_col_offset=71)], orelse=[], lineno=172, col_offset=4, end_lineno=174,
      end_col_offset=71), If(test=Compare(left=Constant(value=''--output_dir'', lineno=175,
      col_offset=7, end_lineno=175, end_col_offset=21), ops=[In()], comparators=[Name(id=''arg_string'',
      ctx=Load(), lineno=175, col_offset=25, end_lineno=175, end_col_offset=35)],
      lineno=175, col_offset=7, end_lineno=175, end_col_offset=35), body=[Assign(targets=[Name(id=''output_dir'',
      ctx=Store(), lineno=176, col_offset=8, end_lineno=176, end_col_offset=18)],
      value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load(), lineno=176, col_offset=21, end_lineno=176, end_col_offset=31), attr=''split'',
      ctx=Load(), lineno=176, col_offset=21, end_lineno=176, end_col_offset=37), args=[Constant(value=''--output_dir
      '', lineno=176, col_offset=38, end_lineno=176, end_col_offset=53)], keywords=[],
      lineno=176, col_offset=21, end_lineno=176, end_col_offset=54), slice=Constant(value=1,
      lineno=176, col_offset=55, end_lineno=176, end_col_offset=56), ctx=Load(), lineno=176,
      col_offset=21, end_lineno=176, end_col_offset=57), attr=''split'', ctx=Load(),
      lineno=176, col_offset=21, end_lineno=176, end_col_offset=63), args=[Constant(value=''
      '', lineno=176, col_offset=64, end_lineno=176, end_col_offset=67)], keywords=[],
      lineno=176, col_offset=21, end_lineno=176, end_col_offset=68), slice=Constant(value=0,
      lineno=176, col_offset=69, end_lineno=176, end_col_offset=70), ctx=Load(), lineno=176,
      col_offset=21, end_lineno=176, end_col_offset=71), lineno=176, col_offset=8,
      end_lineno=176, end_col_offset=71), Assign(targets=[Name(id=''arg_string'',
      ctx=Store(), lineno=177, col_offset=8, end_lineno=177, end_col_offset=18)],
      value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load(), lineno=177,
      col_offset=21, end_lineno=177, end_col_offset=31), attr=''replace'', ctx=Load(),
      lineno=177, col_offset=21, end_lineno=177, end_col_offset=39), args=[JoinedStr(values=[Constant(value=''--output_dir
      '', lineno=177, col_offset=40, end_lineno=177, end_col_offset=68), FormattedValue(value=Name(id=''output_dir'',
      ctx=Load(), lineno=177, col_offset=56, end_lineno=177, end_col_offset=66), conversion=-1,
      lineno=177, col_offset=40, end_lineno=177, end_col_offset=68)], lineno=177,
      col_offset=40, end_lineno=177, end_col_offset=68), Constant(value='''', lineno=177,
      col_offset=70, end_lineno=177, end_col_offset=72)], keywords=[], lineno=177,
      col_offset=21, end_lineno=177, end_col_offset=73), lineno=177, col_offset=8,
      end_lineno=177, end_col_offset=73)], orelse=[], lineno=175, col_offset=4, end_lineno=177,
      end_col_offset=73), If(test=Compare(left=Constant(value=''--model_config_pathname'',
      lineno=178, col_offset=7, end_lineno=178, end_col_offset=32), ops=[In()], comparators=[Name(id=''arg_string'',
      ctx=Load(), lineno=178, col_offset=36, end_lineno=178, end_col_offset=46)],
      lineno=178, col_offset=7, end_lineno=178, end_col_offset=46), body=[Assign(targets=[Name(id=''model_config_pathname'',
      ctx=Store(), lineno=179, col_offset=8, end_lineno=179, end_col_offset=29)],
      value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load(), lineno=179, col_offset=32, end_lineno=179, end_col_offset=42), attr=''split'',
      ctx=Load(), lineno=179, col_offset=32, end_lineno=179, end_col_offset=48), args=[Constant(value=''--model_config_pathname
      '', lineno=179, col_offset=49, end_lineno=179, end_col_offset=75)], keywords=[],
      lineno=179, col_offset=32, end_lineno=179, end_col_offset=76), slice=Constant(value=1,
      lineno=179, col_offset=77, end_lineno=179, end_col_offset=78), ctx=Load(), lineno=179,
      col_offset=32, end_lineno=179, end_col_offset=79), attr=''split'', ctx=Load(),
      lineno=179, col_offset=32, end_lineno=179, end_col_offset=85), args=[Constant(value=''
      '', lineno=179, col_offset=86, end_lineno=179, end_col_offset=89)], keywords=[],
      lineno=179, col_offset=32, end_lineno=179, end_col_offset=90), slice=Constant(value=0,
      lineno=179, col_offset=91, end_lineno=179, end_col_offset=92), ctx=Load(), lineno=179,
      col_offset=32, end_lineno=179, end_col_offset=93), lineno=179, col_offset=8,
      end_lineno=179, end_col_offset=93), Assign(targets=[Name(id=''arg_string'',
      ctx=Store(), lineno=180, col_offset=8, end_lineno=180, end_col_offset=18)],
      value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load(), lineno=180,
      col_offset=21, end_lineno=180, end_col_offset=31), attr=''replace'', ctx=Load(),
      lineno=180, col_offset=21, end_lineno=180, end_col_offset=39), args=[JoinedStr(values=[Constant(value=''--model_config_pathname
      '', lineno=180, col_offset=40, end_lineno=180, end_col_offset=90), FormattedValue(value=Name(id=''model_config_pathname'',
      ctx=Load(), lineno=180, col_offset=67, end_lineno=180, end_col_offset=88), conversion=-1,
      lineno=180, col_offset=40, end_lineno=180, end_col_offset=90)], lineno=180,
      col_offset=40, end_lineno=180, end_col_offset=90), Constant(value='''', lineno=180,
      col_offset=92, end_lineno=180, end_col_offset=94)], keywords=[], lineno=180,
      col_offset=21, end_lineno=180, end_col_offset=95), lineno=180, col_offset=8,
      end_lineno=180, end_col_offset=95)], orelse=[], lineno=178, col_offset=4, end_lineno=180,
      end_col_offset=95), If(test=Compare(left=Constant(value=''--questions_pathname'',
      lineno=181, col_offset=7, end_lineno=181, end_col_offset=29), ops=[In()], comparators=[Name(id=''arg_string'',
      ctx=Load(), lineno=181, col_offset=33, end_lineno=181, end_col_offset=43)],
      lineno=181, col_offset=7, end_lineno=181, end_col_offset=43), body=[Assign(targets=[Name(id=''questions_pathname'',
      ctx=Store(), lineno=182, col_offset=8, end_lineno=182, end_col_offset=26)],
      value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load(), lineno=182, col_offset=29, end_lineno=182, end_col_offset=39), attr=''split'',
      ctx=Load(), lineno=182, col_offset=29, end_lineno=182, end_col_offset=45), args=[Constant(value=''--questions_pathname
      '', lineno=182, col_offset=46, end_lineno=182, end_col_offset=69)], keywords=[],
      lineno=182, col_offset=29, end_lineno=182, end_col_offset=70), slice=Constant(value=1,
      lineno=182, col_offset=71, end_lineno=182, end_col_offset=72), ctx=Load(), lineno=182,
      col_offset=29, end_lineno=182, end_col_offset=73), attr=''split'', ctx=Load(),
      lineno=182, col_offset=29, end_lineno=182, end_col_offset=79), args=[Constant(value=''
      '', lineno=182, col_offset=80, end_lineno=182, end_col_offset=83)], keywords=[],
      lineno=182, col_offset=29, end_lineno=182, end_col_offset=84), slice=Constant(value=0,
      lineno=182, col_offset=85, end_lineno=182, end_col_offset=86), ctx=Load(), lineno=182,
      col_offset=29, end_lineno=182, end_col_offset=87), lineno=182, col_offset=8,
      end_lineno=182, end_col_offset=87), Assign(targets=[Name(id=''arg_string'',
      ctx=Store(), lineno=183, col_offset=8, end_lineno=183, end_col_offset=18)],
      value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load(), lineno=183,
      col_offset=21, end_lineno=183, end_col_offset=31), attr=''replace'', ctx=Load(),
      lineno=183, col_offset=21, end_lineno=183, end_col_offset=39), args=[JoinedStr(values=[Constant(value=''--questions_pathname
      '', lineno=183, col_offset=40, end_lineno=183, end_col_offset=84), FormattedValue(value=Name(id=''questions_pathname'',
      ctx=Load(), lineno=183, col_offset=64, end_lineno=183, end_col_offset=82), conversion=-1,
      lineno=183, col_offset=40, end_lineno=183, end_col_offset=84)], lineno=183,
      col_offset=40, end_lineno=183, end_col_offset=84), Constant(value='''', lineno=183,
      col_offset=86, end_lineno=183, end_col_offset=88)], keywords=[], lineno=183,
      col_offset=21, end_lineno=183, end_col_offset=89), lineno=183, col_offset=8,
      end_lineno=183, end_col_offset=89)], orelse=[], lineno=181, col_offset=4, end_lineno=183,
      end_col_offset=89), If(test=Compare(left=Constant(value=''--use_llm'', lineno=184,
      col_offset=7, end_lineno=184, end_col_offset=18), ops=[In()], comparators=[Name(id=''arg_string'',
      ctx=Load(), lineno=184, col_offset=22, end_lineno=184, end_col_offset=32)],
      lineno=184, col_offset=7, end_lineno=184, end_col_offset=32), body=[Assign(targets=[Name(id=''use_llm'',
      ctx=Store(), lineno=185, col_offset=8, end_lineno=185, end_col_offset=15)],
      value=Constant(value=True, lineno=185, col_offset=18, end_lineno=185, end_col_offset=22),
      lineno=185, col_offset=8, end_lineno=185, end_col_offset=22), Assign(targets=[Name(id=''arg_string'',
      ctx=Store(), lineno=186, col_offset=8, end_lineno=186, end_col_offset=18)],
      value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load(), lineno=186,
      col_offset=21, end_lineno=186, end_col_offset=31), attr=''replace'', ctx=Load(),
      lineno=186, col_offset=21, end_lineno=186, end_col_offset=39), args=[Constant(value=''--use_llm'',
      lineno=186, col_offset=40, end_lineno=186, end_col_offset=51), Constant(value='''',
      lineno=186, col_offset=53, end_lineno=186, end_col_offset=55)], keywords=[],
      lineno=186, col_offset=21, end_lineno=186, end_col_offset=56), lineno=186, col_offset=8,
      end_lineno=186, end_col_offset=56)], orelse=[], lineno=184, col_offset=4, end_lineno=186,
      end_col_offset=56), If(test=Compare(left=Constant(value=''--quiet'', lineno=187,
      col_offset=7, end_lineno=187, end_col_offset=16), ops=[In()], comparators=[Name(id=''arg_string'',
      ctx=Load(), lineno=187, col_offset=20, end_lineno=187, end_col_offset=30)],
      lineno=187, col_offset=7, end_lineno=187, end_col_offset=30), body=[Assign(targets=[Name(id=''quiet'',
      ctx=Store(), lineno=188, col_offset=8, end_lineno=188, end_col_offset=13)],
      value=Constant(value=True, lineno=188, col_offset=16, end_lineno=188, end_col_offset=20),
      lineno=188, col_offset=8, end_lineno=188, end_col_offset=20), Assign(targets=[Name(id=''arg_string'',
      ctx=Store(), lineno=189, col_offset=8, end_lineno=189, end_col_offset=18)],
      value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load(), lineno=189,
      col_offset=21, end_lineno=189, end_col_offset=31), attr=''replace'', ctx=Load(),
      lineno=189, col_offset=21, end_lineno=189, end_col_offset=39), args=[Constant(value=''--quiet'',
      lineno=189, col_offset=40, end_lineno=189, end_col_offset=49), Constant(value='''',
      lineno=189, col_offset=51, end_lineno=189, end_col_offset=53)], keywords=[],
      lineno=189, col_offset=21, end_lineno=189, end_col_offset=54), lineno=189, col_offset=8,
      end_lineno=189, end_col_offset=54)], orelse=[], lineno=187, col_offset=4, end_lineno=189,
      end_col_offset=54), Expr(value=Call(func=Name(id=''py2dataset'', ctx=Load(),
      lineno=191, col_offset=4, end_lineno=191, end_col_offset=14), args=[Name(id=''start_dir'',
      ctx=Load(), lineno=191, col_offset=15, end_lineno=191, end_col_offset=24), Name(id=''output_dir'',
      ctx=Load(), lineno=191, col_offset=26, end_lineno=191, end_col_offset=36), Name(id=''questions_pathname'',
      ctx=Load(), lineno=191, col_offset=38, end_lineno=191, end_col_offset=56), Name(id=''model_config_pathname'',
      ctx=Load(), lineno=191, col_offset=58, end_lineno=191, end_col_offset=79), Name(id=''use_llm'',
      ctx=Load(), lineno=191, col_offset=81, end_lineno=191, end_col_offset=88), Name(id=''quiet'',
      ctx=Load(), lineno=191, col_offset=90, end_lineno=191, end_col_offset=95)],
      keywords=[], lineno=191, col_offset=4, end_lineno=191, end_col_offset=96), lineno=191,
      col_offset=4, end_lineno=191, end_col_offset=96)], decorator_list=[], lineno=153,
      col_offset=0, end_lineno=191, end_col_offset=96)'
    function_docstring: "Command-line entry point for processing Python files and\
      \ generating datasets.\nArgs:\n    --start_dir (str, optional): Starting directory\
      \ to search for Python files. Defaults to the current working directory.\n \
      \   --output_dir (str, optional): Directory to write the output files. Defaults\
      \ to the 'datasets' directory in the current working directory.\n    --questions_pathname\
      \ (str, optional): Path to the questions file. If not provided, defaults defined\
      \ in 'get_py2dataset_params.py' will be used.\n    --model_config_pathname (str,\
      \ optional): Path to the model configuration file. If not provided, defaults\
      \ defined in 'get_py2dataset_params.py' will be used.\n    --use_llm (bool,\
      \ optional): Use a Large Language Model for generating JSON answers. Defaults\
      \ to False.\n    --quiet (bool, optional): Limit logging output. If provided,\
      \ only warnings and errors will be logged. Defaults to False."
    function_inputs: []
    function_defaults: []
    function_returns: []
    function_calls:
    - ''' ''.join'
    - arg_string.split('--start_dir ')[1].split
    - arg_string.split
    - arg_string.replace
    - arg_string.split('--output_dir ')[1].split
    - arg_string.split('--model_config_pathname ')[1].split
    - arg_string.split('--questions_pathname ')[1].split
    - py2dataset
    function_call_inputs:
      ''' ''.join':
      - sys.argv[1:]
      arg_string.split('--start_dir ')[1].split:
      - ''' '''
      arg_string.split:
      - '''--questions_pathname '''
      arg_string.replace:
      - '''--quiet'''
      - ''''''
      arg_string.split('--output_dir ')[1].split:
      - ''' '''
      arg_string.split('--model_config_pathname ')[1].split:
      - ''' '''
      arg_string.split('--questions_pathname ')[1].split:
      - ''' '''
      py2dataset:
      - start_dir
      - output_dir
      - questions_pathname
      - model_config_pathname
      - use_llm
      - quiet
    function_variables:
    - model_config_pathname
    - output_dir
    - quiet
    - use_llm
    - questions_pathname
    - start_dir
    - arg_string
    function_decorators: []
    function_annotations: []
    function_properties: []
classes: {}
