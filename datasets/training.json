[
    {
        "instruction": "Define the Python code file that is described as follows:\nThe `get_default_questions` function returns a list of default questions with ids, texts, and types for use in the py2dataset program. It validates that each question is a dictionary and has all three keys specified in [req01]. \nThe `get_default_model_config` function returns a dictionary representing the default model configuration used by the `py2dataset` program. The prompt template is set to a default value, but can be customized based on user input. \nThe `get_output_dir` function takes an optional output directory and verifies whether it exists or creates a new directory using Path(). The specified OUTPUT_DIR global variable serves as a default. This allows users the ability to pass a non-valid file path when running the program, and ensures that there is always a valid output directory for writing files. \nThe `get_questions` function accepts an optional questions_pathname argument, but defaults to QUESTIONS_FILE in the current working directory if it is not provided or invalid. It then checks if the file exists and is valid JSON format using json.load(). If it fails, it returns default questions from get_default_questions() instead. \nThe `instantiate_model` function takes a model_config dictionary as an argument and imports the specified module and class from the model_config. It then instantiates the model using the provided configuration based on the import path and parameters. If there is an error, it returns None. \nThe `get_model` function accepts an optional model_config_pathname argument and defaults to MODEL_CONFIG_FILE in the current working directory if not provided or invalid. It then validates and imports a new dictionary config and updates default prompt using the appropriate global variable based on whether an updated output was received in its signature, [req08] using Path() validation check with `output_dir.is_dir()`. If it fails to load, it defaults to the default model configuration and uses yaml.safe_load(). It returns an instantiated model object along with a prompt template. \nThe `write_questions_file` function accepts an optional output directory and writes the default questions to QUESTIONS_FILE in that directory or the current working directory if none is specified using open(). It defaults to Path().exists() for checking the directory path before writing to avoid creating unwanted directories or errors. \nThe `write_model_config_file` function accepts an optional output directory and writes the default model configuration to MODEL_CONFIG_FILE in that directory or the current working directory if none is specified using open(). It defaults to Path().exists() for checking the directory path before writing to avoid creating unwanted directories or errors. \nThe `get_output_dir` function uses os.path.abspath() to ensure that the output directory is an absolute path, and then creates it if it does not exist using os.makedirs(). It logs a message indicating which directory was used for output. \nThe `get_questions` function accepts an optional questions_pathname argument and checks whether it exists or not. If it fails to load, it defaults to the default questions file in the current working directory. It then validates that each question is a dictionary with all three keys specified in [req01]. \nThe `instantiate_model` function imports the module and class from the model_config dictionary using importlib.import_module() and getattr(). It then instantiates the model object based on whether the \"model_inference_function\" value is specified or not. The latter allows users to select their desired Hugging Face API, ct-transformers specifically in this case. \nThe `get_model` function accepts an optional model_config_pathname argument and defaults to MODEL_CONFIG_FILE in the current working directory if it is not provided or invalid. It then validates that the file exists using yaml.safe_load() before loading a new dictionary config and updating default prompt using the appropriate global variable based on whether an updated output was received in its signature, [req08] using Path(). If it fails to load, it defaults to the default model configuration. It returns an instantiated model object along with a prompt template specified by the user or the default prompt. \nThe `write_questions_file` function writes the default questions to QUESTIONS_FILE in the provided output directory using json.dump(). If no output directory is provided, it defaults to the current working directory. \nThe `write_model_config_file` function also takes an optional output_dir and creates a default YAML config file in the provided path or current directory. This allows for user-specific settings such as different prompts or model parameters.",
        "output": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport yaml\nimport importlib\nfrom typing import Dict, List \nfrom pathlib import Path\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"What are the dependencies of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"internal_code_graph\",\n            \"text\": \"What is the call code graph of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"What functions are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },      \n        {\n            \"id\": \"file_classes\",\n            \"text\": \"What classes are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        }, \n        {\n            \"id\": \"function_returns\",\n            \"text\": \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {   \n            \"id\": \"file_purpose\",\n            \"text\": \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible \n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 8400,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except: # get default questions if can't read questions_pathname file \n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\": \n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else: \n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")    \n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return instantiate_model(model_config['inference_model']), model_config['prompt_template']\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n"
    },
    {
        "instruction": "Define the Python code file that is described as follows:\nThe purpose of this Python file is to generate JSON formatted question-answer pairs and instructions for a given Python file. It provides a `DatasetGenerator` class that accepts a Python file path (str), file details (Dict), base name (str), list of questions (List[Dict]), use_llm flag (bool), language model (object), and prompt (str) as input during instantiation. The `clean_and_get_unique_elements`, `add_to_list`, `get_response_from_llm`, `process_question`, and `generate` methods are provided to clean an input string, add a response to the list, retrieve a response from the language model, process questions related to file, function, class, or method, and generate responses for all the questions and return the instruct_list respectively. The `get_python_datasets` function creates an instance of the `DatasetGenerator` class using the provided input and generates question-answer pairs and instructions. \n\nFunctions:\n1. get_python_datasets:\n   a. Takes in the file path (str), file details (Dict), base name (str), list of questions (List[Dict]), use_llm flag (bool), language model (object), and prompt (str) as input.\n   b. Creates an instance of the `DatasetGenerator` class using the provided input.\n   c. Generates question-answer pairs and instructions using the `generate` method of the `DatasetGenerator` instance.\n   d. Returns the generated `instruct_list`.\n\nClass: DatasetGenerator\n1. __init__:\n   a. Initializes and stores the Python file path, file details, base name, list of questions, use_llm flag, language model, and prompt as class attributes.\n2. clean_and_get_unique_elements:\n   a. Clean an input string (str) and return a string of unique elements.\n3. add_to_list:\n   a. Adds response to the instruct list.\n4. get_response_from_llm:\n   a. Retrieves a response from the language model.\n5. process_question:\n   a. Processes question and adds the generated response to the `instruct_list`.\n6. process_question_type:\n   a. Process questions related to file, function, class, or method.\n7. generate:\n   a. Generates responses for all the questions in the list and returns the `instruct_list`.\n\nAttributes of DatasetGenerator:\n1. file_path (str): The path to the Python file.\n2. file_details (Dict[str, Any]): Details of the Python file.\n3. base_name (str): The base name of the Python file.\n4. questions (List[Dict[str, str]]): Questions for generating responses.\n5. instruct_list (List[Dict[str, str]]): Storage for generated instructions.\n6. question_mapping (Dict[str, str]): Mapping of question types to keys in file details.\n7. use_llm (bool): Flag indicating if a language model should be used.\n8. llm (object): The language model for generating responses.\n9. prompt (str): The prompt format for querying the language model.\n\nMethods of DatasetGenerator:\n1. clean_and_get_unique_elements(input_str: str) -> str: Clean and return unique elements from an input string.\n2. add_to_list(list_to_update: List[Dict], query: str, response: str, additional_field=None) -> List[Dict]: Adds response to the instruct list.\n3. get_response_from_llm(query: str, context: str) -> str: Retrieves a language model response for the given query and context.\n4. process_question(question_type: str, question_id: str, query: str, context: str, info: Dict): Generate an output string and store in instruct list for specific input file elements and llm use if enabled. \n5. get_string_from_info(self, info, item_type) -> str: Gets a comma-separated string of unique elements from the provided dictionary.\n6. process_question_type(self, question_id: str, question_text: str): Process questions related to file, function, or class attributes and generate responses.\n7. generate() -> Tuple[List[Dict], List[Dict]]: Generates responses for all the questions in the list and returns the instruct_list.",
        "output": "\"\"\"\nGenerates JSON format question-answer pairs and instructions for a Python file\nRequirements:\n[req01] The `DatasetGenerator` class shall:\n        a. Accept a Python file path (str), file details (Dict), base name (str), list of questions (List[Dict]), use_llm flag (bool), language model (object), and prompt (str) as input during instantiation.\n        b. Initialize and store the Python file path, file details, base name, list of questions, use_llm flag, language model, and prompt as class attributes.\n        c. Provide the `clean_and_get_unique_elements` method to clean an input string (str) and return a string of unique elements.\n        d. Provide the `add_to_list` method to add a response (str) to a list (List[Dict]).\n        e. Provide the `get_response_from_llm` method to retrieve a response from the language model.\n        f. Provide the `process_question` method to process a question and add the generated response to the instruct_list.\n        g. Provide the `process_question_type` method to process questions related to a file, function, class, or method.\n        h. Provide the `generate` method to generate responses for all questions in the list and return the instruct_list.\n[req02] The `get_python_datasets` function shall:\n        a. Accept a Python file path (str), file details (Dict), base name (str), list of questions (List[Dict]), use_llm flag (bool), language model (object), and prompt (str) as input.\n        b. Create an instance of the `DatasetGenerator` class using the provided input.\n        c. Generate question-answer pairs and instructions using the `generate` method of the `DatasetGenerator` instance.\n        d. Return the generated `instruct_list`.\n\"\"\"\nimport logging\nimport re\nfrom typing import Dict, List, Tuple\n\n# Set up logging\nlogging.basicConfig(\n    format='%(asctime)s - %(levelname)s - %(message)s', \n    level=logging.INFO\n)\nlogger = logging.getLogger(__name__)\n\nclass DatasetGenerator:\n    \"\"\"\n    Generate JSON formatted dictionary outputs for a Python file.\n    Attributes:\n        file_path (str): The path to the Python file.\n        file_details (Dict[str, Any]): Details of the Python file.\n        base_name (str): The base name of the Python file.\n        questions (List[Dict[str, str]]): Questions for generating responses.\n        instruct_list (List[Dict[str, str]]): Storage for generated instructions.\n        question_mapping (Dict[str, str]): Mapping of question types to keys in file details.\n        use_llm (bool): Flag indicating if a language model should be used.\n        llm (object): The language model for generating responses.\n        prompt (str): The prompt format for querying the language model.\n    Methods:\n        clean_and_get_unique_elements(input_str: str) -> str: \n            Clean and return unique elements from an input string.\n        add_to_list(list_to_update: List[Dict], query: str, response: str, additional_field=None) -> List[Dict]: \n            Add response to the instruct list.\n        get_response_from_llm(query: str, context: str) -> str:\n            Get language model response to query for given context.\n        process_question(question_type: str, question_id: str, query: str, context: str, info: Dict) -> None:\n            Process question and add generated response to the instruct_list.\n        process_question_type(question_type: str, question_id: str, question_text: str) -> None:\n            Process question related to file, function, class, or method.\n        generate() -> Tuple[List[Dict], List[Dict]]:\n            Generate responses for all the questions and return the instruct_list.\n    \"\"\"\n    def __init__(self, file_path: str, file_details: Dict, base_name: str, questions: List[Dict], llm: object, prompt: str) -> None:\n        self.file_path = file_path\n        self.file_details = file_details\n        self.base_name = base_name\n        self.questions = questions\n        self.llm = llm\n        self.prompt = prompt\n        if self.llm is None:\n            self.use_llm = False\n        else:\n            self.use_llm = True\n        self.instruct_list = []\n        self.question_mapping = {\n            'file': 'file',\n            'function': 'functions',\n            'class': 'classes',\n            'method': 'classes'\n        }\n\n    @staticmethod\n    def clean_and_get_unique_elements(input_str: str) -> str:\n        \"\"\"\n        Clean input string and return string of unique elements.\n        Args:\n            input_str (str): The input string to be cleaned.\n        Returns:\n            str: The cleaned string.\n        \"\"\"\n        cleaned_elements = set(re.sub(r'[^\\w\\-_>\\s:/.]', '', element.strip())\n                               for element in re.sub(r'\\s+', ' ', input_str).split(','))\n        return ', '.join(cleaned_elements)\n\n    @staticmethod\n    def add_to_list(list_to_update: List[Dict], query: str, response: str, additional_field=None) -> List[Dict]:\n        \"\"\"\n        Adds response to instruct list.\n        Args:\n            list_to_update (List[Dict]): The list to be updated.\n            query (str): The query to be added.\n            response (str): The response to be added.\n            additional_field (str): The additional field to be added.\n        Returns:\n            List[Dict]: The updated list.\n        \"\"\"\n        if response and response.strip() and response != 'None':\n            list_to_update.append(\n                {'instruction': query, 'input' : additional_field, 'output': response}\n                if additional_field else\n                {'question': query, 'answer': response}\n            )\n        return list_to_update\n\n    def get_response_from_llm(self, query: str, context: str) -> str:\n        \"\"\"\n        Get language model response to query for given context.\n        Args:\n            query (str): The query to be used for generating the response.\n            context (str): The context to be used for generating the response.\n        Returns:\n            str: The generated response.\n        \"\"\"\n        # Update the context with the selected instructions from the instruct_list\n        excluded_instructions = [\"What is the call code graph\", \"What is the docstring\"]\n        filtered_instruct_list = [item for item in self.instruct_list if not any(item['instruction'].startswith(prefix) for prefix in excluded_instructions)]\n        past_instructs = \"\\n\".join([f\"Instruction: {item['instruction']} \\nOutput: {item['output']}\" for item in filtered_instruct_list])\n        full_context = context + \"\\n\" + \"Here's some detail about this code:\" + \"\\n\" + past_instructs\n\n        try:\n            prompt = self.prompt.format(context=full_context, query=query)\n            logging.info(f'Query: {query}')\n            response = self.llm(prompt)\n            logging.info(f'Response: {response}')\n        except:\n            logger.error('Failed to generate model response')\n        return response\n\n    def process_question(self, question_type: str, question_id: str, query: str, context: str, info: Dict) -> None:\n        \"\"\"\n        Process question and add the generated response to the instruct_list.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            query (str): The query to be processed.\n            context (str): The context to be used for generating the response.\n            info (Dict): The information of the Python file.\n        Returns:\n            None\n        \"\"\"\n        if question_id.endswith('code_graph'):\n            response = info.get(question_id, {})\n        else:\n            response = self.get_response_from_llm(query, context) if self.use_llm and question_id.endswith('purpose') else self.clean_and_get_unique_elements(str(info.get(question_id, '')))\n        if response and response != 'None':\n            response_str = str(response).strip()\n            if response_str:\n                self.instruct_list.append({'instruction': query, 'input': context, 'output': response_str})\n\n    @staticmethod\n    def get_string_from_info(info, item_type):\n        if info[item_type]:\n            items = [item.strip() for item in str(info[item_type]).split(',') if item]\n            return ', '.join(items)\n        return ''\n\n    def process_question_type(self, question_type: str, question_id: str, question_text: str) -> None:\n        \"\"\"\n        Process questions related to a file, function, class, or method.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            question_text (str): The text of the question to be processed.\n        Returns:\n            None\n        \"\"\"\n        if question_type == 'file':\n            query = question_text.format(filename=self.base_name)\n            context = self.file_details['file_info']['file_code']\n            info = self.file_details['file_info']\n            self.process_question(question_type, question_id, query, context, info)\n        elif question_type == 'method':  \n            for class_name, class_info in self.file_details['classes'].items():\n                for key, method_info in class_info.items():\n                    if key.startswith('class_method_'):\n                        method_name = key[len('class_method_'):]\n                        context = method_info['method_code']\n                        mapping = {'class_name': class_name, 'method_name': method_name}\n                        query = question_text.format(filename=self.base_name, **mapping)\n                        self.process_question(question_type, question_id, query, context, method_info)\n        else:  # if question_type == 'function' or question_type == 'class'\n            for name, info in self.file_details[self.question_mapping[question_type]].items():\n                context = info[f'{question_type}_code']\n                mapping = {f'{question_type}_name': name}\n                if question_id == f'{question_type}_purpose' and self.use_llm:\n                    variables_string = self.get_string_from_info(info, f'{question_type}_variables')\n                    inputs_string = self.get_string_from_info(info, f'{question_type}_inputs')\n                    combined_string = ', '.join([s for s in [variables_string, inputs_string] if s])\n                    mapping[f'{question_type}_variables'] = self.clean_and_get_unique_elements(combined_string)\n                    # get methods to include in mapping for query\n                    if question_type == 'class':\n                        methods_string = self.get_string_from_info(info, f'{question_type}_methods')\n                        mapping[f'{question_type}_methods'] = methods_string\n\n                query = question_text.format(filename=self.base_name, **mapping)\n                self.process_question(question_type, question_id, query, context, info)\n\n    def generate(self) -> Tuple[List[Dict], List[Dict]]:\n        \"\"\"\n        Generate responses for all the questions and returns the instruct_list.\n        Args:\n            None\n        Returns:\n            Tuple[List[Dict], List[Dict]]: The generated question-answer pairs and instructions.\n        \"\"\"\n        for question in self.questions:\n            self.process_question_type(question['type'], question['id'], question['text'])\n        return self.instruct_list\n\n\ndef get_python_datasets(file_path: str, file_details: Dict, base_name: str, questions: List[Dict], \n                        llm: object, prompt: str) -> Tuple[List[Dict], List[Dict]]:\n    \"\"\"\n    Extract information from a Python file and return it in JSON format.\n    Args:\n        file_path (str): The path to the Python file.\n        file_details (Dict): The details of the file.\n        base_name (str): The base Python code filename.\n        questions (List[Dict]): The list of questions.\n        llm (object): The language model to be used for generating responses.\n        prompt (str): The prompt to be used for generating responses.\n    Returns:\n        Tuple[List[Dict], List[Dict]]: Extracted information in JSON format.\n    \"\"\"\n    generator = DatasetGenerator(file_path, file_details, base_name, questions, llm, prompt)\n    return generator.generate()\n"
    },
    {
        "instruction": "Define the Python code file that is described as follows:\n1. The purpose of this Python file is to extract details from a given Python file using AST (Abstract Syntax Tree), determine the code call graph, and return it as a dictionary. It provides functions for getting all calls in an AST subtree rooted at a specified node, class and function definition analysis with associated methods such as getting their attributes and call details, extracting summaries from a file using CodeVisitor class, creating a comprehensive code graph representing relationships between nodes (functions, classes, etc.), and extracting file-level information. \n2. Functions: get_all_calls - This function recursively finds all function calls in the subtree rooted at a specified node; CodeVisitor - Extracts details about functions and classes in a Python file using AST; code_graph - Creates a dictionary representing nodes and edges in a code graph based on function/class/method call relationships, returns comprehensive information on file level; get_python_file_details - This function takes in a file path, extracts detailed information from the specified Python file using the CodeVisitor class and includes the entire file graph in the returned details.\n3. Input: \n- get_all_calls(node): Accepts an AST node as input and recursively finds all function calls in its subtree.\n- CodeVisitor(code): Initializes a new instance of the class with source code, visits functions and classes to gather details about them, and stores their attributes/properties, such as function name, definition, docstring, inputs, return types, annotations, call_inputs, and defaults in dictionaries.\n- analyze(node): Traverses the AST rooted at 'node' and populates file_info with comprehensive details about the code. \n- code_graph(file_summary): Accepts a dictionary of file summary information (e.g., dependencies, function names, class names) and returns a dictionary representing nodes and edges in the code graph, indicating relationships like function calls, method calls, and class inheritance.\n- get_python_file_details(file_path): Extracts detailed information from the specified Python file using AST and the CodeVisitor class, including the entire file graph.",
        "output": "\"\"\"\nUse AST to extract details from a Python file, determine the code call graph and return it as a dictionary.\nRequirements:\n[req01] The get_all_calls function shall:\n        a. Accept a node as an argument.\n        b. Recursively find all function calls in the subtree rooted at the node.\n        c. Return a list of all function calls in the subtree rooted at the node.\n[req02] The `CodeVisitor` class shall:\n        a. Accept the source code as input\n        b. Use the AST to extract details about the code.\n        c. Inherit from `ast.NodeVisitor`.\n        d. Implement the `visit_FunctionDef` method to gather details about functions.\n        e. Implement the `visit_ClassDef` method to gather details about classes.\n        f. Implement the `extract_details` method to parse information about a given node.\n        g. Implement the `analyze` method to traverse the AST, list all nodes within the current file, and populate the 'file_info' attribute with comprehensive file details.\n[req03] The `code_graph` function shall:\n        a. Accept the file summary and file details as input.\n        b. Construct a dictionary with nodes and edges that illustrate code relationships.\n        c. Define elements such as function nodes, class nodes, and method nodes.\n        d. Specify edges to represent relationships like function calls, method calls, and class inheritance.\n        e. Return a dictionary representation of the code graph, aiding in understanding the code's structure and inter-relationships.\n[req04] The `get_python_file_details` function shall:\n        a. Accept a file path as an argument.\n        b. Extract detailed information from the specified Python file using the AST and the `CodeVisitor` class.\n        c. Include the entire file graph in the returned details.\n        d. Return a dictionary encompassing the extracted file details.\n\"\"\"\nimport ast\nimport re\nimport json\nimport logging\nimport networkx as nx\nfrom typing import Dict, List, Optional, Union\n\ndef get_all_calls(node):\n    \"\"\"\n    Recursively find all function calls in the subtree rooted at `node`.\n    Args:\n        node: ast.AST: The node to start the search from.\n    Returns:\n        list: A list of all function calls in the subtree rooted at `node`.\n    \"\"\"\n    calls = {}\n    for child in ast.iter_child_nodes(node):\n        if isinstance(child, ast.Call):\n            calls[ast.unparse(child.func)] = [ast.unparse(arg) for arg in child.args]\n        calls.update(get_all_calls(child))\n    return calls\n\nclass CodeVisitor(ast.NodeVisitor):\n    \"\"\"\n    Visitor class for traversing an AST (Abstract Syntax Tree) and extracting details about the code.\n    Attributes:\n        code (str): The source code.\n        functions(Dict): details about functions in the code.\n        classes (Dict): details about classes in the code.\n        file_info (Dict): details about the file.\n    Methods:\n        visit_FunctionDef(node: ast.FunctionDef) -> None: \n            Extract details about a function.\n        visit_ClassDef(node: ast.ClassDef) -> None: \n            Extract details about a class.\n        extract_details(node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]: \n            Extract details about a node.\n        analyze(node: ast.AST) -> None: \n            Populate file_info with details about the file.\n    \"\"\"\n    def __init__(self, code: str):\n        \"\"\"\n        Initialize a new instance of the class.\n        Args:\n            code: str: The source code.\n        Returns:\n            None\n        \"\"\"\n        self.code: str = code\n        self.functions: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.classes: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.file_info: Dict[str, Union[str, List[str]]] = {}\n        self.current_class: str = None\n    \n    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n        \"\"\"\n        Extract details about a function.\n        Args:\n            node: ast.FunctionDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        details = self.extract_details(node, 'method' if self.current_class else 'function')\n        if self.current_class:\n            self.classes[self.current_class][f'class_method_{node.name}'] = details\n        else:\n            self.functions[node.name] = details\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n        \"\"\"\n        Extract details about a class.\n        Args:\n            node: ast.ClassDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        self.classes[node.name] = self.extract_details(node, 'class') # populate class dictionary when class definition found in AST\n        self.current_class = node.name  # set current_class to indicate inside a class\n        self.generic_visit(node) # continue AST traversal to the next node\n        self.current_class = None  # reset current_class when finished with this class\n    \n    def extract_details(self, node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]:\n        \"\"\"\n        Extract details about a node.\n        Args:\n            node: ast.AST: The node to extract details from.\n            node_type: str: The type of node.\n        Returns:\n            Dict[str, Union[str, List[str]]]: The details extracted from the node.\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        call_data = get_all_calls(node)\n        details = {\n            f\"{node_type}_name\": node.name, \n            f\"{node_type}_code\": ast.unparse(node),\n            f\"{node_type}_ast\": ast.dump(node, include_attributes=True), \n            f\"{node_type}_docstring\": ast.get_docstring(node),\n            f\"{node_type}_inputs\": [arg.arg for arg in node.args.args] if node_type in ['function', 'method'] else None,\n            f\"{node_type}_defaults\": [ast.unparse(d) for d in node.args.defaults] if node_type in ['function', 'method'] else None,\n            f\"{node_type}_returns\": [ast.unparse(subnode.value) if subnode.value is not None else \"None\" for subnode in node_walk if isinstance(subnode, ast.Return)],\n            f\"{node_type}_calls\": list(call_data.keys()),\n            f\"{node_type}_call_inputs\": call_data, \n            f\"{node_type}_variables\": list({ast.unparse(target) for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Name)}),\n            f\"{node_type}_decorators\": list({ast.unparse(decorator) for decorator in node.decorator_list} if node.decorator_list else set()),\n            f\"{node_type}_annotations\": list({ast.unparse(subnode.annotation) for subnode in node_walk if isinstance(subnode, ast.AnnAssign) and subnode.annotation is not None}),\n            f\"{node_type}_properties\": list({ast.unparse(subnode) for subnode in node_walk if isinstance(subnode, ast.Attribute) and isinstance(subnode.ctx, ast.Store)}),\n        }  \n        if node_type in ['class', 'method']:\n            if node_type == 'method' and self.current_class: # find attributes defined as self.attribute\n                attributes = [target.attr for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute) and isinstance(target.value, ast.Name) and target.value.id == 'self']\n                if attributes: # if this class already has some attributes, add to them\n                    if \"class_attributes\" in self.classes[self.current_class]:\n                        self.classes[self.current_class][\"class_attributes\"].extend(attributes)\n                    else: # otherwise, start a new list of attributes for this class\n                        self.classes[self.current_class][\"class_attributes\"] = attributes\n            if node_type == 'class':\n                details.update({\n                    \"class_attributes\": [target.attr for subnode in node.body if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute)],\n                    \"class_methods\": [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\"],\n                    \"class_inheritance\": [ast.unparse(base) for base in node.bases] if node.bases else [],\n                    \"class_static_methods\": [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\" and any(isinstance(decorator, ast.Name) and decorator.id == \"staticmethod\" for decorator in subnode.decorator_list)],\n                    })\n        return details\n\n    def analyze(self, node: ast.AST) -> None:\n        \"\"\"\n        Traverse the AST rooted at 'node', create a list of all nodes within the current file, and populate 'file_info' with file details\n        Args:\n            node: ast.AST: The node to analyze.\n        Returns:\n            None\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        self.visit(node)\n        self.file_info = {\n            \"file_code\": self.code,\n            \"file_ast\" : ast.dump(node),\n            \"file_dependencies\": list({alias.name for subnode in node_walk if isinstance(subnode, ast.Import) for alias in subnode.names} | {subnode.module for subnode in node_walk if isinstance(subnode, ast.ImportFrom)}),\n            \"file_functions\": list(self.functions.keys()),\n            \"file_classes\": list(self.classes.keys()),\n        }\n        \n        # add file_summary to file_info\n        function_defs = [{func_name: {\"inputs\": details[\"function_inputs\"], \"calls\": details[\"function_calls\"], \"call_inputs\": details[\"function_call_inputs\"], \"returns\": details[\"function_returns\"]}} for func_name, details in self.functions.items()]\n        class_defs = []\n        for class_name, class_details in self.classes.items():\n            method_defs = {}\n            for method_name, details in class_details.items():\n                if method_name.startswith('class_method_'):\n                    method_defs[method_name[len('class_method_'):]] = {\"inputs\": details[\"method_inputs\"], \"calls\": details[\"method_calls\"], \"call_inputs\": details[\"method_call_inputs\"], \"returns\": details[\"method_returns\"]}\n            class_defs.append({class_name: {\"method_defs\": method_defs}})\n        self.file_info[\"file_summary\"] = { 'dependencies': self.file_info[\"file_dependencies\"], 'function_defs' : function_defs, 'class_defs' : class_defs}\n\ndef code_graph(file_summary: Dict[str, Union[Dict, str]]) -> Dict[str, Union[List[str], Dict[str, List[str]]]]:\n    \"\"\"\n    Create a dictionary representation of file details.\n    Args:\n        file_summary: Dict[str, Union[Dict, str]]: The details extracted from the file.\n    Returns:\n        dict: A dictionary with nodes and edges representing the relationships in the code.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Create lookup dictionaries for function and class method details\n    function_details_lookup = {}\n    for function_def in file_summary['function_defs']:\n        function_details_lookup.update(function_def)\n    class_method_details_lookup = {}\n    for class_def in file_summary['class_defs']:\n        for class_name, class_details in class_def.items(): # Extract class name and details\n            G.add_node(class_name) # Add class as a graph node\n            for method_name, method_details in class_details['method_defs'].items():\n                qualified_method_name = f'{class_name}.{method_name}' # Create method fully qualified name\n                G.add_node(qualified_method_name) # Add method as a graph node\n                class_method_details_lookup[qualified_method_name] = method_details  # Store method details \n                G.add_edge(class_name, qualified_method_name) # Add edge from class to method\n\n    # Helper function to extract edge data from target details\n    def get_edge_data_from_details(target_details: dict, source_details: dict, target: str) -> dict:\n        edge_data = {}\n        if target_details:\n            edge_data['target_inputs'] = target_details.get('inputs')\n            edge_data['target_returns'] = list(set(target_details.get('returns', [])))\n        if source_details and 'call_inputs' in source_details and target in source_details['call_inputs']:\n            edge_data['target_inputs'] = source_details['call_inputs'][target]     \n        return edge_data\n\n    # Helper function to add edge with data\n    def add_edge_with_data(source: str, target: str, init_method: Optional[str] = None) -> None:\n        target_details = class_method_details_lookup.get(init_method or target) or function_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        G.add_edge(source, target, **get_edge_data_from_details(target_details, source_details, target))\n\n    # Helper function to add edges for function or class method calls\n    def add_edges_for_calls(source_name, calls):\n        class_names = [list(class_def.keys())[0] for class_def in file_summary['class_defs']]\n        for called in calls:\n            called_class_name = called.split('.')[0]\n            if called.startswith(\"self.\"):\n                method_name = called.replace(\"self.\", \"\")\n                fully_qualified_name = f\"{source_name.split('.')[0]}.{method_name}\"\n                if fully_qualified_name in class_method_details_lookup:\n                    add_edge_with_data(source_name, fully_qualified_name)\n                    continue\n            if (\n                called in function_details_lookup or \n                called in class_method_details_lookup or \n                f\"{source_name.split('.')[0]}.{called}\" in class_method_details_lookup\n            ):\n                add_edge_with_data(source_name, called)\n            elif called_class_name in class_names:\n                init_method = None\n                init_method_name = f\"{called}.__init__\"\n                if init_method_name in class_method_details_lookup:\n                    init_method = init_method_name\n                add_edge_with_data(source_name, called, init_method)\n            else:\n                G.add_node(called)\n                add_edge_with_data(source_name, called)\n\n    # Add function nodes to graph and edges for function calls\n    for function_name in function_details_lookup.keys():\n        G.add_node(function_name)\n    for func_name, details in function_details_lookup.items():\n        add_edges_for_calls(func_name, details['calls'])\n\n    # Add edges for method calls\n    for qualified_method_name, details in class_method_details_lookup.items():\n        add_edges_for_calls(qualified_method_name, details['calls'])\n\n    # Add edge data to edges and create node and edges to return\n    for edge in G.edges:\n        source, target = edge\n        target_details = function_details_lookup.get(target) or class_method_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        edge_data = get_edge_data_from_details(target_details, source_details, target)\n        G[source][target].update(edge_data)\n    nodes = list(G.nodes)\n    edges = [{\"source\": edge[0], \"target\": edge[1], **edge[2]} for edge in G.edges.data()]\n    return {\"nodes\": nodes, \"edges\": edges}\n\n\ndef get_python_file_details(file_path: str) -> Dict[str, Union[Dict, str]]:\n    \"\"\"\n    Extract details from a Python file.\n    Args:\n        file_path: str: The path to the Python file.\n    Returns:\n        Dict[str, Union[Dict, str]]: The details extracted from the file.\n    \"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors='ignore') as f:\n            code = f.read()\n            tree = ast.parse(code)\n    except:\n        logging.warning(f\"Permission denied or syntax error in file: {file_path}\")\n        return None \n\n    visitor = CodeVisitor(code)\n    visitor.analyze(tree)\n    file_details = {'file_info': visitor.file_info, 'functions': visitor.functions, 'classes': visitor.classes}\n    file_details['file_info']['entire_code_graph'] = code_graph(file_details['file_info']['file_summary'])\n    file_details['file_info']['file_summary'] = json.dumps(file_details['file_info']['file_summary']).replace('\\\"','')\n    return file_details"
    },
    {
        "instruction": "Define the Python code file that is described as follows:\n## Function and class details",
        "output": "\"\"\"\nFor each Python file within given directory, generate, save, and return datasets that include responses to questions about the code.\nRequirements:\n[req00] The extract_python_data function shall:\n    a. Accept parameters for the Python file path, base name, model configuration pathname, questions dictionary, and use of LLM.\n    b. Use the 'get_python_file_details' function to get the Python file details.\n    c. If the use_llm parameter is True, instantiate the LLM using the 'get_model' function.\n    d. Use the 'get_python_datasets' function to get the instruct.json datasets.\n    e. Return the file details and instruct.json dataset.\n[req01] The process_python_directories function shall:\n    a. Accept parameters for the starting directory, output directory, model configuration pathname, questions dictionary, and use of LLM.\n    b. Search for all Python files within the given directory and its subdirectories using a glob pattern.\n    c. For each Python file, call the extract_python_data function to get the file details and instruct.json dataset.\n    d. For valid Python file datasets, call the save_python_data function to save the file details and instruct.json dataset.\n    e. Combine all of the instruct.json files together using the 'combine_json_files' function.\n    f. Return the combined datasets.\n[req02] The py2dataset function shall:\n    a. Accept parameters for the starting directory, output directory, questions pathname, model configuration pathname, quiet mode, and use of LLM.\n    b. Determine the starting directory based on provided or default values.\n    c. Adjust the logging level based on the quiet flag.\n    d. Call the process_python_directories function to process the Python files and generate datasets.\n    e. Return the datasets.\n[req03] The main function shall:\n    a. Accept and process command-line arguments.\n    b. Determine the parameters for the py2dataset function based on the processed command-line arguments.\n    c. Call the py2dataset function with the derived parameters.\n\"\"\"\nimport os\nimport sys\nimport gc\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Union\nfrom multiprocessing import Process\n\nfrom get_python_file_details import get_python_file_details\nfrom get_python_datasets import get_python_datasets\nfrom get_py2dataset_params import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output import combine_json_files, save_python_data\n\ndef extract_python_data(file_path: str, base_name: str, questions: Dict, llm: object, prompt: str) -> Tuple[Union[Dict, Tuple], List[Dict], List[Dict]]:\n    \"\"\"\n    Extracts data from a Python file.\n    Args:\n        file_path (str): Path to the Python file.\n        base_name (str): Base name of the Python file.\n        questions (Dict): Questions dictionary to answer about the Python file.\n        llm (object): Large Language Model object. If None, use the default prompt.\n        prompt (str): Prompt to use for the Large Language Model.\n    Returns:\n        Tuple[Union[Dict, Tuple], List[Dict], List[Dict]]: File details dictionary or tuple of file details and None, instruct.json dataset.\n    \"\"\"\n    file_details, instruct_list = None, None    \n    # use AST to get python file details\n    file_details = get_python_file_details(file_path)\n    if file_details is None or isinstance(file_details, tuple):\n        return file_details, instruct_list\n\n    # get lists for instruct.json for python file\n    instruct_list = get_python_datasets(file_path, file_details, base_name, questions, llm, prompt)  \n    return file_details, instruct_list\n\n\ndef process_single_file(pythonfile_path, start_dir, model_config_pathname, questions, use_llm, output_dir):\n    \"\"\"\n    Process a single Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path (str): Path to the Python file.\n        start_dir (str): Starting directory to search for Python files.\n        model_config_pathname (str): Path to the model configuration file.\n        questions (Dict): Questions dictionary to answer about the Python file.\n        use_llm (bool): If True, use a Large Language Model for generating JSON answers.\n        output_dir (str): Directory to write the output files.\n    Returns:\n        none\n    \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    #instantiate llm and prompt if use_llm is True \n    #do this for each file to aviod multiprocessing pickling problem\n    llm, prompt = get_model(model_config_pathname) if use_llm else (None, '')\n\n    # get and save file_details and instruct_list\n    file_details, instruct_list = extract_python_data(pythonfile_path, base_name, questions, llm, prompt)\n    if file_details is None or isinstance(file_details, tuple):\n        return\n    save_python_data(file_details, instruct_list, relative_path, output_dir)\n\n\ndef process_python_directories(start_dir: str, output_dir: str, model_config_pathname: str, questions: Dict, \n                               use_llm: bool) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Processes all Python files in the provided directory and subdirectories.\n    Args:\n        start_dir (str): Starting directory to search for Python files.\n        output_dir (str): Directory to write the output files.\n        model_config_pathname (str): Path to the model configuration file.\n        questions (Dict): Questions dictionary to answer about each Python file.\n        use_llm (bool): If True, use the LLM model to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n    datasets = {}\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n\n        if pythonfile_path.is_dir():\n            continue\n\n        # spawn a new child process to manage python memory leaks\n        proc = Process(target=process_single_file, args=(pythonfile_path, start_dir, model_config_pathname, questions, use_llm, output_dir))\n        proc.start()\n        proc.join()\n        \n    # combine all of the instruct.json files together\n    datasets = combine_json_files(output_dir)   \n    return datasets\n\n\ndef py2dataset(start_dir: str = '', output_dir: str = '', questions_pathname: str = '', model_config_pathname: str = '', \n               use_llm: bool = False, quiet: bool = False) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process Python files to generate question-answer pairs and instructions.\n    Args:\n        start_dir (str, optional): Starting directory to search for Python files. Defaults to current working directory.\n        output_dir (str, optional): Directory to write the output files.\n        questions_pathname (str, optional): Path to the questions file.\n        model_config_pathname (str, optional): Path to the model configuration file.\n        use_llm (bool, optional): If True, use a Large Language Model for generating JSON answers. Defaults to False.\n        quiet (bool, optional): Limit logging output. Defaults to False.\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)  # Increase the recursion limit for AST\n    \n    # if start dir is empty or not a valid directory, use current working directory\n    if start_dir == '' :\n        logging.info('No valid start path provided. Using current working directory.')\n        start_dir = os.getcwd()    \n    start_dir = os.path.abspath(start_dir)\n    \n    output_dir = get_output_dir(output_dir)\n    questions = get_questions(questions_pathname)\n\n    datasets = process_python_directories(start_dir, output_dir, model_config_pathname, questions, use_llm)\n    return datasets\n\ndef main():\n    \"\"\"\n    Command-line entry point for processing Python files and generating datasets.\n    Args:\n        --start_dir (str, optional): Starting directory to search for Python files. Defaults to the current working directory.\n        --output_dir (str, optional): Directory to write the output files. Defaults to the 'datasets' directory in the current working directory.\n        --questions_pathname (str, optional): Path to the questions file. If not provided, defaults defined in 'get_py2dataset_params.py' will be used.\n        --model_config_pathname (str, optional): Path to the model configuration file. If not provided, defaults defined in 'get_py2dataset_params.py' will be used.\n        --use_llm (bool, optional): Use a Large Language Model for generating JSON answers. Defaults to False.\n        --quiet (bool, optional): Limit logging output. If provided, only warnings and errors will be logged. Defaults to False.\n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname = ''\n    use_llm = False\n    quiet = False\n\n    if '--start_dir' in arg_string:    \n        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n    if '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n        model_config_pathname = arg_string.split('--model_config_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}', '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--questions_pathname {questions_pathname}', '') \n    if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string = arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n        quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n\n    py2dataset(start_dir, output_dir, questions_pathname, model_config_pathname, use_llm, quiet)\n\nif __name__ == \"__main__\":\n    main()"
    },
    {
        "instruction": "Define the Python code file that is described as follows:\nThe purpose of this Python file is to provide utility functions for reading the input and saving the output of the py2dataset script. It includes functions such as read_file(), write_file(), convert_json_to_html(), combine_json_files(), create_code_graph(), and save_python_data(). The functions are used to read JSON or YAML files, convert JSON files to HTML format, merge all JSON files in a given directory, remove duplicates from the combined JSON files, write the data as JSON or YAML files, generate code graphs based on provided file details, and save Python file details as a YAML file.\n\n1. read_file() - This function reads a JSON or YAML file and returns its contents as a dictionary. It takes in a file path as an argument and opens the file using the appropriate method (json.load() for JSON files and yaml.load() for YAML files) to load the data into a Python dictionary.\n2. write_file() - This function writes a dictionary to a JSON or YAML file. It takes in two arguments, \"data\" as a dictionary containing the information that needs to be written and \"file_path\" as the path to the output file. The appropriate method (json.dump() for JSON files and yaml.safe_dump()) is used to write the data to the file with proper indentation and spacing.\n3. convert_json_to_html() - This function converts all JSON files in a given directory into HTML format while preserving spacing and tabs in the \"input\" field. It first searches for JSON files in the provided directory using pathlib.Path.rglob() and loops through them to load their content. It then converts each dictionary of entries into an HTML table with appropriate CSS styles and saves it as a .html file.\n4. combine_json_files() - This function combines all JSON files in the output directory into \"instruct.json\" and removes duplicates based on the provided keys (\"instruction\" and \"output\"). It first creates an empty list called \"combined_data\". Then, it loops through each JSON file in the directory using pathlib.Path.rglob() to load its content into a dictionary called \"json_file_data\". The function then uses remove_duplicate_dataset_entries() to filter out duplicates from combined_data based on two keys (\"instruction\" and \"output\") before writing it back to instruct.json file. Additionally, it generates training data that contains purpose and graph data formatted as follow for each item in the dataset by extracting specific entries with regex pattern matching. Finally, it calls convert_json_to_html() function to save HTML files for each JSON file in the output directory.\n5. remove_duplicate_dataset_entries() - This function removes duplicate entries from a provided list of dictionaries based on two keys (\"instruction\" and \"output\"). It initializes an empty set called \"seen\", an empty list called \"result\". Then, it loops through each item in the dataset and checks if the tuple (item[\"instruction\"], item[\"output\"]) is already present in seen. If not, it adds it to both seen and result sets. The function returns a list without duplicate entries based on those two keys.\n6. create_code_graph() - This function takes \"file_details\", a base name, and an output directory as arguments and generates code graphs based on the provided file details using networkx library. It creates a directed graph (DiGraph) called G, adds nodes from \"file_info\"[\"nodes\"], and then loops through each edge in \"file_info\"[\"edges\"] to add edges with their respective inputs and returns. The function then uses nx.draw() to draw the graph, labels the edges based on input and return values, and saves it as a PNG image using plt.savefig().\n7. save_python_data() - This function takes \"file_details\", \"instruct_list\", \"relative_path\", and \"output_dir\" as arguments and saves Python file details as a YAML file, the instruction data as a JSON file, and code graphs. It first creates an output directory using pathlib.Path().mkdir() method if it does not exist. Then, it loops through each entry in instruct_list and generates two different JSON files (\"details\" and \"instruct\") by filtering entries that start with specific patterns (1) Describe the Python code file that is described as follows: and What is the call code graph for Python file:). It also calls create_code_graph() to generate a PNG image of the entire code graph.\n8. The function read_file() takes in a \"file_path\" argument, checks its extension using file_path.suffix[1:] (i.e., 'json' or 'yaml') and loads it accordingly with either json.load() or yaml.load(). It returns the contents of the file as a dictionary.\n9. The function write_file() takes in two arguments, \"data\" as a dictionary containing the information that needs to be written and \"file_path\" as the path to the output file. It uses appropriate methods (json.dump() for JSON files and yaml.safe_dump()) to write the data to the file with proper indentation and spacing.\n10. The function preserve_spacing() takes in a \"text\" argument and preserves spaces and tabs while converting it into HTML format by replacing spaces with &nbsp; and tabs with &nbsp; * tab_width (default 4).\n\nReasons to follow: The requirements from the code problem indicate that read_file should open either a JSON or YAML file using an appropriate loader. Therefore, \"try-except\" blocks are added around the two possible load methods for different types of files and it will use json.load() if it is unable to load with yaml.load(). Additionally, it has some comments and indentation rules in line 59 and 62. write_file uses both SafeDumper from PyYAML to preserve the order of dictionaries and indent=4 for JSON files. The function convert_json_to_html() is used to generate HTML tables from JSON files while preserving spacing and tabs, which are replaced with &nbsp; and <br/> tags respectively. It also uses pathlib.Path.rglob() to search for all .json files in a given directory, as specified in the problem requirements.\nThe function remove_duplicate_dataset_entries() removes duplicate entries from \"dataset\" by iterating over each item in the list and checking if its (instruction, output) tuple is already present in \"seen\", an empty set. It adds the new items to \"result\" if it is not a duplicate and returns the updated list. The function then filters out purpose and graph data from instruct_list, which is combined with code data using regex patterns and saved as training.json file.\nThe function create_code_graph() takes in \"file_details\", \"base_name\", and \"output_subdir\" to generate call code graphs based on the provided information using networkx library and save it as a PNG image using plt.savefig(). The base name is used to create a unique file name for each graph.\nThe function save_python_data() takes in \"file_details\", \"instruct_list\", \"relative_path\" (as str), and \"output_dir\". It uses Path() method to create an output directory if it does not exist, and then creates two JSON files: details.json and instruct.json. It also calls create_code_graph() to generate PNG images of the entire code graph and saves them in the same directory as instruct.json.\nVariables: \n- file_type (str): The type of file based on its extension (either 'yaml' or 'json')\n- html_content (str): The HTML content for each table, including CSS styles and headers\n- column_count (int): The number of columns in the \"input\" and \"output\" data tables, to set fixed width for them as 1/3 and 2/3. It will help determine column_width\n- html_file (Path): The output file path with a .html extension\n- seen (set): A set used to store unique (instruction, output) tuples to avoid duplicates in \"combine_json_files()\" function\n- dataset (list): The list of dictionaries extracted from each JSON file, contains 'instruct', 'output', and other information such as call nodes/edges for creating a code graph\n- pos: the node positions determined by nx.spring_layout() function used to position the nodes on the network plot.\n- result (list): An empty list of combined JSON data from multiple files\n- edge_labels (dict): A dictionary that maps edges to their respective input and return values, for displaying them as labels in the graph\n- output_file (Path): The path where the PNG image will be saved",
        "output": "\"\"\"\nUtility functions for reading the input and saving the output of the py2dataset script.\nRequirements:\n[req01] The `read_file` function shall:\n        a. Accept a file path as an argument.\n        b. Read and return the contents of a JSON or YAML file as a dictionary.\n[req02] The `write_file` function shall:\n        a. Accept a dictionary and a file path as arguments.\n        b. Write the dictionary to a file in either JSON or YAML format.\n[req03] The `convert_json_to_html` function shall:\n        a. Convert JSON files within a given directory to HTML format.\n        b. Save each converted file with a .html extension.\n        c. Preserve spacing and tabs for the 'input' field.\n[req04] The `combine_json_files` function shall:\n        a. Accept a directory path as an argument.\n        b. Merge all JSON files in the directory.\n        c. Remove duplicates from the combined JSON files.\n        d. Write the combined data to 'instruct.json' files.\n        e. Convert the merged JSON files to HTML format.\n        f. Return the 'instruct_list' datasets.\n[req05] The `create_code_graph` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Generate code graphs based on the provided file details.\n        c. Save the graphs as PNG images in the specified output directory.\n[req06] The `save_python_data` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Save the details of the Python file as a YAML file.\n        c. Save the instruction data as JSON files.\n        d. Generate and save code graphs.\n\"\"\"\nimport sys\nimport os\nimport re\nimport json\nimport logging\nimport yaml\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom html import escape\nfrom pathlib import Path\nfrom typing import Dict, List, Union\n\n\ndef read_file(file_path: Path) -> Dict:\n    \"\"\"\n    Reads a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n    Returns:\n        The contents of the file as a dictionary.\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open() as f:\n        if file_type == 'json':\n            return json.load(f)\n        elif file_type == 'yaml':\n            return yaml.load(f)\n\n\ndef write_file(data: Dict, file_path: Path) -> None:\n    \"\"\"\n    Writes a dictionary to a JSON or YAML file. \n    Args:\n        data (Dict): The data to write to the file.\n        file_path (Path): The path to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open('w') as f:\n        if file_type == 'json':\n            json.dump(data, f, indent=4)\n        elif file_type == 'yaml':\n            yaml.SafeDumper.ignore_aliases = lambda *args: True\n            yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)\n\n\ndef convert_json_to_html(directory: str) -> None:\n    \"\"\"\n    Convert JSON files within a given directory to HTML format.\n    Args:\n        directory (str): The directory where the JSON files are located.\n    Returns:\n        None    \n    \"\"\"\n    def preserve_spacing(text: str, tab_width: int = 4) -> str:\n        \"\"\"Preserve spaces and tabs in the provided text.\"\"\"\n        return text.replace(\" \", \"&nbsp;\").replace(\"\\t\", \"&nbsp;\" * tab_width)\n\n    for json_file in Path(directory).rglob('*.json'):\n        dataset = read_file(json_file)\n        if not dataset:\n            continue\n\n        html_file = json_file.with_suffix('.html')\n        html_content = \"\"\"\n        <html>\n        <head>\n            <style>\n                table {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th, td {\n                    border: 1px solid black;\n                    padding: 8px;\n                    text-align: left;\n                    white-space: pre-line;\n                    vertical-align: top;\n                    word-wrap: break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        \"\"\"\n        column_count = len(dataset[0].keys())\n        column_width = 100 / column_count  # Calculate the width for each column based on the number of columns\n        for key in dataset[0].keys():\n            html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\n        html_content += \"\"\"\n                    </tr>\n                </thead>\n                <tbody>\n        \"\"\"\n        for entry in dataset:\n            html_content += \"<tr>\"\n            for key in entry:\n                # Convert \\n to HTML line breaks\n                value = escape(str(entry[key]))\n                value = preserve_spacing(value)\n                value = value.replace('\\n', '<br/>')\n                html_content += f\"<td>{value}</td>\"\n            html_content += \"</tr>\"\n\n        html_content += \"\"\"\n                </tbody>\n            </table>\n        </body>\n        </html>\n        \"\"\"\n        html_file_path = json_file.with_suffix('.html')\n        try:   \n            with open(html_file_path, 'w', encoding='utf-8') as file:\n                file.write(html_content)\n        except:\n            logging.save(logging.info(f'Failed saving: {html_file_path}'))\n\n\ndef combine_json_files(directory: str) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Combine all JSON files in the output directory into 'instruct.json', and then remove duplicates.\n    Args:\n        directory (str): The directory where the output files are located.\n    Returns:\n        A dictionary containing the 'instruct_list' datasets.\n    \"\"\"\n   \n    def remove_duplicate_dataset_entries(dataset: List[Dict], key1: str, key2: str) -> List[Dict]:\n        \"\"\"\n        Remove duplicate entries from the provided dataset based on the provided keys.\n        Args:\n            dataset (List[Dict]): The dataset to remove duplicates from.\n            key1 (str): The first key to check for duplicates.\n            key2 (str): The second key to check for duplicates.\n        Returns:\n            A dataset without duplicate entries.\n        \"\"\"\n        seen = set()\n        result = []\n        for item in dataset:\n            if (item[key1], item[key2]) not in seen:\n                seen.add((item[key1], item[key2]))\n                result.append(item)\n        return result\n\n    instruct_data = []\n    for file_name in ['instruct.json']:\n        file_path = Path(directory) / file_name\n        combined_data = []\n        for json_file in Path(directory).rglob(f'*.{file_name}'):\n            json_file_data = read_file(json_file)\n            combined_data.extend(json_file_data)\n            combined_data = remove_duplicate_dataset_entries(combined_data, 'instruction', 'output')\n            instruct_data = combined_data.copy()\n            # gen training datasets that contains purpose and graph data formatted as follow for each item in the dataset:\n            purpose_data = [item for item in combined_data if item['instruction'].startswith('1) Describe the purpose')]\n            graph_data = [item for item in combined_data if item['instruction'].startswith('What is the call code graph')]\n            code_output = []\n            graph_output = []\n            for item in purpose_data:\n                code_output.append({'instruction': 'Define the Python code file that is described as follows:\\n'+ item['output'], 'output': item['input']})\n            for item in graph_data:\n                graph_output.append({'instruction': 'Define the call code graph for Python file:\\n' + item['input'], 'output': item['output']})\n            code_graph_output = code_output + graph_output\n            write_file(code_graph_output, Path(directory) / 'training.json')\n\n        write_file(combined_data, file_path)\n\n    # Save html file for each json file in the output directory\n    convert_json_to_html(directory)\n    return {'instruct_list': instruct_data}\n\n\ndef create_code_graph(file_details: Dict, base_name: str, output_subdir: Path) -> None:\n    \"\"\"\n    Generate graphs from the file_details and save them as PNG images.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        base_name (str): The base name of the output files.\n        output_subdir (Path): The subdirectory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    graph_type = 'entire_code_graph'\n    output_file = output_subdir / f'{base_name}.{graph_type}.png'\n\n    # Create graphs, add nodes, and add edges\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n    for edge in file_details['file_info'][graph_type]['edges']:\n        source, target = edge['source'], edge['target']\n        if source in G.nodes and target in G.nodes:\n           G.add_edge(source, target, **{k: v for k, v in edge.items() if k in ['target_inputs', 'target_returns']})\n    # Draw graphs\n    plt.figure(figsize=(20, 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True, font_weight='bold', font_size = 8, node_shape='s', node_size=500, width=1, arrowsize=12)\n    edge_labels = {}\n    for edge in G.edges(data=True):\n        label = []\n        if 'target_inputs' in edge[2] and edge[2]['target_inputs']:\n            label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\")\n        if 'target_returns' in edge[2] and edge[2]['target_returns']:\n            label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\")\n        edge_labels[(edge[0], edge[1])] = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n    plt.savefig(output_file) # Save the figure\n    plt.close()  # Close the figure\n\n\ndef save_python_data(file_details: dict, instruct_list: list, relative_path: Path, output_dir: str) -> None:\n    \"\"\"\n    Save Python file details as a YAML file, the instruction data as a JSON file, and code graphs.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        instruct_list (list): The instruction data extracted from the Python file.\n        relative_path (Path): The relative path to the Python file.\n        output_dir (str): The directory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir = Path(output_dir) / relative_path.parts[0]\n    output_subdir.mkdir(parents=True, exist_ok=True)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    # write instrunct.json files\n    file_names = [f'{base_name}.instruct.json', f'{base_name}.details.yaml']\n    contents = [instruct_list, file_details]\n\n    for file_name, content in zip(file_names, contents):\n        write_file(content, output_subdir / file_name)\n\n    try:\n        create_code_graph(file_details, base_name, output_subdir)\n    except:\n        logging.info(f'Error creating graph for {base_name}')\n"
    },
    {
        "instruction": "Define the Python code file that is described as follows:\nThe 'py2dataset.setup.py' file is a setup script that uses the setuptools library to install py2dataset package and its dependencies in the Python environment. The code opens a file called README.md using the \"with open()\" function, reads its content, and assigns it to the variable 'long_description'. Then, it creates a dictionary object named 'setup()' that contains metadata for the package including the name of the package ('py2dataset'), version number ('0.1'), author information, description, long_description, url, module names, classifiers, and dependencies. The entry point is defined as 'console_scripts', which means it can be executed from the command line by typing 'py2dataset' in the terminal. Finally, it specifies the package directory ('package_dir') and installs the package.\r\n\r\n1. Purpose: This file sets up the py2dataset package for installation in the Python environment.\r\n2. Functions:\r\n- setup(): It creates a dictionary object named 'setup()' with various metadata for the package and passes it as an argument to setuptools' setup() function that performs necessary configurations before installing the package. This function contains four keys - name, version, author, author_email, long_description.\r\n\r\n3. Inputs: The function does not take any input.\r\n4. Outputs: None, this is a setup file to be executed on installation.\r\n5. Variables: \r\n- long_description (string): This variable contains the content of README.md file that describes the package in detail.\r\n- py_modules (list): It is a list containing 'py2dataset' and 'get_python_file_details'.\r\n- classifiers (list): A list of strings that specify the type of Python environment required for this package, i.e., >=3.8.\r\n- install_requires (list): A list of dependencies required by py2dataset package, such as 'matplotlib', 'networkx' etc. If not found, the corresponding modules are automatically downloaded during installation\r\n\r\nHere's an itemized explanation step-by-step of how the script works: \r\n\r\n1. Opens the file called \"README.md\" using the \"with open()\" function.\r\n2. Assigns its content to a variable named 'long_description'.\r\n3. Creates a dictionary object named 'setup()' with various metadata for the package including name, version, author, author email, description and long_description content from the file.\r\n4. Installs 'setuptools', 'matplotlib', 'networkx', 'ctransformers' and 'pyyaml'.\r\n5. Adds 'entry point' named 'console_scripts' to execute the package from command line by typing 'py2dataset'.\r\n6. Specifies the package directory as '.\\\\' for py2dataset.\r\n7. Installs the package using setuptools' setup() function.",
        "output": "from setuptools import setup\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"py2dataset\",\n    version=\"0.1\",\n    author=\"Jeff Meloy\",\n    author_email=\"jeffmeloy@gmail.com\",\n    description=\"A tool to generate structured datasets from Python source code\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/jeffmeloy/py2dataset\",\n    py_modules=[\"py2dataset\", \"get_python_file_details\", \"get_python_json\"],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires='>=3.8',\n    install_requires=[\n        \"matplotlib\",\n        \"networkx\",\n        \"ctransformers\",\n        \"pyyaml\"\n    ],\n    entry_points={'console_scripts': ['py2dataset = py2dataset:main']},\n    packages=['py2dataset'],\n    package_dir={'py2dataset': '.\\\\'},\n)"
    },
    {
        "instruction": "Define the call code graph for Python file:\n\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport yaml\nimport importlib\nfrom typing import Dict, List \nfrom pathlib import Path\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"What are the dependencies of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"internal_code_graph\",\n            \"text\": \"What is the call code graph of the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"What are the structural relationships between the functions and classes defined and used in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"What functions are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },      \n        {\n            \"id\": \"file_classes\",\n            \"text\": \"What classes are defined in the Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"What are the inputs to the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"What is the docstring of the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"What calls are made in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"What variables are defined in the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        }, \n        {\n            \"id\": \"function_returns\",\n            \"text\": \"What are the returned items from the function: '{function_name}' in the Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"What are the methods defined within the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"What is the docstring of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"What are the attributes of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"What variables are defined in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"What is the Inheritance of the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"What are the inputs to method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"What is the docstring of the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"What calls are made in the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"What are the returns from the method: '{method_name}' in the class: '{class_name}' in the Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {   \n            \"id\": \"file_purpose\",\n            \"text\": \"1) Describe the purpose and processing summary of the Python file: '{filename}; 2) Provide an itemized detailed description of each applicable function, class, and method; 3) Explain what each of input, output, and variable do within the file.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible \n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 8400,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except: # get default questions if can't read questions_pathname file \n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\": \n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else: \n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except ImportError or AttributeError or Exception as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")    \n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    return instantiate_model(model_config['inference_model']), model_config['prompt_template']\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "{'nodes': ['get_default_questions', 'get_default_model_config', 'get_output_dir', 'get_questions', 'instantiate_model', 'get_model', 'write_questions_file', 'write_model_config_file', 'os.path.abspath', 'os.makedirs', 'logging.info', 'os.path.join', 'os.getcwd', 'open', 'json.load', \"model_config['model_import_path'].rsplit\", 'getattr', 'importlib.import_module', 'inference_function', 'model_params.pop', 'ModelClass', 'yaml.safe_load', 'Path(output_dir).is_dir', 'Path', 'json.dump', 'yaml.dump'], 'edges': [{'source': 'get_output_dir', 'target': 'os.path.abspath', 'target_inputs': ['output_dir or OUTPUT_DIR']}, {'source': 'get_output_dir', 'target': 'os.makedirs', 'target_inputs': ['output_dir']}, {'source': 'get_output_dir', 'target': 'logging.info', 'target_inputs': [\"f'Using output directory: {output_dir}'\"]}, {'source': 'get_questions', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'QUESTIONS_FILE']}, {'source': 'get_questions', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_questions', 'target': 'open', 'target_inputs': ['questions_pathname', \"'r'\"]}, {'source': 'get_questions', 'target': 'json.load', 'target_inputs': ['f']}, {'source': 'get_questions', 'target': 'logging.info', 'target_inputs': [\"f'Questions file not valid: {questions_pathname} Using default questions'\"]}, {'source': 'get_questions', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'instantiate_model', 'target': \"model_config['model_import_path'].rsplit\", 'target_inputs': [\"'.'\", '1']}, {'source': 'instantiate_model', 'target': 'getattr', 'target_inputs': ['ModelClass', 'inference_function_name']}, {'source': 'instantiate_model', 'target': 'importlib.import_module', 'target_inputs': ['module_name']}, {'source': 'instantiate_model', 'target': 'inference_function', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'model_params.pop', 'target_inputs': [\"'model_path'\"]}, {'source': 'instantiate_model', 'target': 'ModelClass', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'logging.info', 'target_inputs': [\"f'Failed to instantiate the model. Error: {e}'\"]}, {'source': 'get_model', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'MODEL_CONFIG_FILE']}, {'source': 'get_model', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_model', 'target': 'open', 'target_inputs': ['model_config_pathname', \"'r'\"]}, {'source': 'get_model', 'target': 'yaml.safe_load', 'target_inputs': ['config_file']}, {'source': 'get_model', 'target': 'logging.info', 'target_inputs': [\"f'Model config file not valid: {model_config_pathname} Using default model config'\"]}, {'source': 'get_model', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'get_model', 'target': 'instantiate_model', 'target_inputs': [\"model_config['inference_model']\"], 'target_returns': ['model', 'None']}, {'source': 'write_questions_file', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'write_questions_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_questions_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, QUESTIONS_FILE)', \"'w'\"]}, {'source': 'write_questions_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'QUESTIONS_FILE']}, {'source': 'write_questions_file', 'target': 'json.dump', 'target_inputs': ['questions', 'file']}, {'source': 'write_model_config_file', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'write_model_config_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_model_config_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, MODEL_CONFIG_FILE)', \"'w'\"]}, {'source': 'write_model_config_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'MODEL_CONFIG_FILE']}, {'source': 'write_model_config_file', 'target': 'yaml.dump', 'target_inputs': ['model_config', 'file']}]}"
    },
    {
        "instruction": "Define the call code graph for Python file:\n\"\"\"\nGenerates JSON format question-answer pairs and instructions for a Python file\nRequirements:\n[req01] The `DatasetGenerator` class shall:\n        a. Accept a Python file path (str), file details (Dict), base name (str), list of questions (List[Dict]), use_llm flag (bool), language model (object), and prompt (str) as input during instantiation.\n        b. Initialize and store the Python file path, file details, base name, list of questions, use_llm flag, language model, and prompt as class attributes.\n        c. Provide the `clean_and_get_unique_elements` method to clean an input string (str) and return a string of unique elements.\n        d. Provide the `add_to_list` method to add a response (str) to a list (List[Dict]).\n        e. Provide the `get_response_from_llm` method to retrieve a response from the language model.\n        f. Provide the `process_question` method to process a question and add the generated response to the instruct_list.\n        g. Provide the `process_question_type` method to process questions related to a file, function, class, or method.\n        h. Provide the `generate` method to generate responses for all questions in the list and return the instruct_list.\n[req02] The `get_python_datasets` function shall:\n        a. Accept a Python file path (str), file details (Dict), base name (str), list of questions (List[Dict]), use_llm flag (bool), language model (object), and prompt (str) as input.\n        b. Create an instance of the `DatasetGenerator` class using the provided input.\n        c. Generate question-answer pairs and instructions using the `generate` method of the `DatasetGenerator` instance.\n        d. Return the generated `instruct_list`.\n\"\"\"\nimport logging\nimport re\nfrom typing import Dict, List, Tuple\n\n# Set up logging\nlogging.basicConfig(\n    format='%(asctime)s - %(levelname)s - %(message)s', \n    level=logging.INFO\n)\nlogger = logging.getLogger(__name__)\n\nclass DatasetGenerator:\n    \"\"\"\n    Generate JSON formatted dictionary outputs for a Python file.\n    Attributes:\n        file_path (str): The path to the Python file.\n        file_details (Dict[str, Any]): Details of the Python file.\n        base_name (str): The base name of the Python file.\n        questions (List[Dict[str, str]]): Questions for generating responses.\n        instruct_list (List[Dict[str, str]]): Storage for generated instructions.\n        question_mapping (Dict[str, str]): Mapping of question types to keys in file details.\n        use_llm (bool): Flag indicating if a language model should be used.\n        llm (object): The language model for generating responses.\n        prompt (str): The prompt format for querying the language model.\n    Methods:\n        clean_and_get_unique_elements(input_str: str) -> str: \n            Clean and return unique elements from an input string.\n        add_to_list(list_to_update: List[Dict], query: str, response: str, additional_field=None) -> List[Dict]: \n            Add response to the instruct list.\n        get_response_from_llm(query: str, context: str) -> str:\n            Get language model response to query for given context.\n        process_question(question_type: str, question_id: str, query: str, context: str, info: Dict) -> None:\n            Process question and add generated response to the instruct_list.\n        process_question_type(question_type: str, question_id: str, question_text: str) -> None:\n            Process question related to file, function, class, or method.\n        generate() -> Tuple[List[Dict], List[Dict]]:\n            Generate responses for all the questions and return the instruct_list.\n    \"\"\"\n    def __init__(self, file_path: str, file_details: Dict, base_name: str, questions: List[Dict], llm: object, prompt: str) -> None:\n        self.file_path = file_path\n        self.file_details = file_details\n        self.base_name = base_name\n        self.questions = questions\n        self.llm = llm\n        self.prompt = prompt\n        if self.llm is None:\n            self.use_llm = False\n        else:\n            self.use_llm = True\n        self.instruct_list = []\n        self.question_mapping = {\n            'file': 'file',\n            'function': 'functions',\n            'class': 'classes',\n            'method': 'classes'\n        }\n\n    @staticmethod\n    def clean_and_get_unique_elements(input_str: str) -> str:\n        \"\"\"\n        Clean input string and return string of unique elements.\n        Args:\n            input_str (str): The input string to be cleaned.\n        Returns:\n            str: The cleaned string.\n        \"\"\"\n        cleaned_elements = set(re.sub(r'[^\\w\\-_>\\s:/.]', '', element.strip())\n                               for element in re.sub(r'\\s+', ' ', input_str).split(','))\n        return ', '.join(cleaned_elements)\n\n    @staticmethod\n    def add_to_list(list_to_update: List[Dict], query: str, response: str, additional_field=None) -> List[Dict]:\n        \"\"\"\n        Adds response to instruct list.\n        Args:\n            list_to_update (List[Dict]): The list to be updated.\n            query (str): The query to be added.\n            response (str): The response to be added.\n            additional_field (str): The additional field to be added.\n        Returns:\n            List[Dict]: The updated list.\n        \"\"\"\n        if response and response.strip() and response != 'None':\n            list_to_update.append(\n                {'instruction': query, 'input' : additional_field, 'output': response}\n                if additional_field else\n                {'question': query, 'answer': response}\n            )\n        return list_to_update\n\n    def get_response_from_llm(self, query: str, context: str) -> str:\n        \"\"\"\n        Get language model response to query for given context.\n        Args:\n            query (str): The query to be used for generating the response.\n            context (str): The context to be used for generating the response.\n        Returns:\n            str: The generated response.\n        \"\"\"\n        # Update the context with the selected instructions from the instruct_list\n        excluded_instructions = [\"What is the call code graph\", \"What is the docstring\"]\n        filtered_instruct_list = [item for item in self.instruct_list if not any(item['instruction'].startswith(prefix) for prefix in excluded_instructions)]\n        past_instructs = \"\\n\".join([f\"Instruction: {item['instruction']} \\nOutput: {item['output']}\" for item in filtered_instruct_list])\n        full_context = context + \"\\n\" + \"Here's some detail about this code:\" + \"\\n\" + past_instructs\n\n        try:\n            prompt = self.prompt.format(context=full_context, query=query)\n            logging.info(f'Query: {query}')\n            response = self.llm(prompt)\n            logging.info(f'Response: {response}')\n        except:\n            logger.error('Failed to generate model response')\n        return response\n\n    def process_question(self, question_type: str, question_id: str, query: str, context: str, info: Dict) -> None:\n        \"\"\"\n        Process question and add the generated response to the instruct_list.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            query (str): The query to be processed.\n            context (str): The context to be used for generating the response.\n            info (Dict): The information of the Python file.\n        Returns:\n            None\n        \"\"\"\n        if question_id.endswith('code_graph'):\n            response = info.get(question_id, {})\n        else:\n            response = self.get_response_from_llm(query, context) if self.use_llm and question_id.endswith('purpose') else self.clean_and_get_unique_elements(str(info.get(question_id, '')))\n        if response and response != 'None':\n            response_str = str(response).strip()\n            if response_str:\n                self.instruct_list.append({'instruction': query, 'input': context, 'output': response_str})\n\n    @staticmethod\n    def get_string_from_info(info, item_type):\n        if info[item_type]:\n            items = [item.strip() for item in str(info[item_type]).split(',') if item]\n            return ', '.join(items)\n        return ''\n\n    def process_question_type(self, question_type: str, question_id: str, question_text: str) -> None:\n        \"\"\"\n        Process questions related to a file, function, class, or method.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            question_text (str): The text of the question to be processed.\n        Returns:\n            None\n        \"\"\"\n        if question_type == 'file':\n            query = question_text.format(filename=self.base_name)\n            context = self.file_details['file_info']['file_code']\n            info = self.file_details['file_info']\n            self.process_question(question_type, question_id, query, context, info)\n        elif question_type == 'method':  \n            for class_name, class_info in self.file_details['classes'].items():\n                for key, method_info in class_info.items():\n                    if key.startswith('class_method_'):\n                        method_name = key[len('class_method_'):]\n                        context = method_info['method_code']\n                        mapping = {'class_name': class_name, 'method_name': method_name}\n                        query = question_text.format(filename=self.base_name, **mapping)\n                        self.process_question(question_type, question_id, query, context, method_info)\n        else:  # if question_type == 'function' or question_type == 'class'\n            for name, info in self.file_details[self.question_mapping[question_type]].items():\n                context = info[f'{question_type}_code']\n                mapping = {f'{question_type}_name': name}\n                if question_id == f'{question_type}_purpose' and self.use_llm:\n                    variables_string = self.get_string_from_info(info, f'{question_type}_variables')\n                    inputs_string = self.get_string_from_info(info, f'{question_type}_inputs')\n                    combined_string = ', '.join([s for s in [variables_string, inputs_string] if s])\n                    mapping[f'{question_type}_variables'] = self.clean_and_get_unique_elements(combined_string)\n                    # get methods to include in mapping for query\n                    if question_type == 'class':\n                        methods_string = self.get_string_from_info(info, f'{question_type}_methods')\n                        mapping[f'{question_type}_methods'] = methods_string\n\n                query = question_text.format(filename=self.base_name, **mapping)\n                self.process_question(question_type, question_id, query, context, info)\n\n    def generate(self) -> Tuple[List[Dict], List[Dict]]:\n        \"\"\"\n        Generate responses for all the questions and returns the instruct_list.\n        Args:\n            None\n        Returns:\n            Tuple[List[Dict], List[Dict]]: The generated question-answer pairs and instructions.\n        \"\"\"\n        for question in self.questions:\n            self.process_question_type(question['type'], question['id'], question['text'])\n        return self.instruct_list\n\n\ndef get_python_datasets(file_path: str, file_details: Dict, base_name: str, questions: List[Dict], \n                        llm: object, prompt: str) -> Tuple[List[Dict], List[Dict]]:\n    \"\"\"\n    Extract information from a Python file and return it in JSON format.\n    Args:\n        file_path (str): The path to the Python file.\n        file_details (Dict): The details of the file.\n        base_name (str): The base Python code filename.\n        questions (List[Dict]): The list of questions.\n        llm (object): The language model to be used for generating responses.\n        prompt (str): The prompt to be used for generating responses.\n    Returns:\n        Tuple[List[Dict], List[Dict]]: Extracted information in JSON format.\n    \"\"\"\n    generator = DatasetGenerator(file_path, file_details, base_name, questions, llm, prompt)\n    return generator.generate()\n",
        "output": "{'nodes': ['DatasetGenerator', 'DatasetGenerator.__init__', 'DatasetGenerator.clean_and_get_unique_elements', 'DatasetGenerator.add_to_list', 'DatasetGenerator.get_response_from_llm', 'DatasetGenerator.process_question', 'DatasetGenerator.get_string_from_info', 'DatasetGenerator.process_question_type', 'DatasetGenerator.generate', 'get_python_datasets', 'generator.generate', 'set', 're.sub', 'element.strip', \"re.sub('\\\\\\\\s+', ' ', input_str).split\", \"', '.join\", 'response.strip', 'list_to_update.append', 'any', \"item['instruction'].startswith\", \"'\\\\n'.join\", 'self.prompt.format', 'logging.info', 'self.llm', 'logger.error', 'question_id.endswith', 'info.get', 'str', 'str(response).strip', 'self.instruct_list.append', 'item.strip', 'str(info[item_type]).split', 'question_text.format', \"self.file_details['classes'].items\", 'class_info.items', 'key.startswith', 'len', 'self.file_details[self.question_mapping[question_type]].items'], 'edges': [{'source': 'DatasetGenerator', 'target': 'DatasetGenerator.__init__', 'target_inputs': ['self', 'file_path', 'file_details', 'base_name', 'questions', 'llm', 'prompt'], 'target_returns': []}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.clean_and_get_unique_elements', 'target_inputs': ['input_str'], 'target_returns': [\"', '.join(cleaned_elements)\"]}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.add_to_list', 'target_inputs': ['list_to_update', 'query', 'response', 'additional_field'], 'target_returns': ['list_to_update']}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.get_response_from_llm', 'target_inputs': ['self', 'query', 'context'], 'target_returns': ['response']}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.process_question', 'target_inputs': ['self', 'question_type', 'question_id', 'query', 'context', 'info'], 'target_returns': []}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.get_string_from_info', 'target_inputs': ['info', 'item_type'], 'target_returns': [\"', '.join(items)\", \"''\"]}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.process_question_type', 'target_inputs': ['self', 'question_type', 'question_id', 'question_text'], 'target_returns': []}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.generate', 'target_inputs': ['self'], 'target_returns': ['self.instruct_list']}, {'source': 'DatasetGenerator.clean_and_get_unique_elements', 'target': 'set', 'target_inputs': [\"(re.sub('[^\\\\\\\\w\\\\\\\\-_>\\\\\\\\s:/.]', '', element.strip()) for element in re.sub('\\\\\\\\s+', ' ', input_str).split(','))\"]}, {'source': 'DatasetGenerator.clean_and_get_unique_elements', 'target': 're.sub', 'target_inputs': [\"'\\\\\\\\s+'\", \"' '\", 'input_str']}, {'source': 'DatasetGenerator.clean_and_get_unique_elements', 'target': 'element.strip', 'target_inputs': []}, {'source': 'DatasetGenerator.clean_and_get_unique_elements', 'target': \"re.sub('\\\\\\\\s+', ' ', input_str).split\", 'target_inputs': [\"','\"]}, {'source': 'DatasetGenerator.clean_and_get_unique_elements', 'target': \"', '.join\", 'target_inputs': ['cleaned_elements']}, {'source': 'DatasetGenerator.add_to_list', 'target': 'response.strip', 'target_inputs': []}, {'source': 'DatasetGenerator.add_to_list', 'target': 'list_to_update.append', 'target_inputs': [\"{'instruction': query, 'input': additional_field, 'output': response} if additional_field else {'question': query, 'answer': response}\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'any', 'target_inputs': [\"(item['instruction'].startswith(prefix) for prefix in excluded_instructions)\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': \"item['instruction'].startswith\", 'target_inputs': ['prefix']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': \"'\\\\n'.join\", 'target_inputs': ['[f\"Instruction: {item[\\'instruction\\']} \\\\nOutput: {item[\\'output\\']}\" for item in filtered_instruct_list]']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'self.prompt.format', 'target_inputs': []}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'logging.info', 'target_inputs': [\"f'Response: {response}'\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'self.llm', 'target_inputs': ['prompt']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'logger.error', 'target_inputs': [\"'Failed to generate model response'\"]}, {'source': 'DatasetGenerator.process_question', 'target': 'question_id.endswith', 'target_inputs': [\"'purpose'\"]}, {'source': 'DatasetGenerator.process_question', 'target': 'info.get', 'target_inputs': ['question_id', \"''\"]}, {'source': 'DatasetGenerator.process_question', 'target': 'DatasetGenerator.get_response_from_llm', 'target_inputs': ['self', 'query', 'context'], 'target_returns': ['response']}, {'source': 'DatasetGenerator.process_question', 'target': 'DatasetGenerator.clean_and_get_unique_elements', 'target_inputs': ['input_str'], 'target_returns': [\"', '.join(cleaned_elements)\"]}, {'source': 'DatasetGenerator.process_question', 'target': 'str', 'target_inputs': ['response']}, {'source': 'DatasetGenerator.process_question', 'target': 'str(response).strip', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question', 'target': 'self.instruct_list.append', 'target_inputs': [\"{'instruction': query, 'input': context, 'output': response_str}\"]}, {'source': 'DatasetGenerator.get_string_from_info', 'target': 'item.strip', 'target_inputs': []}, {'source': 'DatasetGenerator.get_string_from_info', 'target': 'str(info[item_type]).split', 'target_inputs': [\"','\"]}, {'source': 'DatasetGenerator.get_string_from_info', 'target': 'str', 'target_inputs': ['info[item_type]']}, {'source': 'DatasetGenerator.get_string_from_info', 'target': \"', '.join\", 'target_inputs': ['items']}, {'source': 'DatasetGenerator.process_question_type', 'target': 'question_text.format', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'DatasetGenerator.process_question', 'target_inputs': ['self', 'question_type', 'question_id', 'query', 'context', 'info'], 'target_returns': []}, {'source': 'DatasetGenerator.process_question_type', 'target': \"self.file_details['classes'].items\", 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'class_info.items', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'key.startswith', 'target_inputs': [\"'class_method_'\"]}, {'source': 'DatasetGenerator.process_question_type', 'target': 'len', 'target_inputs': [\"'class_method_'\"]}, {'source': 'DatasetGenerator.process_question_type', 'target': 'self.file_details[self.question_mapping[question_type]].items', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'DatasetGenerator.get_string_from_info', 'target_inputs': ['info', 'item_type'], 'target_returns': [\"', '.join(items)\", \"''\"]}, {'source': 'DatasetGenerator.process_question_type', 'target': \"', '.join\", 'target_inputs': ['[s for s in [variables_string, inputs_string] if s]']}, {'source': 'DatasetGenerator.process_question_type', 'target': 'DatasetGenerator.clean_and_get_unique_elements', 'target_inputs': ['input_str'], 'target_returns': [\"', '.join(cleaned_elements)\"]}, {'source': 'DatasetGenerator.generate', 'target': 'DatasetGenerator.process_question_type', 'target_inputs': ['self', 'question_type', 'question_id', 'question_text'], 'target_returns': []}, {'source': 'get_python_datasets', 'target': 'DatasetGenerator', 'target_inputs': ['file_path', 'file_details', 'base_name', 'questions', 'llm', 'prompt'], 'target_returns': []}, {'source': 'get_python_datasets', 'target': 'generator.generate', 'target_inputs': []}]}"
    },
    {
        "instruction": "Define the call code graph for Python file:\n\"\"\"\nUse AST to extract details from a Python file, determine the code call graph and return it as a dictionary.\nRequirements:\n[req01] The get_all_calls function shall:\n        a. Accept a node as an argument.\n        b. Recursively find all function calls in the subtree rooted at the node.\n        c. Return a list of all function calls in the subtree rooted at the node.\n[req02] The `CodeVisitor` class shall:\n        a. Accept the source code as input\n        b. Use the AST to extract details about the code.\n        c. Inherit from `ast.NodeVisitor`.\n        d. Implement the `visit_FunctionDef` method to gather details about functions.\n        e. Implement the `visit_ClassDef` method to gather details about classes.\n        f. Implement the `extract_details` method to parse information about a given node.\n        g. Implement the `analyze` method to traverse the AST, list all nodes within the current file, and populate the 'file_info' attribute with comprehensive file details.\n[req03] The `code_graph` function shall:\n        a. Accept the file summary and file details as input.\n        b. Construct a dictionary with nodes and edges that illustrate code relationships.\n        c. Define elements such as function nodes, class nodes, and method nodes.\n        d. Specify edges to represent relationships like function calls, method calls, and class inheritance.\n        e. Return a dictionary representation of the code graph, aiding in understanding the code's structure and inter-relationships.\n[req04] The `get_python_file_details` function shall:\n        a. Accept a file path as an argument.\n        b. Extract detailed information from the specified Python file using the AST and the `CodeVisitor` class.\n        c. Include the entire file graph in the returned details.\n        d. Return a dictionary encompassing the extracted file details.\n\"\"\"\nimport ast\nimport re\nimport json\nimport logging\nimport networkx as nx\nfrom typing import Dict, List, Optional, Union\n\ndef get_all_calls(node):\n    \"\"\"\n    Recursively find all function calls in the subtree rooted at `node`.\n    Args:\n        node: ast.AST: The node to start the search from.\n    Returns:\n        list: A list of all function calls in the subtree rooted at `node`.\n    \"\"\"\n    calls = {}\n    for child in ast.iter_child_nodes(node):\n        if isinstance(child, ast.Call):\n            calls[ast.unparse(child.func)] = [ast.unparse(arg) for arg in child.args]\n        calls.update(get_all_calls(child))\n    return calls\n\nclass CodeVisitor(ast.NodeVisitor):\n    \"\"\"\n    Visitor class for traversing an AST (Abstract Syntax Tree) and extracting details about the code.\n    Attributes:\n        code (str): The source code.\n        functions(Dict): details about functions in the code.\n        classes (Dict): details about classes in the code.\n        file_info (Dict): details about the file.\n    Methods:\n        visit_FunctionDef(node: ast.FunctionDef) -> None: \n            Extract details about a function.\n        visit_ClassDef(node: ast.ClassDef) -> None: \n            Extract details about a class.\n        extract_details(node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]: \n            Extract details about a node.\n        analyze(node: ast.AST) -> None: \n            Populate file_info with details about the file.\n    \"\"\"\n    def __init__(self, code: str):\n        \"\"\"\n        Initialize a new instance of the class.\n        Args:\n            code: str: The source code.\n        Returns:\n            None\n        \"\"\"\n        self.code: str = code\n        self.functions: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.classes: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.file_info: Dict[str, Union[str, List[str]]] = {}\n        self.current_class: str = None\n    \n    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n        \"\"\"\n        Extract details about a function.\n        Args:\n            node: ast.FunctionDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        details = self.extract_details(node, 'method' if self.current_class else 'function')\n        if self.current_class:\n            self.classes[self.current_class][f'class_method_{node.name}'] = details\n        else:\n            self.functions[node.name] = details\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n        \"\"\"\n        Extract details about a class.\n        Args:\n            node: ast.ClassDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        self.classes[node.name] = self.extract_details(node, 'class') # populate class dictionary when class definition found in AST\n        self.current_class = node.name  # set current_class to indicate inside a class\n        self.generic_visit(node) # continue AST traversal to the next node\n        self.current_class = None  # reset current_class when finished with this class\n    \n    def extract_details(self, node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]:\n        \"\"\"\n        Extract details about a node.\n        Args:\n            node: ast.AST: The node to extract details from.\n            node_type: str: The type of node.\n        Returns:\n            Dict[str, Union[str, List[str]]]: The details extracted from the node.\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        call_data = get_all_calls(node)\n        details = {\n            f\"{node_type}_name\": node.name, \n            f\"{node_type}_code\": ast.unparse(node),\n            f\"{node_type}_ast\": ast.dump(node, include_attributes=True), \n            f\"{node_type}_docstring\": ast.get_docstring(node),\n            f\"{node_type}_inputs\": [arg.arg for arg in node.args.args] if node_type in ['function', 'method'] else None,\n            f\"{node_type}_defaults\": [ast.unparse(d) for d in node.args.defaults] if node_type in ['function', 'method'] else None,\n            f\"{node_type}_returns\": [ast.unparse(subnode.value) if subnode.value is not None else \"None\" for subnode in node_walk if isinstance(subnode, ast.Return)],\n            f\"{node_type}_calls\": list(call_data.keys()),\n            f\"{node_type}_call_inputs\": call_data, \n            f\"{node_type}_variables\": list({ast.unparse(target) for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Name)}),\n            f\"{node_type}_decorators\": list({ast.unparse(decorator) for decorator in node.decorator_list} if node.decorator_list else set()),\n            f\"{node_type}_annotations\": list({ast.unparse(subnode.annotation) for subnode in node_walk if isinstance(subnode, ast.AnnAssign) and subnode.annotation is not None}),\n            f\"{node_type}_properties\": list({ast.unparse(subnode) for subnode in node_walk if isinstance(subnode, ast.Attribute) and isinstance(subnode.ctx, ast.Store)}),\n        }  \n        if node_type in ['class', 'method']:\n            if node_type == 'method' and self.current_class: # find attributes defined as self.attribute\n                attributes = [target.attr for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute) and isinstance(target.value, ast.Name) and target.value.id == 'self']\n                if attributes: # if this class already has some attributes, add to them\n                    if \"class_attributes\" in self.classes[self.current_class]:\n                        self.classes[self.current_class][\"class_attributes\"].extend(attributes)\n                    else: # otherwise, start a new list of attributes for this class\n                        self.classes[self.current_class][\"class_attributes\"] = attributes\n            if node_type == 'class':\n                details.update({\n                    \"class_attributes\": [target.attr for subnode in node.body if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute)],\n                    \"class_methods\": [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\"],\n                    \"class_inheritance\": [ast.unparse(base) for base in node.bases] if node.bases else [],\n                    \"class_static_methods\": [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\" and any(isinstance(decorator, ast.Name) and decorator.id == \"staticmethod\" for decorator in subnode.decorator_list)],\n                    })\n        return details\n\n    def analyze(self, node: ast.AST) -> None:\n        \"\"\"\n        Traverse the AST rooted at 'node', create a list of all nodes within the current file, and populate 'file_info' with file details\n        Args:\n            node: ast.AST: The node to analyze.\n        Returns:\n            None\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        self.visit(node)\n        self.file_info = {\n            \"file_code\": self.code,\n            \"file_ast\" : ast.dump(node),\n            \"file_dependencies\": list({alias.name for subnode in node_walk if isinstance(subnode, ast.Import) for alias in subnode.names} | {subnode.module for subnode in node_walk if isinstance(subnode, ast.ImportFrom)}),\n            \"file_functions\": list(self.functions.keys()),\n            \"file_classes\": list(self.classes.keys()),\n        }\n        \n        # add file_summary to file_info\n        function_defs = [{func_name: {\"inputs\": details[\"function_inputs\"], \"calls\": details[\"function_calls\"], \"call_inputs\": details[\"function_call_inputs\"], \"returns\": details[\"function_returns\"]}} for func_name, details in self.functions.items()]\n        class_defs = []\n        for class_name, class_details in self.classes.items():\n            method_defs = {}\n            for method_name, details in class_details.items():\n                if method_name.startswith('class_method_'):\n                    method_defs[method_name[len('class_method_'):]] = {\"inputs\": details[\"method_inputs\"], \"calls\": details[\"method_calls\"], \"call_inputs\": details[\"method_call_inputs\"], \"returns\": details[\"method_returns\"]}\n            class_defs.append({class_name: {\"method_defs\": method_defs}})\n        self.file_info[\"file_summary\"] = { 'dependencies': self.file_info[\"file_dependencies\"], 'function_defs' : function_defs, 'class_defs' : class_defs}\n\ndef code_graph(file_summary: Dict[str, Union[Dict, str]]) -> Dict[str, Union[List[str], Dict[str, List[str]]]]:\n    \"\"\"\n    Create a dictionary representation of file details.\n    Args:\n        file_summary: Dict[str, Union[Dict, str]]: The details extracted from the file.\n    Returns:\n        dict: A dictionary with nodes and edges representing the relationships in the code.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Create lookup dictionaries for function and class method details\n    function_details_lookup = {}\n    for function_def in file_summary['function_defs']:\n        function_details_lookup.update(function_def)\n    class_method_details_lookup = {}\n    for class_def in file_summary['class_defs']:\n        for class_name, class_details in class_def.items(): # Extract class name and details\n            G.add_node(class_name) # Add class as a graph node\n            for method_name, method_details in class_details['method_defs'].items():\n                qualified_method_name = f'{class_name}.{method_name}' # Create method fully qualified name\n                G.add_node(qualified_method_name) # Add method as a graph node\n                class_method_details_lookup[qualified_method_name] = method_details  # Store method details \n                G.add_edge(class_name, qualified_method_name) # Add edge from class to method\n\n    # Helper function to extract edge data from target details\n    def get_edge_data_from_details(target_details: dict, source_details: dict, target: str) -> dict:\n        edge_data = {}\n        if target_details:\n            edge_data['target_inputs'] = target_details.get('inputs')\n            edge_data['target_returns'] = list(set(target_details.get('returns', [])))\n        if source_details and 'call_inputs' in source_details and target in source_details['call_inputs']:\n            edge_data['target_inputs'] = source_details['call_inputs'][target]     \n        return edge_data\n\n    # Helper function to add edge with data\n    def add_edge_with_data(source: str, target: str, init_method: Optional[str] = None) -> None:\n        target_details = class_method_details_lookup.get(init_method or target) or function_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        G.add_edge(source, target, **get_edge_data_from_details(target_details, source_details, target))\n\n    # Helper function to add edges for function or class method calls\n    def add_edges_for_calls(source_name, calls):\n        class_names = [list(class_def.keys())[0] for class_def in file_summary['class_defs']]\n        for called in calls:\n            called_class_name = called.split('.')[0]\n            if called.startswith(\"self.\"):\n                method_name = called.replace(\"self.\", \"\")\n                fully_qualified_name = f\"{source_name.split('.')[0]}.{method_name}\"\n                if fully_qualified_name in class_method_details_lookup:\n                    add_edge_with_data(source_name, fully_qualified_name)\n                    continue\n            if (\n                called in function_details_lookup or \n                called in class_method_details_lookup or \n                f\"{source_name.split('.')[0]}.{called}\" in class_method_details_lookup\n            ):\n                add_edge_with_data(source_name, called)\n            elif called_class_name in class_names:\n                init_method = None\n                init_method_name = f\"{called}.__init__\"\n                if init_method_name in class_method_details_lookup:\n                    init_method = init_method_name\n                add_edge_with_data(source_name, called, init_method)\n            else:\n                G.add_node(called)\n                add_edge_with_data(source_name, called)\n\n    # Add function nodes to graph and edges for function calls\n    for function_name in function_details_lookup.keys():\n        G.add_node(function_name)\n    for func_name, details in function_details_lookup.items():\n        add_edges_for_calls(func_name, details['calls'])\n\n    # Add edges for method calls\n    for qualified_method_name, details in class_method_details_lookup.items():\n        add_edges_for_calls(qualified_method_name, details['calls'])\n\n    # Add edge data to edges and create node and edges to return\n    for edge in G.edges:\n        source, target = edge\n        target_details = function_details_lookup.get(target) or class_method_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        edge_data = get_edge_data_from_details(target_details, source_details, target)\n        G[source][target].update(edge_data)\n    nodes = list(G.nodes)\n    edges = [{\"source\": edge[0], \"target\": edge[1], **edge[2]} for edge in G.edges.data()]\n    return {\"nodes\": nodes, \"edges\": edges}\n\n\ndef get_python_file_details(file_path: str) -> Dict[str, Union[Dict, str]]:\n    \"\"\"\n    Extract details from a Python file.\n    Args:\n        file_path: str: The path to the Python file.\n    Returns:\n        Dict[str, Union[Dict, str]]: The details extracted from the file.\n    \"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors='ignore') as f:\n            code = f.read()\n            tree = ast.parse(code)\n    except:\n        logging.warning(f\"Permission denied or syntax error in file: {file_path}\")\n        return None \n\n    visitor = CodeVisitor(code)\n    visitor.analyze(tree)\n    file_details = {'file_info': visitor.file_info, 'functions': visitor.functions, 'classes': visitor.classes}\n    file_details['file_info']['entire_code_graph'] = code_graph(file_details['file_info']['file_summary'])\n    file_details['file_info']['file_summary'] = json.dumps(file_details['file_info']['file_summary']).replace('\\\"','')\n    return file_details",
        "output": "{'nodes': ['CodeVisitor', 'CodeVisitor.__init__', 'CodeVisitor.visit_FunctionDef', 'CodeVisitor.visit_ClassDef', 'CodeVisitor.extract_details', 'CodeVisitor.analyze', 'get_all_calls', 'code_graph', 'get_edge_data_from_details', 'add_edge_with_data', 'add_edges_for_calls', 'get_python_file_details', 'ast.iter_child_nodes', 'isinstance', 'ast.unparse', 'calls.update', 'nx.DiGraph', 'function_details_lookup.update', 'class_def.items', 'G.add_node', \"class_details['method_defs'].items\", 'G.add_edge', 'target_details.get', 'list', 'set', 'class_method_details_lookup.get', 'function_details_lookup.get', 'class_def.keys', 'called.split', 'called.startswith', 'called.replace', 'source_name.split', 'function_details_lookup.keys', 'function_details_lookup.items', 'class_method_details_lookup.items', 'G[source][target].update', 'G.edges.data', 'open', 'f.read', 'ast.parse', 'logging.warning', 'visitor.analyze', \"json.dumps(file_details['file_info']['file_summary']).replace\", 'json.dumps', 'self.generic_visit', 'ast.walk', 'ast.dump', 'ast.get_docstring', 'call_data.keys', \"self.classes[self.current_class]['class_attributes'].extend\", 'details.update', 'any', 'self.visit', 'self.functions.keys', 'self.classes.keys', 'self.functions.items', 'self.classes.items', 'class_details.items', 'method_name.startswith', 'len', 'class_defs.append'], 'edges': [{'source': 'CodeVisitor', 'target': 'CodeVisitor.__init__', 'target_inputs': ['self', 'code'], 'target_returns': []}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.visit_FunctionDef', 'target_inputs': ['self', 'node'], 'target_returns': []}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.visit_ClassDef', 'target_inputs': ['self', 'node'], 'target_returns': []}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.extract_details', 'target_inputs': ['self', 'node', 'node_type'], 'target_returns': ['details']}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.analyze', 'target_inputs': ['self', 'node'], 'target_returns': []}, {'source': 'CodeVisitor.visit_FunctionDef', 'target': 'CodeVisitor.extract_details', 'target_inputs': ['self', 'node', 'node_type'], 'target_returns': ['details']}, {'source': 'CodeVisitor.visit_FunctionDef', 'target': 'self.generic_visit', 'target_inputs': ['node']}, {'source': 'CodeVisitor.visit_ClassDef', 'target': 'CodeVisitor.extract_details', 'target_inputs': ['self', 'node', 'node_type'], 'target_returns': ['details']}, {'source': 'CodeVisitor.visit_ClassDef', 'target': 'self.generic_visit', 'target_inputs': ['node']}, {'source': 'CodeVisitor.extract_details', 'target': 'list', 'target_inputs': ['{ast.unparse(subnode) for subnode in node_walk if isinstance(subnode, ast.Attribute) and isinstance(subnode.ctx, ast.Store)}']}, {'source': 'CodeVisitor.extract_details', 'target': 'ast.walk', 'target_inputs': ['node']}, {'source': 'CodeVisitor.extract_details', 'target': 'get_all_calls', 'target_inputs': ['node'], 'target_returns': ['calls']}, {'source': 'CodeVisitor.extract_details', 'target': 'ast.unparse', 'target_inputs': ['base']}, {'source': 'CodeVisitor.extract_details', 'target': 'ast.dump', 'target_inputs': ['node']}, {'source': 'CodeVisitor.extract_details', 'target': 'ast.get_docstring', 'target_inputs': ['node']}, {'source': 'CodeVisitor.extract_details', 'target': 'isinstance', 'target_inputs': ['decorator', 'ast.Name']}, {'source': 'CodeVisitor.extract_details', 'target': 'call_data.keys', 'target_inputs': []}, {'source': 'CodeVisitor.extract_details', 'target': 'set', 'target_inputs': []}, {'source': 'CodeVisitor.extract_details', 'target': \"self.classes[self.current_class]['class_attributes'].extend\", 'target_inputs': ['attributes']}, {'source': 'CodeVisitor.extract_details', 'target': 'details.update', 'target_inputs': [\"{'class_attributes': [target.attr for subnode in node.body if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute)], 'class_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != '__init__'], 'class_inheritance': [ast.unparse(base) for base in node.bases] if node.bases else [], 'class_static_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != '__init__' and any((isinstance(decorator, ast.Name) and decorator.id == 'staticmethod' for decorator in subnode.decorator_list))]}\"]}, {'source': 'CodeVisitor.extract_details', 'target': 'any', 'target_inputs': [\"(isinstance(decorator, ast.Name) and decorator.id == 'staticmethod' for decorator in subnode.decorator_list)\"]}, {'source': 'CodeVisitor.analyze', 'target': 'list', 'target_inputs': ['self.classes.keys()']}, {'source': 'CodeVisitor.analyze', 'target': 'ast.walk', 'target_inputs': ['node']}, {'source': 'CodeVisitor.analyze', 'target': 'self.visit', 'target_inputs': ['node']}, {'source': 'CodeVisitor.analyze', 'target': 'ast.dump', 'target_inputs': ['node']}, {'source': 'CodeVisitor.analyze', 'target': 'isinstance', 'target_inputs': ['subnode', 'ast.ImportFrom']}, {'source': 'CodeVisitor.analyze', 'target': 'self.functions.keys', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'self.classes.keys', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'self.functions.items', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'self.classes.items', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'class_details.items', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'method_name.startswith', 'target_inputs': [\"'class_method_'\"]}, {'source': 'CodeVisitor.analyze', 'target': 'len', 'target_inputs': [\"'class_method_'\"]}, {'source': 'CodeVisitor.analyze', 'target': 'class_defs.append', 'target_inputs': [\"{class_name: {'method_defs': method_defs}}\"]}, {'source': 'get_all_calls', 'target': 'ast.iter_child_nodes', 'target_inputs': ['node']}, {'source': 'get_all_calls', 'target': 'isinstance', 'target_inputs': ['child', 'ast.Call']}, {'source': 'get_all_calls', 'target': 'ast.unparse', 'target_inputs': ['arg']}, {'source': 'get_all_calls', 'target': 'calls.update', 'target_inputs': ['get_all_calls(child)']}, {'source': 'get_all_calls', 'target': 'get_all_calls', 'target_inputs': ['child'], 'target_returns': ['calls']}, {'source': 'code_graph', 'target': 'nx.DiGraph', 'target_inputs': []}, {'source': 'code_graph', 'target': 'function_details_lookup.update', 'target_inputs': ['function_def']}, {'source': 'code_graph', 'target': 'class_def.items', 'target_inputs': []}, {'source': 'code_graph', 'target': 'G.add_node', 'target_inputs': ['function_name']}, {'source': 'code_graph', 'target': \"class_details['method_defs'].items\", 'target_inputs': []}, {'source': 'code_graph', 'target': 'G.add_edge', 'target_inputs': ['source', 'target']}, {'source': 'code_graph', 'target': 'target_details.get', 'target_inputs': [\"'returns'\", '[]']}, {'source': 'code_graph', 'target': 'list', 'target_inputs': ['G.nodes']}, {'source': 'code_graph', 'target': 'set', 'target_inputs': [\"target_details.get('returns', [])\"]}, {'source': 'code_graph', 'target': 'class_method_details_lookup.get', 'target_inputs': ['source']}, {'source': 'code_graph', 'target': 'function_details_lookup.get', 'target_inputs': ['source']}, {'source': 'code_graph', 'target': 'get_edge_data_from_details', 'target_inputs': ['target_details', 'source_details', 'target'], 'target_returns': ['edge_data']}, {'source': 'code_graph', 'target': 'class_def.keys', 'target_inputs': []}, {'source': 'code_graph', 'target': 'called.split', 'target_inputs': [\"'.'\"]}, {'source': 'code_graph', 'target': 'called.startswith', 'target_inputs': [\"'self.'\"]}, {'source': 'code_graph', 'target': 'called.replace', 'target_inputs': [\"'self.'\", \"''\"]}, {'source': 'code_graph', 'target': 'source_name.split', 'target_inputs': [\"'.'\"]}, {'source': 'code_graph', 'target': 'add_edge_with_data', 'target_inputs': ['source_name', 'called'], 'target_returns': []}, {'source': 'code_graph', 'target': 'function_details_lookup.keys', 'target_inputs': []}, {'source': 'code_graph', 'target': 'function_details_lookup.items', 'target_inputs': []}, {'source': 'code_graph', 'target': 'add_edges_for_calls', 'target_inputs': ['qualified_method_name', \"details['calls']\"], 'target_returns': []}, {'source': 'code_graph', 'target': 'class_method_details_lookup.items', 'target_inputs': []}, {'source': 'code_graph', 'target': 'G[source][target].update', 'target_inputs': ['edge_data']}, {'source': 'code_graph', 'target': 'G.edges.data', 'target_inputs': []}, {'source': 'get_edge_data_from_details', 'target': 'target_details.get', 'target_inputs': [\"'returns'\", '[]']}, {'source': 'get_edge_data_from_details', 'target': 'list', 'target_inputs': [\"set(target_details.get('returns', []))\"]}, {'source': 'get_edge_data_from_details', 'target': 'set', 'target_inputs': [\"target_details.get('returns', [])\"]}, {'source': 'add_edge_with_data', 'target': 'class_method_details_lookup.get', 'target_inputs': ['source']}, {'source': 'add_edge_with_data', 'target': 'function_details_lookup.get', 'target_inputs': ['source']}, {'source': 'add_edge_with_data', 'target': 'G.add_edge', 'target_inputs': ['source', 'target']}, {'source': 'add_edge_with_data', 'target': 'get_edge_data_from_details', 'target_inputs': ['target_details', 'source_details', 'target'], 'target_returns': ['edge_data']}, {'source': 'add_edges_for_calls', 'target': 'list', 'target_inputs': ['class_def.keys()']}, {'source': 'add_edges_for_calls', 'target': 'class_def.keys', 'target_inputs': []}, {'source': 'add_edges_for_calls', 'target': 'called.split', 'target_inputs': [\"'.'\"]}, {'source': 'add_edges_for_calls', 'target': 'called.startswith', 'target_inputs': [\"'self.'\"]}, {'source': 'add_edges_for_calls', 'target': 'called.replace', 'target_inputs': [\"'self.'\", \"''\"]}, {'source': 'add_edges_for_calls', 'target': 'source_name.split', 'target_inputs': [\"'.'\"]}, {'source': 'add_edges_for_calls', 'target': 'add_edge_with_data', 'target_inputs': ['source_name', 'called'], 'target_returns': []}, {'source': 'add_edges_for_calls', 'target': 'G.add_node', 'target_inputs': ['called']}, {'source': 'get_python_file_details', 'target': 'open', 'target_inputs': ['file_path', \"'r'\"]}, {'source': 'get_python_file_details', 'target': 'f.read', 'target_inputs': []}, {'source': 'get_python_file_details', 'target': 'ast.parse', 'target_inputs': ['code']}, {'source': 'get_python_file_details', 'target': 'logging.warning', 'target_inputs': [\"f'Permission denied or syntax error in file: {file_path}'\"]}, {'source': 'get_python_file_details', 'target': 'CodeVisitor', 'target_inputs': ['code'], 'target_returns': []}, {'source': 'get_python_file_details', 'target': 'visitor.analyze', 'target_inputs': ['tree']}, {'source': 'get_python_file_details', 'target': 'code_graph', 'target_inputs': [\"file_details['file_info']['file_summary']\"], 'target_returns': [\"{'nodes': nodes, 'edges': edges}\", 'edge_data']}, {'source': 'get_python_file_details', 'target': \"json.dumps(file_details['file_info']['file_summary']).replace\", 'target_inputs': ['\\'\"\\'', \"''\"]}, {'source': 'get_python_file_details', 'target': 'json.dumps', 'target_inputs': [\"file_details['file_info']['file_summary']\"]}]}"
    },
    {
        "instruction": "Define the call code graph for Python file:\n\"\"\"\nFor each Python file within given directory, generate, save, and return datasets that include responses to questions about the code.\nRequirements:\n[req00] The extract_python_data function shall:\n    a. Accept parameters for the Python file path, base name, model configuration pathname, questions dictionary, and use of LLM.\n    b. Use the 'get_python_file_details' function to get the Python file details.\n    c. If the use_llm parameter is True, instantiate the LLM using the 'get_model' function.\n    d. Use the 'get_python_datasets' function to get the instruct.json datasets.\n    e. Return the file details and instruct.json dataset.\n[req01] The process_python_directories function shall:\n    a. Accept parameters for the starting directory, output directory, model configuration pathname, questions dictionary, and use of LLM.\n    b. Search for all Python files within the given directory and its subdirectories using a glob pattern.\n    c. For each Python file, call the extract_python_data function to get the file details and instruct.json dataset.\n    d. For valid Python file datasets, call the save_python_data function to save the file details and instruct.json dataset.\n    e. Combine all of the instruct.json files together using the 'combine_json_files' function.\n    f. Return the combined datasets.\n[req02] The py2dataset function shall:\n    a. Accept parameters for the starting directory, output directory, questions pathname, model configuration pathname, quiet mode, and use of LLM.\n    b. Determine the starting directory based on provided or default values.\n    c. Adjust the logging level based on the quiet flag.\n    d. Call the process_python_directories function to process the Python files and generate datasets.\n    e. Return the datasets.\n[req03] The main function shall:\n    a. Accept and process command-line arguments.\n    b. Determine the parameters for the py2dataset function based on the processed command-line arguments.\n    c. Call the py2dataset function with the derived parameters.\n\"\"\"\nimport os\nimport sys\nimport gc\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Union\nfrom multiprocessing import Process\n\nfrom get_python_file_details import get_python_file_details\nfrom get_python_datasets import get_python_datasets\nfrom get_py2dataset_params import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output import combine_json_files, save_python_data\n\ndef extract_python_data(file_path: str, base_name: str, questions: Dict, llm: object, prompt: str) -> Tuple[Union[Dict, Tuple], List[Dict], List[Dict]]:\n    \"\"\"\n    Extracts data from a Python file.\n    Args:\n        file_path (str): Path to the Python file.\n        base_name (str): Base name of the Python file.\n        questions (Dict): Questions dictionary to answer about the Python file.\n        llm (object): Large Language Model object. If None, use the default prompt.\n        prompt (str): Prompt to use for the Large Language Model.\n    Returns:\n        Tuple[Union[Dict, Tuple], List[Dict], List[Dict]]: File details dictionary or tuple of file details and None, instruct.json dataset.\n    \"\"\"\n    file_details, instruct_list = None, None    \n    # use AST to get python file details\n    file_details = get_python_file_details(file_path)\n    if file_details is None or isinstance(file_details, tuple):\n        return file_details, instruct_list\n\n    # get lists for instruct.json for python file\n    instruct_list = get_python_datasets(file_path, file_details, base_name, questions, llm, prompt)  \n    return file_details, instruct_list\n\n\ndef process_single_file(pythonfile_path, start_dir, model_config_pathname, questions, use_llm, output_dir):\n    \"\"\"\n    Process a single Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path (str): Path to the Python file.\n        start_dir (str): Starting directory to search for Python files.\n        model_config_pathname (str): Path to the model configuration file.\n        questions (Dict): Questions dictionary to answer about the Python file.\n        use_llm (bool): If True, use a Large Language Model for generating JSON answers.\n        output_dir (str): Directory to write the output files.\n    Returns:\n        none\n    \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    #instantiate llm and prompt if use_llm is True \n    #do this for each file to aviod multiprocessing pickling problem\n    llm, prompt = get_model(model_config_pathname) if use_llm else (None, '')\n\n    # get and save file_details and instruct_list\n    file_details, instruct_list = extract_python_data(pythonfile_path, base_name, questions, llm, prompt)\n    if file_details is None or isinstance(file_details, tuple):\n        return\n    save_python_data(file_details, instruct_list, relative_path, output_dir)\n\n\ndef process_python_directories(start_dir: str, output_dir: str, model_config_pathname: str, questions: Dict, \n                               use_llm: bool) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Processes all Python files in the provided directory and subdirectories.\n    Args:\n        start_dir (str): Starting directory to search for Python files.\n        output_dir (str): Directory to write the output files.\n        model_config_pathname (str): Path to the model configuration file.\n        questions (Dict): Questions dictionary to answer about each Python file.\n        use_llm (bool): If True, use the LLM model to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n    datasets = {}\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n\n        if pythonfile_path.is_dir():\n            continue\n\n        # spawn a new child process to manage python memory leaks\n        proc = Process(target=process_single_file, args=(pythonfile_path, start_dir, model_config_pathname, questions, use_llm, output_dir))\n        proc.start()\n        proc.join()\n        \n    # combine all of the instruct.json files together\n    datasets = combine_json_files(output_dir)   \n    return datasets\n\n\ndef py2dataset(start_dir: str = '', output_dir: str = '', questions_pathname: str = '', model_config_pathname: str = '', \n               use_llm: bool = False, quiet: bool = False) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process Python files to generate question-answer pairs and instructions.\n    Args:\n        start_dir (str, optional): Starting directory to search for Python files. Defaults to current working directory.\n        output_dir (str, optional): Directory to write the output files.\n        questions_pathname (str, optional): Path to the questions file.\n        model_config_pathname (str, optional): Path to the model configuration file.\n        use_llm (bool, optional): If True, use a Large Language Model for generating JSON answers. Defaults to False.\n        quiet (bool, optional): Limit logging output. Defaults to False.\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)  # Increase the recursion limit for AST\n    \n    # if start dir is empty or not a valid directory, use current working directory\n    if start_dir == '' :\n        logging.info('No valid start path provided. Using current working directory.')\n        start_dir = os.getcwd()    \n    start_dir = os.path.abspath(start_dir)\n    \n    output_dir = get_output_dir(output_dir)\n    questions = get_questions(questions_pathname)\n\n    datasets = process_python_directories(start_dir, output_dir, model_config_pathname, questions, use_llm)\n    return datasets\n\ndef main():\n    \"\"\"\n    Command-line entry point for processing Python files and generating datasets.\n    Args:\n        --start_dir (str, optional): Starting directory to search for Python files. Defaults to the current working directory.\n        --output_dir (str, optional): Directory to write the output files. Defaults to the 'datasets' directory in the current working directory.\n        --questions_pathname (str, optional): Path to the questions file. If not provided, defaults defined in 'get_py2dataset_params.py' will be used.\n        --model_config_pathname (str, optional): Path to the model configuration file. If not provided, defaults defined in 'get_py2dataset_params.py' will be used.\n        --use_llm (bool, optional): Use a Large Language Model for generating JSON answers. Defaults to False.\n        --quiet (bool, optional): Limit logging output. If provided, only warnings and errors will be logged. Defaults to False.\n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname = ''\n    use_llm = False\n    quiet = False\n\n    if '--start_dir' in arg_string:    \n        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n    if '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n        model_config_pathname = arg_string.split('--model_config_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}', '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--questions_pathname {questions_pathname}', '') \n    if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string = arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n        quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n\n    py2dataset(start_dir, output_dir, questions_pathname, model_config_pathname, use_llm, quiet)\n\nif __name__ == \"__main__\":\n    main()",
        "output": "{'nodes': ['extract_python_data', 'process_single_file', 'process_python_directories', 'py2dataset', 'main', 'get_python_file_details', 'isinstance', 'get_python_datasets', 'logging.info', 'pythonfile_path.relative_to', \"'.'.join\", 'get_model', 'save_python_data', 'Path(start_dir).rglob', 'Path', 'pythonfile_path.is_dir', 'Process', 'proc.start', 'proc.join', 'combine_json_files', 'logging.getLogger().setLevel', 'logging.getLogger', 'sys.setrecursionlimit', 'os.getcwd', 'os.path.abspath', 'get_output_dir', 'get_questions', \"' '.join\", \"arg_string.split('--start_dir ')[1].split\", 'arg_string.split', 'arg_string.replace', \"arg_string.split('--output_dir ')[1].split\", \"arg_string.split('--model_config_pathname ')[1].split\", \"arg_string.split('--questions_pathname ')[1].split\"], 'edges': [{'source': 'extract_python_data', 'target': 'get_python_file_details', 'target_inputs': ['file_path']}, {'source': 'extract_python_data', 'target': 'isinstance', 'target_inputs': ['file_details', 'tuple']}, {'source': 'extract_python_data', 'target': 'get_python_datasets', 'target_inputs': ['file_path', 'file_details', 'base_name', 'questions', 'llm', 'prompt']}, {'source': 'process_single_file', 'target': 'logging.info', 'target_inputs': [\"f'Processing: {pythonfile_path}'\"]}, {'source': 'process_single_file', 'target': 'pythonfile_path.relative_to', 'target_inputs': ['start_dir']}, {'source': 'process_single_file', 'target': \"'.'.join\", 'target_inputs': ['(part for part in relative_path.parts)']}, {'source': 'process_single_file', 'target': 'get_model', 'target_inputs': ['model_config_pathname']}, {'source': 'process_single_file', 'target': 'extract_python_data', 'target_inputs': ['pythonfile_path', 'base_name', 'questions', 'llm', 'prompt'], 'target_returns': ['(file_details, instruct_list)']}, {'source': 'process_single_file', 'target': 'isinstance', 'target_inputs': ['file_details', 'tuple']}, {'source': 'process_single_file', 'target': 'save_python_data', 'target_inputs': ['file_details', 'instruct_list', 'relative_path', 'output_dir']}, {'source': 'process_python_directories', 'target': 'Path(start_dir).rglob', 'target_inputs': [\"'[!_]*.py'\"]}, {'source': 'process_python_directories', 'target': 'Path', 'target_inputs': ['start_dir']}, {'source': 'process_python_directories', 'target': 'pythonfile_path.is_dir', 'target_inputs': []}, {'source': 'process_python_directories', 'target': 'Process', 'target_inputs': []}, {'source': 'process_python_directories', 'target': 'proc.start', 'target_inputs': []}, {'source': 'process_python_directories', 'target': 'proc.join', 'target_inputs': []}, {'source': 'process_python_directories', 'target': 'combine_json_files', 'target_inputs': ['output_dir']}, {'source': 'py2dataset', 'target': 'logging.getLogger().setLevel', 'target_inputs': ['logging.INFO']}, {'source': 'py2dataset', 'target': 'logging.getLogger', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'sys.setrecursionlimit', 'target_inputs': ['3000']}, {'source': 'py2dataset', 'target': 'logging.info', 'target_inputs': [\"'No valid start path provided. Using current working directory.'\"]}, {'source': 'py2dataset', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'os.path.abspath', 'target_inputs': ['start_dir']}, {'source': 'py2dataset', 'target': 'get_output_dir', 'target_inputs': ['output_dir']}, {'source': 'py2dataset', 'target': 'get_questions', 'target_inputs': ['questions_pathname']}, {'source': 'py2dataset', 'target': 'process_python_directories', 'target_inputs': ['start_dir', 'output_dir', 'model_config_pathname', 'questions', 'use_llm'], 'target_returns': ['datasets']}, {'source': 'main', 'target': \"' '.join\", 'target_inputs': ['sys.argv[1:]']}, {'source': 'main', 'target': \"arg_string.split('--start_dir ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': 'arg_string.split', 'target_inputs': [\"'--questions_pathname '\"]}, {'source': 'main', 'target': 'arg_string.replace', 'target_inputs': [\"'--quiet'\", \"''\"]}, {'source': 'main', 'target': \"arg_string.split('--output_dir ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': \"arg_string.split('--model_config_pathname ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': \"arg_string.split('--questions_pathname ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': 'py2dataset', 'target_inputs': ['start_dir', 'output_dir', 'questions_pathname', 'model_config_pathname', 'use_llm', 'quiet'], 'target_returns': ['datasets']}]}"
    },
    {
        "instruction": "Define the call code graph for Python file:\n\"\"\"\nUtility functions for reading the input and saving the output of the py2dataset script.\nRequirements:\n[req01] The `read_file` function shall:\n        a. Accept a file path as an argument.\n        b. Read and return the contents of a JSON or YAML file as a dictionary.\n[req02] The `write_file` function shall:\n        a. Accept a dictionary and a file path as arguments.\n        b. Write the dictionary to a file in either JSON or YAML format.\n[req03] The `convert_json_to_html` function shall:\n        a. Convert JSON files within a given directory to HTML format.\n        b. Save each converted file with a .html extension.\n        c. Preserve spacing and tabs for the 'input' field.\n[req04] The `combine_json_files` function shall:\n        a. Accept a directory path as an argument.\n        b. Merge all JSON files in the directory.\n        c. Remove duplicates from the combined JSON files.\n        d. Write the combined data to 'instruct.json' files.\n        e. Convert the merged JSON files to HTML format.\n        f. Return the 'instruct_list' datasets.\n[req05] The `create_code_graph` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Generate code graphs based on the provided file details.\n        c. Save the graphs as PNG images in the specified output directory.\n[req06] The `save_python_data` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Save the details of the Python file as a YAML file.\n        c. Save the instruction data as JSON files.\n        d. Generate and save code graphs.\n\"\"\"\nimport sys\nimport os\nimport re\nimport json\nimport logging\nimport yaml\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom html import escape\nfrom pathlib import Path\nfrom typing import Dict, List, Union\n\n\ndef read_file(file_path: Path) -> Dict:\n    \"\"\"\n    Reads a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n    Returns:\n        The contents of the file as a dictionary.\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open() as f:\n        if file_type == 'json':\n            return json.load(f)\n        elif file_type == 'yaml':\n            return yaml.load(f)\n\n\ndef write_file(data: Dict, file_path: Path) -> None:\n    \"\"\"\n    Writes a dictionary to a JSON or YAML file. \n    Args:\n        data (Dict): The data to write to the file.\n        file_path (Path): The path to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open('w') as f:\n        if file_type == 'json':\n            json.dump(data, f, indent=4)\n        elif file_type == 'yaml':\n            yaml.SafeDumper.ignore_aliases = lambda *args: True\n            yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)\n\n\ndef convert_json_to_html(directory: str) -> None:\n    \"\"\"\n    Convert JSON files within a given directory to HTML format.\n    Args:\n        directory (str): The directory where the JSON files are located.\n    Returns:\n        None    \n    \"\"\"\n    def preserve_spacing(text: str, tab_width: int = 4) -> str:\n        \"\"\"Preserve spaces and tabs in the provided text.\"\"\"\n        return text.replace(\" \", \"&nbsp;\").replace(\"\\t\", \"&nbsp;\" * tab_width)\n\n    for json_file in Path(directory).rglob('*.json'):\n        dataset = read_file(json_file)\n        if not dataset:\n            continue\n\n        html_file = json_file.with_suffix('.html')\n        html_content = \"\"\"\n        <html>\n        <head>\n            <style>\n                table {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th, td {\n                    border: 1px solid black;\n                    padding: 8px;\n                    text-align: left;\n                    white-space: pre-line;\n                    vertical-align: top;\n                    word-wrap: break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        \"\"\"\n        column_count = len(dataset[0].keys())\n        column_width = 100 / column_count  # Calculate the width for each column based on the number of columns\n        for key in dataset[0].keys():\n            html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\n        html_content += \"\"\"\n                    </tr>\n                </thead>\n                <tbody>\n        \"\"\"\n        for entry in dataset:\n            html_content += \"<tr>\"\n            for key in entry:\n                # Convert \\n to HTML line breaks\n                value = escape(str(entry[key]))\n                value = preserve_spacing(value)\n                value = value.replace('\\n', '<br/>')\n                html_content += f\"<td>{value}</td>\"\n            html_content += \"</tr>\"\n\n        html_content += \"\"\"\n                </tbody>\n            </table>\n        </body>\n        </html>\n        \"\"\"\n        html_file_path = json_file.with_suffix('.html')\n        try:   \n            with open(html_file_path, 'w', encoding='utf-8') as file:\n                file.write(html_content)\n        except:\n            logging.save(logging.info(f'Failed saving: {html_file_path}'))\n\n\ndef combine_json_files(directory: str) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Combine all JSON files in the output directory into 'instruct.json', and then remove duplicates.\n    Args:\n        directory (str): The directory where the output files are located.\n    Returns:\n        A dictionary containing the 'instruct_list' datasets.\n    \"\"\"\n   \n    def remove_duplicate_dataset_entries(dataset: List[Dict], key1: str, key2: str) -> List[Dict]:\n        \"\"\"\n        Remove duplicate entries from the provided dataset based on the provided keys.\n        Args:\n            dataset (List[Dict]): The dataset to remove duplicates from.\n            key1 (str): The first key to check for duplicates.\n            key2 (str): The second key to check for duplicates.\n        Returns:\n            A dataset without duplicate entries.\n        \"\"\"\n        seen = set()\n        result = []\n        for item in dataset:\n            if (item[key1], item[key2]) not in seen:\n                seen.add((item[key1], item[key2]))\n                result.append(item)\n        return result\n\n    instruct_data = []\n    for file_name in ['instruct.json']:\n        file_path = Path(directory) / file_name\n        combined_data = []\n        for json_file in Path(directory).rglob(f'*.{file_name}'):\n            json_file_data = read_file(json_file)\n            combined_data.extend(json_file_data)\n            combined_data = remove_duplicate_dataset_entries(combined_data, 'instruction', 'output')\n            instruct_data = combined_data.copy()\n            # gen training datasets that contains purpose and graph data formatted as follow for each item in the dataset:\n            purpose_data = [item for item in combined_data if item['instruction'].startswith('1) Describe the purpose')]\n            graph_data = [item for item in combined_data if item['instruction'].startswith('What is the call code graph')]\n            code_output = []\n            graph_output = []\n            for item in purpose_data:\n                code_output.append({'instruction': 'Define the Python code file that is described as follows:\\n'+ item['output'], 'output': item['input']})\n            for item in graph_data:\n                graph_output.append({'instruction': 'Define the call code graph for Python file:\\n' + item['input'], 'output': item['output']})\n            code_graph_output = code_output + graph_output\n            write_file(code_graph_output, Path(directory) / 'training.json')\n\n        write_file(combined_data, file_path)\n\n    # Save html file for each json file in the output directory\n    convert_json_to_html(directory)\n    return {'instruct_list': instruct_data}\n\n\ndef create_code_graph(file_details: Dict, base_name: str, output_subdir: Path) -> None:\n    \"\"\"\n    Generate graphs from the file_details and save them as PNG images.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        base_name (str): The base name of the output files.\n        output_subdir (Path): The subdirectory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    graph_type = 'entire_code_graph'\n    output_file = output_subdir / f'{base_name}.{graph_type}.png'\n\n    # Create graphs, add nodes, and add edges\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n    for edge in file_details['file_info'][graph_type]['edges']:\n        source, target = edge['source'], edge['target']\n        if source in G.nodes and target in G.nodes:\n           G.add_edge(source, target, **{k: v for k, v in edge.items() if k in ['target_inputs', 'target_returns']})\n    # Draw graphs\n    plt.figure(figsize=(20, 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True, font_weight='bold', font_size = 8, node_shape='s', node_size=500, width=1, arrowsize=12)\n    edge_labels = {}\n    for edge in G.edges(data=True):\n        label = []\n        if 'target_inputs' in edge[2] and edge[2]['target_inputs']:\n            label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\")\n        if 'target_returns' in edge[2] and edge[2]['target_returns']:\n            label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\")\n        edge_labels[(edge[0], edge[1])] = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n    plt.savefig(output_file) # Save the figure\n    plt.close()  # Close the figure\n\n\ndef save_python_data(file_details: dict, instruct_list: list, relative_path: Path, output_dir: str) -> None:\n    \"\"\"\n    Save Python file details as a YAML file, the instruction data as a JSON file, and code graphs.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        instruct_list (list): The instruction data extracted from the Python file.\n        relative_path (Path): The relative path to the Python file.\n        output_dir (str): The directory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir = Path(output_dir) / relative_path.parts[0]\n    output_subdir.mkdir(parents=True, exist_ok=True)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    # write instrunct.json files\n    file_names = [f'{base_name}.instruct.json', f'{base_name}.details.yaml']\n    contents = [instruct_list, file_details]\n\n    for file_name, content in zip(file_names, contents):\n        write_file(content, output_subdir / file_name)\n\n    try:\n        create_code_graph(file_details, base_name, output_subdir)\n    except:\n        logging.info(f'Error creating graph for {base_name}')\n",
        "output": "{'nodes': ['read_file', 'write_file', 'convert_json_to_html', 'preserve_spacing', 'combine_json_files', 'remove_duplicate_dataset_entries', 'create_code_graph', 'save_python_data', 'file_path.open', 'json.load', 'yaml.load', 'json.dump', 'yaml.dump', \"text.replace(' ', '&nbsp;').replace\", 'text.replace', 'Path(directory).rglob', 'Path', 'json_file.with_suffix', 'len', 'dataset[0].keys', 'escape', 'str', 'value.replace', 'open', 'file.write', 'logging.save', 'logging.info', 'set', 'seen.add', 'result.append', 'combined_data.extend', 'combined_data.copy', \"item['instruction'].startswith\", 'code_output.append', 'graph_output.append', 'nx.DiGraph', 'G.add_nodes_from', 'G.add_edge', 'edge.items', 'plt.figure', 'nx.spring_layout', 'nx.draw', 'G.edges', 'label.append', \"', '.join\", \"'\\\\n'.join\", 'nx.draw_networkx_edge_labels', 'plt.savefig', 'plt.close', 'output_subdir.mkdir', \"'.'.join\", 'zip'], 'edges': [{'source': 'read_file', 'target': 'file_path.open', 'target_inputs': []}, {'source': 'read_file', 'target': 'json.load', 'target_inputs': ['f']}, {'source': 'read_file', 'target': 'yaml.load', 'target_inputs': ['f']}, {'source': 'write_file', 'target': 'file_path.open', 'target_inputs': [\"'w'\"]}, {'source': 'write_file', 'target': 'json.dump', 'target_inputs': ['data', 'f']}, {'source': 'write_file', 'target': 'yaml.dump', 'target_inputs': ['data', 'f']}, {'source': 'convert_json_to_html', 'target': \"text.replace(' ', '&nbsp;').replace\", 'target_inputs': [\"'\\\\t'\", \"'&nbsp;' * tab_width\"]}, {'source': 'convert_json_to_html', 'target': 'text.replace', 'target_inputs': [\"' '\", \"'&nbsp;'\"]}, {'source': 'convert_json_to_html', 'target': 'Path(directory).rglob', 'target_inputs': [\"'*.json'\"]}, {'source': 'convert_json_to_html', 'target': 'Path', 'target_inputs': ['directory']}, {'source': 'convert_json_to_html', 'target': 'read_file', 'target_inputs': ['json_file'], 'target_returns': ['json.load(f)', 'yaml.load(f)']}, {'source': 'convert_json_to_html', 'target': 'json_file.with_suffix', 'target_inputs': [\"'.html'\"]}, {'source': 'convert_json_to_html', 'target': 'len', 'target_inputs': ['dataset[0].keys()']}, {'source': 'convert_json_to_html', 'target': 'dataset[0].keys', 'target_inputs': []}, {'source': 'convert_json_to_html', 'target': 'escape', 'target_inputs': ['str(entry[key])']}, {'source': 'convert_json_to_html', 'target': 'str', 'target_inputs': ['entry[key]']}, {'source': 'convert_json_to_html', 'target': 'preserve_spacing', 'target_inputs': ['value'], 'target_returns': [\"text.replace(' ', '&nbsp;').replace('\\\\t', '&nbsp;' * tab_width)\"]}, {'source': 'convert_json_to_html', 'target': 'value.replace', 'target_inputs': [\"'\\\\n'\", \"'<br/>'\"]}, {'source': 'convert_json_to_html', 'target': 'open', 'target_inputs': ['html_file_path', \"'w'\"]}, {'source': 'convert_json_to_html', 'target': 'file.write', 'target_inputs': ['html_content']}, {'source': 'convert_json_to_html', 'target': 'logging.save', 'target_inputs': [\"logging.info(f'Failed saving: {html_file_path}')\"]}, {'source': 'convert_json_to_html', 'target': 'logging.info', 'target_inputs': [\"f'Failed saving: {html_file_path}'\"]}, {'source': 'preserve_spacing', 'target': \"text.replace(' ', '&nbsp;').replace\", 'target_inputs': [\"'\\\\t'\", \"'&nbsp;' * tab_width\"]}, {'source': 'preserve_spacing', 'target': 'text.replace', 'target_inputs': [\"' '\", \"'&nbsp;'\"]}, {'source': 'combine_json_files', 'target': 'set', 'target_inputs': []}, {'source': 'combine_json_files', 'target': 'seen.add', 'target_inputs': ['(item[key1], item[key2])']}, {'source': 'combine_json_files', 'target': 'result.append', 'target_inputs': ['item']}, {'source': 'combine_json_files', 'target': 'Path', 'target_inputs': ['directory']}, {'source': 'combine_json_files', 'target': 'Path(directory).rglob', 'target_inputs': [\"f'*.{file_name}'\"]}, {'source': 'combine_json_files', 'target': 'read_file', 'target_inputs': ['json_file'], 'target_returns': ['json.load(f)', 'yaml.load(f)']}, {'source': 'combine_json_files', 'target': 'combined_data.extend', 'target_inputs': ['json_file_data']}, {'source': 'combine_json_files', 'target': 'remove_duplicate_dataset_entries', 'target_inputs': ['combined_data', \"'instruction'\", \"'output'\"], 'target_returns': ['result']}, {'source': 'combine_json_files', 'target': 'combined_data.copy', 'target_inputs': []}, {'source': 'combine_json_files', 'target': \"item['instruction'].startswith\", 'target_inputs': [\"'What is the call code graph'\"]}, {'source': 'combine_json_files', 'target': 'code_output.append', 'target_inputs': [\"{'instruction': 'Define the Python code file that is described as follows:\\\\n' + item['output'], 'output': item['input']}\"]}, {'source': 'combine_json_files', 'target': 'graph_output.append', 'target_inputs': [\"{'instruction': 'Define the call code graph for Python file:\\\\n' + item['input'], 'output': item['output']}\"]}, {'source': 'combine_json_files', 'target': 'write_file', 'target_inputs': ['combined_data', 'file_path'], 'target_returns': []}, {'source': 'combine_json_files', 'target': 'convert_json_to_html', 'target_inputs': ['directory'], 'target_returns': [\"text.replace(' ', '&nbsp;').replace('\\\\t', '&nbsp;' * tab_width)\"]}, {'source': 'remove_duplicate_dataset_entries', 'target': 'set', 'target_inputs': []}, {'source': 'remove_duplicate_dataset_entries', 'target': 'seen.add', 'target_inputs': ['(item[key1], item[key2])']}, {'source': 'remove_duplicate_dataset_entries', 'target': 'result.append', 'target_inputs': ['item']}, {'source': 'create_code_graph', 'target': 'nx.DiGraph', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'G.add_nodes_from', 'target_inputs': [\"file_details['file_info'][graph_type]['nodes']\"]}, {'source': 'create_code_graph', 'target': 'G.add_edge', 'target_inputs': ['source', 'target']}, {'source': 'create_code_graph', 'target': 'edge.items', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'plt.figure', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'nx.spring_layout', 'target_inputs': ['G']}, {'source': 'create_code_graph', 'target': 'nx.draw', 'target_inputs': ['G', 'pos']}, {'source': 'create_code_graph', 'target': 'G.edges', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'label.append', 'target_inputs': ['f\"\\\\nReturns: {\\', \\'.join(edge[2][\\'target_returns\\'])}\"']}, {'source': 'create_code_graph', 'target': \"', '.join\", 'target_inputs': [\"edge[2]['target_returns']\"]}, {'source': 'create_code_graph', 'target': \"'\\\\n'.join\", 'target_inputs': ['label']}, {'source': 'create_code_graph', 'target': 'nx.draw_networkx_edge_labels', 'target_inputs': ['G', 'pos']}, {'source': 'create_code_graph', 'target': 'plt.savefig', 'target_inputs': ['output_file']}, {'source': 'create_code_graph', 'target': 'plt.close', 'target_inputs': []}, {'source': 'save_python_data', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'save_python_data', 'target': 'output_subdir.mkdir', 'target_inputs': []}, {'source': 'save_python_data', 'target': \"'.'.join\", 'target_inputs': ['(part for part in relative_path.parts)']}, {'source': 'save_python_data', 'target': 'zip', 'target_inputs': ['file_names', 'contents']}, {'source': 'save_python_data', 'target': 'write_file', 'target_inputs': ['content', 'output_subdir / file_name'], 'target_returns': []}, {'source': 'save_python_data', 'target': 'create_code_graph', 'target_inputs': ['file_details', 'base_name', 'output_subdir'], 'target_returns': []}, {'source': 'save_python_data', 'target': 'logging.info', 'target_inputs': [\"f'Error creating graph for {base_name}'\"]}]}"
    },
    {
        "instruction": "Define the call code graph for Python file:\nfrom setuptools import setup\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"py2dataset\",\n    version=\"0.1\",\n    author=\"Jeff Meloy\",\n    author_email=\"jeffmeloy@gmail.com\",\n    description=\"A tool to generate structured datasets from Python source code\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/jeffmeloy/py2dataset\",\n    py_modules=[\"py2dataset\", \"get_python_file_details\", \"get_python_json\"],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires='>=3.8',\n    install_requires=[\n        \"matplotlib\",\n        \"networkx\",\n        \"ctransformers\",\n        \"pyyaml\"\n    ],\n    entry_points={'console_scripts': ['py2dataset = py2dataset:main']},\n    packages=['py2dataset'],\n    package_dir={'py2dataset': '.\\\\'},\n)",
        "output": "{'nodes': [], 'edges': []}"
    }
]