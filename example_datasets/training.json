[
    {
        "instruction": "Define a Python code file that is described as follows:\nThe purpose of this Python file is to obtain parameters needed by the py2dataset application for creating a dataset. These parameters include: a list of questions that define what types of data py2dataset can generate based on user-provided prompts, a model configuration dictionary specifying the type and settings of the language model used for inference, an output directory for writing generated datasets, and paths to files containing customized questions or model configurations. The file also includes functions for obtaining these parameters from various sources (default values, provided files, or arguments passed in) and instantiating the desired language model with its appropriate parameters based on those inputs. It can write default or customized prompt templates, questions, and model configurations to JSON or YAML format files if needed. \n\nFunctions:\n- `get_default_questions()` returns a list of default questions that py2dataset can generate data for. Each question is represented as a dictionary with an ID, text, and type (file, function, class, etc.).\n- `get_default_model_config()` returns the default model configuration in YAML format, which includes the prompt template and the settings used to instantiate a language model from ctransformers library.\n- `get_output_dir(output_dir='')` takes an optional output directory argument and returns its absolute path if it exists or can be created. If no valid output directory is provided, it uses the default OUTPUT_DIR variable defined in the file.\n- `get_questions(questions_pathname)` gets questions from a specified file or falls back to default settings when it is invalid (no valid question files exist or fail to parse as JSON) \n- `instantiate_model(model_config: dict) -> object` imports and instantiates the desired language model based on the provided configuration.\n- `get_model(model_config_pathname)` gets a model from a specified file or falls back to default settings when it is invalid (no valid config files exist or fail to parse as YAML). It also returns an appropriate prompt template for that model based on its settings in the dictionary. \n- `write_questions_file(output_dir='')` writes default questions to the QUESTIONS_FILE if no valid output directory is provided. This function calls get_default_questions(). \n- `write_model_config_file(output_dir='')` writes a YAML file containing the default model configuration (the template prompt and any model settings).\n\nInputs: \n1) filename for all functions except `get_model` - this is the path to the Python file being analyzed. \n2) function_name for `function_inputs`, `method_inputs`, and `class_methods`. \n3) class_name for `class_inheritance`, `class_attributes`, `method_returns`, and `file_functions` - the name of a class in the file. \n4) model_config_pathname for `get_model` - path to the YAML configuration file for the desired language model.\n5) questions_pathname for `get_questions` - path to a JSON file containing customized questions.\n6) output_dir for all functions that write files - where to save generated data or configuration files. \n\nOutputs: \n1) A list of dictionaries representing the questions py2dataset can generate data for, with each dictionary having an ID, text, and type (file, function, class). \n2) A dictionary containing a prompt template and model settings. \n3) An instance of a language model from the ctransformers library instantiated according to the specified parameters.\n4) Two JSON or YAML files in the desired output directory. One is the `QUESTIONS_FILE` file, which contains default questions (or customized questions if provided), and the other is the `MODEL_CONFIG_FILE`, containing the default prompt template and any model settings that can be adjusted by the user. \n\"\"\"\nQ: In `instantiate_model(model_config)`, what happens if the specified module or class cannot be imported? \nA: The function returns None, indicating an error in importing the module or class. This is logged to the console and handled later on when attempting to use the model instance.",
        "output": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returned items from function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible\n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 14000,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n"
    },
    {
        "instruction": "Define a Python code file that is described as follows:\nThe Python file `py2dataset.get_python_datasets.py` generates JSON formatted question-answer pairs and instructions for a given Python file. It has two main functions: `clean_and_get_unique_elements` and `get_python_datasets`. The `clean_and_get_unique_elements` function cleans an input string (str) and returns a string of unique elements, while the `get_python_datasets` function generates instructions for the given Python file using the `DatasetGenerator` class. \n\n1. Summary of Function: The main function, `get_python_datasets`, extracts information from the Python file passed in as a parameter and returns it in JSON format along with question-answer pairs and their respective prompts/context. This is done using the `DatasetGenerator` class, which accepts a Python file path, file details, base name, list of questions, and model configuration as input during instantiation. The `get_response_from_llm` method retrieves responses from the language model for given context, while the `process_question` method processes each question and adds them to an instruct list, and `process_question_type` handles specific questions related to a Python file's functions, classes, or methods. Finally, `generate()` is used to generate all instructions/answers from these methods. The `add_to_list`, `get_response_from_llm`, and `get_string_from_info` methods are helper functions for the main class. \n2. Detailed Description of Functions:\n\nFunction `clean_and_get_unique_elements`: This function takes in a string (str) and returns a cleaned string of unique elements separated by commas, as described in its docstring. It removes non-word characters using regex and splits the input string into individual elements, then adds them to a set to remove duplicates before joining them back together with commas. \n\nFunction `get_python_datasets`: This function takes in a Python file path, file details, base name, questions list, and model config as input. It instantiates the `DatasetGenerator` class using these inputs and generates instructions for all the questions using its `generate()` method. The generated responses are returned along with their respective prompts/context. \n\nClass `DatasetGenerator`: This class has multiple methods, attributes, and a constructor to extract information from Python files. Its primary method, `generate`, handles all of the necessary processing of different question types (file, function, and class) and generates responses for each question using the provided language model or by parsing the file's code. It also provides helper functions like `add_to_list` and `get_response_from_llm`. The main methods are: \n- `__init__(self, file_path: str, file_details: Dict, base_name: str, questions: List[Dict], model_config: Dict) -> None`: Initializes the class with necessary attributes and stores the input parameters. \n- `add_to_list(list_to_update: List[Dict], query: str, response: str, additional_field=None) -> List[Dict]`: Adds a response to the instruct list along with its prompt/context and any additional field if needed. \n- `get_response_from_llm(query: str, context: str) -> str`: Gets a response from the language model for a given query and context.\n- `process_question(question_type: str, question_id: str, query: str, info: Dict): Retrieves a specific response from file details using `get_response_from_llm` if applicable, otherwise cleans it directly. Adds the generated response to the instruct list along with its prompt/context.\n- `process_question_type(question_type: str, question_id: str, question_text: str): Processes questions related to a Python file's functions, classes, or methods by extracting their respective information and generating responses using `process_question`. \n- `generate() -> Tuple[List[Dict], List[Dict]]`: Generates responses for all the questions in the list and returns them along with their prompt/context. \n3. Detailed Description of Variables:\n- `file_path` (str): The path to the Python file being processed.\n- `file_details` (Dict): A dictionary containing information about the Python file, such as its code, functions, classes, and methods.\n- `base_name` (str): The base name of the Python file.\n- `questions` (List[Dict]): A list of dictionaries with question types, IDs, and texts for generating responses. \n- `model_config` (Dict): Configuration for the language model used to generate responses. \n- `instruct_list`: The final list containing all instructions/answers generated by `DatasetGenerator`. \n- `question_mapping` (Dict[str, str]): A mapping of question types to keys in file details. \n- `use_llm` (bool): A flag indicating if a language model should be used for generating responses or not. \n- `llm`: The language model object provided by the user. \n- `prompt` (str): The prompt format for querying the language model. \n- `items` (Dict): Temporary dictionary used in processing a list of questions from one type (`functions`, `classes`)\n- `full_context` (str): The full context to be used for generating responses, including code and previous question/answer pairs. \n- `methods_string`: A string containing the methods defined in a class, if applicable. \n- `mapping`: A dictionary with information about the current object being processed.\n- `query` (str): The query text to be used for generating responses or for checking dependencies, calls, etc.\n- `response`: The generated response from the language model.\n- `inputs_string` and `variables_string`: Strings containing inputs and variables of a function/class, respectively. \n- `combined_string`: A string combining both `inputs_string` and `variables_string`.\n- `excluded_instructions`: A list of instructions to exclude from the response prompt, as specified by the user in `py2dataset_model_config.yaml`. \n- `response_str` (str): The string representing a variable, call, dependency, etc. This can come either from llm response or manual processing for non-llm cases. \n- `context`: The code of the current object being processed (`file`, `function`, `class`). \n- `method_name`: The name of the method being processed in a class. \n- `context_size` (int): The length of the prompt context as generated by the language model, used for managing response lengths and context. \n- `code_qa`: A string containing all previous question/answer pairs generated so far. \n- `max_context_length` (int): The maximum length of a single prompt/response pair, set in the user's configuration file. \n\nThe purpose of this code is to generate JSON formatted instructions and responses for Python files. It processes questions related to different types of objects: file details, functions, classes, and methods. It can also use a language model (LLM) or manually parse the file's code to extract information and provide prompts/context for each question. The inputs are the Python file path, its contents, base name, list of questions, and LLM configuration. The outputs are the generated instructions in JSON format along with their respective prompts/context.",
        "output": "\"\"\"\nGenerates JSON format question-answer pairs and instructions for a Python file\nRequirements:\n[req01] The `DatasetGenerator` class shall:\n        a. Accept Python file path, file details, base name, list of questions,\n        and model configuration as input during instantiation.\n        b. Initialize and store Python file path, file details, base name,\n        question list, llm, and use_llm flag as class attributes.\n        d. Provide `get_response_from_llm` method to retrieve llm response.\n        e. Provide `process_question` method to process each question, generate\n        corresponding responses, and add to the instruct_list.\n        f. Provide `process_question_type` method to process questions\n        related to the file, functions, classes, and methods.\n        g. Provide `generate` method to generate responses for all questions\n        and return the instruct_list.\n        h. Internally manage question mapping to file details.\n[req02] The `get_python_datasets` function shall:\n        a. Accept a Python file path, file details, base name, questions list,\n        and model config as input.\n        b. Instantiate `DatasetGenerator` class using the provided input.\n        c. Generate instruct_list using `DatasetGenerator` `generate` method.\n        d. Return the generated `instruct_list`.\n[req03] The `clean_and_get_unique_elements` function shall:\n        a. Clean an input string (str) and return a string of unique elements.\n\"\"\"\nimport logging\nimport re\nimport math\nfrom typing import Dict, List, Tuple\n\ndef clean_and_get_unique_elements(input_str: str) -> str:\n    \"\"\"\n    Clean input string and return string of unique elements.\n    Args:\n        input_str (str): The input string to be cleaned.\n    Returns:\n        str: The cleaned string.\n    \"\"\"\n    cleaned_elements = set(re.sub(r'[^\\w\\-_>\\s:/.]', '', element.strip())\n                            for element in re.sub(r'\\s+', ' ', input_str).split(','))\n    return ', '.join(cleaned_elements)\n\n\nclass DatasetGenerator:\n    \"\"\"\n    Generate JSON formatted dictionary outputs for a Python file.\n    Attributes:\n        file_path (str): The path to the Python file.\n        file_details (Dict[str, Any]): Details of the Python file.\n        base_name (str): The base name of the Python file.\n        questions (List[Dict[str, str]]): Questions for generating responses.\n        instruct_list (List[Dict[str, str]]): Storage for generated instructions.\n        question_mapping (Dict[str, str]): Mapping of question types to keys in file details.\n        use_llm (bool): Flag indicating if a language model should be used.\n        llm (object): The language model for generating responses.\n        prompt (str): The prompt format for querying the language model.\n    Methods:\n        add_to_list(list_to_update: List[Dict], query: str, response: str, \n        additional_field=None) -> List[Dict]: \n            Add response to the instruct list.\n        get_response_from_llm(query: str, context: str) -> str:\n            Get language model response to query for given context.\n        process_question(question_type: str, question_id: str, query: str, \n        context: str, info: Dict) -> None:\n            Process question and add generated response to the instruct_list.\n        process_question_type(question_type: str, question_id: str, \n        question_text: str) -> None:\n            Process question related to file, function, class, or method.\n        generate() -> Tuple[List[Dict], List[Dict]]:\n            Generate responses for all the questions and return the instruct_list.\n    \"\"\"\n\n    def __init__(self, file_path: str, file_details: Dict, base_name: str,\n                 questions: List[Dict], model_config: Dict) -> None:\n        \"\"\"\n        Initialize the DatasetGenerator class.\n        Args:\n            file_path (str): The path to the Python file.\n            file_details (Dict[str, Any]): Details of the Python file.\n            base_name (str): The base name of the Python file.\n            questions (List[Dict[str, str]]): Questions for generating responses.\n            model_config (Dict): Configuration for the language model.\n        Returns:\n            None\n        \"\"\"\n        self.file_path = file_path\n        self.file_details = file_details\n        self.base_name = base_name\n        self.questions = questions\n        self.model_config = model_config\n        self.llm = model_config['model']\n        if self.llm is None:\n            self.use_llm = False\n        else:\n            self.use_llm = True\n        self.instruct_list = []\n        self.question_mapping = {\n            'file': 'file',\n            'function': 'functions',\n            'class': 'classes',\n            'method': 'classes'\n        }\n\n    def add_to_list(\n        self,\n        list_to_update: List[Dict],\n        query: str,\n        response: str,\n        additional_field=None\n        ) -> List[Dict]:\n        \"\"\"\n        Add response to the instruct list.\n        Args:\n            list_to_update (List[Dict]): The list to update.\n            query (str): The query to be added.\n            response (str): The response to be added.\n            additional_field (Any): Additional field to be added.\n        Returns:\n            List[Dict]: The updated list.\n        \"\"\"\n        list_to_update.append({'instruction': query, 'input': additional_field, 'output': response})\n        return list_to_update\n\n    def get_response_from_llm(self, query: str, context: str) -> str:\n        \"\"\"\n        Get language model response to query for given context.\n        Args:\n            query (str): The query to be used for generating the response.\n            context (str): The context to be used for generating the response.\n        Returns:\n            str: The generated response.\n        \"\"\"\n        def get_context_and_prompt(query, context, code_qa):\n            full_context = f\"{context}\\nCODE Q and A:\\n{code_qa}\"\n            prompt = self.model_config['prompt_template'].format(context=full_context, query=query)\n            context_size = len(self.llm.tokenize(prompt))\n            return prompt, context_size\n\n        max_context_length = self.model_config['inference_model']['model_params']['context_length']\n        excluded_instructions = [\"Call code graph\", \"Docstring\"]\n        code_qa = (\n            \"\\n\".join([f\"Q: {item['instruction']} \\nA: {item['output']}\" \n            for item in self.instruct_list if not any(item['instruction'].startswith(prefix)\n            for prefix in excluded_instructions)])\n            )\n\n        # manage context length for LLM starting with the longest and most comprehensive\n        context_strategies = [\n            lambda: '```python\\n' + str(context) + '\\n```',\n            lambda: '```python\\n' + str(self.file_details['file_info']['file_code_simplified']) + '\\n```',\n            lambda: self.get_string_from_info(self.file_details['file_info'], 'file_summary'),\n            lambda: ''\n        ]\n        for strategy in context_strategies:\n            context = strategy()\n            prompt, context_size = get_context_and_prompt(query, context, code_qa)\n            if context_size <= 0.70 * max_context_length:\n                break\n        else:\n            logging.error(f'Model response failed, increase py2dataset_model_config.yaml context_length > {math.ceil(context_size/0.70)}')\n            return ''\n\n        try:\n            response = re.sub(r'\\n\\s*\\n', '\\n\\n', self.llm(prompt))\n            logging.info(f'Response: {response}')\n        except Exception as error:\n            logging.error(f'Failed to generate model response: {error}')\n            response = ''\n        return response\n\n    def process_question(self, question_type: str, question_id: str, query: str,\n                         context: str, info: Dict) -> None:\n        \"\"\"\n        Process question and add the generated response to the instruct_list.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            query (str): The query to be processed.\n            context (str): The context to be used for generating the response.\n            info (Dict): The information of the Python file.\n        Returns:\n            None\n        \"\"\"\n        if question_id.endswith('code_graph') or question_id.endswith('docstring'):\n            response = info.get(question_id, {})\n        else:\n            response = (\n                self.get_response_from_llm(query, context)\n                if self.use_llm and question_id.endswith('purpose')\n                else clean_and_get_unique_elements(str(info.get(question_id, '')))\n                )\n        if question_type == 'file':\n            context = self.file_details['file_info']['file_code']\n        if response and response != 'None':\n            response_str = str(response).strip()\n            if response_str:\n                self.instruct_list.append({\n                    'instruction': query,\n                    'input': context,\n                    'output': response_str\n                })\n\n    @staticmethod\n    def get_string_from_info(info, item_type):\n        \"\"\"\n        Get string from info dictionary.\n        Args:\n            info (Dict): The information of the Python file.\n            item_type (str): The type of item to get the string from.\n        Returns:\n            str: The string from the info.\n        \"\"\"\n        if info[item_type]:\n            items = [item.strip() for item in str(info[item_type]).split(',') if item]\n            return ', '.join(items)\n        return ''\n\n    def process_question_type(self, question_type: str, question_id: str,\n                              question_text: str) -> None:\n        \"\"\"\n        Process questions related to a file, function, class, or method.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            question_text (str): The text of the question to be processed.\n        Returns:\n            None\n        \"\"\"\n        if question_type == 'file':\n            query = question_text.format(filename=self.base_name)\n            info = self.file_details['file_info']\n            context = self.file_details['file_info']['file_code']\n            self.process_question(question_type, question_id, query, context, info)\n        elif question_type == 'method':\n            for class_name, class_info in self.file_details['classes'].items():\n                for key, method_info in class_info.items():\n                    if key.startswith('class_method_'):\n                        method_name = key[len('class_method_'):]\n                        context = method_info['method_code']\n                        mapping = {'class_name': class_name, 'method_name': method_name}\n                        query = question_text.format(filename=self.base_name, **mapping)\n                        self.process_question(question_type, question_id, query, context, method_info)\n        else:  # if question_type == 'function' or question_type == 'class'\n            for name, info in self.file_details[self.question_mapping[question_type]].items():\n                context = info[f'{question_type}_code']\n                mapping = {f'{question_type}_name': name}\n                if question_id == f'{question_type}_purpose' and self.use_llm:\n                    variables_string = self.get_string_from_info(info, f'{question_type}_variables')\n                    inputs_string = self.get_string_from_info(info, f'{question_type}_inputs')\n                    combined_string = ', '.join([s for s in [variables_string, inputs_string] if s])\n                    mapping[f'{question_type}_variables'] = clean_and_get_unique_elements(combined_string)\n                    # get methods to include in mapping for query\n                    if question_type == 'class':\n                        methods_string = self.get_string_from_info(info, f'{question_type}_methods')\n                        mapping[f'{question_type}_methods'] = methods_string\n\n                query = question_text.format(filename=self.base_name, **mapping)\n                self.process_question(question_type, question_id, query, context, info)\n\n    def generate(self) -> Tuple[List[Dict], List[Dict]]:\n\n        \"\"\"\n        Generate responses for all the questions and returns the instruct_list.\n        Args:\n            None\n        Returns:\n            Tuple[List[Dict], List[Dict]]: The generated question-answer pairs and instructions.\n        \"\"\"\n        for question in self.questions:\n            self.process_question_type(question['type'], question['id'], question['text'])\n        return self.instruct_list\n\n\ndef get_python_datasets(file_path: str, file_details: Dict, base_name: str, questions: List[Dict],\n                        model_config: Dict) -> Tuple[List[Dict], List[Dict]]:\n    \"\"\"\n    Extract information from a Python file and return it in JSON format.\n    Args:\n        file_path (str): The path to the Python file.\n        file_details (Dict): The details of the file.\n        base_name (str): The base Python code filename.\n        questions (List[Dict]): The list of questions.\n        llm (object): The language model to be used for generating responses.\n        prompt (str): The prompt to be used for generating responses.\n    Returns:\n        Tuple[List[Dict], List[Dict]]: Extracted information in JSON format.\n    \"\"\"\n    generator = DatasetGenerator(file_path, file_details, base_name, questions, model_config)\n    return generator.generate()\n"
    },
    {
        "instruction": "Define a Python code file that is described as follows:\nThe purpose of `py2dataset.get_python_file_details.py` is to extract file details from a Python source code file using the AST (Abstract Syntax Tree). The processing summary includes the following steps: \n1. Removing docstrings and comments from the provided code using `remove_docs_and_comments` function; \n2. Recursively finding all function calls in the subtree rooted at a given node using `get_all_calls`; \n3. Extracting details about functions, classes, and their methods using the `CodeVisitor` class that inherits from `ast.NodeVisitor`; \n4. Constructing a directed graph with nodes and edges using networkx library; \n5. Defining elements such as function nodes, class nodes, and method nodes; \n6. Specifying edges to represent relationships between the nodes; \n7. Returning a dictionary representation of the code call graph. \n\n#### Functions: \n- `remove_docs_and_comments` takes in a Python source code string as input and removes docstrings and comments from it, returning the sanitized code. It uses `ast.parse` to parse the code into an AST object, then iterates through each node of the tree and replaces any string nodes with empty strings or bytes objects with empty strings. This function is used in `get_python_file_details`. \n- `get_all_calls` takes in a node of type ast.AST as input and recursively finds all function calls in the subtree rooted at that node, returning a dictionary of all function calls in the subtree with their arguments. This function is used in `visit_FunctionDef`, where it will add an entry to `function_defs` dict or class attribute details when extracting functions and methods using the `extract_details` method; \n- `CodeVisitor` class accepts source code as input when instantiated, uses the AST to extract details about the code, and inherits from `ast.NodeVisitor`. It has implemented `visit_FunctionDef` to gather details about functions and methods in classes. When visiting a FunctionDef node, it calls `extract_details` method to populate either `functions` or `classes[current_class]` dict depending on whether it is inside a class definition or not. It also implements `visit_ClassDef` to gather details about classes and maintains the current class context using the attribute 'current_class'. \n- `extract_details` method takes in a node of type ast.AST and its type, and extracts various details such as function/method name, code representation, AST representation, docstring, input parameters (for functions and methods), defaults, return statements, calls, and the attributes or annotations present within that specific node's body; it adds all extracted data to the current context using either `functions` or `classes[current_class]` dict. If inside a class definition, it also populates `class_attributes`, `class_methods`, `class_inheritance`, and `class_static_methods`. \n- `analyze` method of CodeVisitor class takes in the current node (typically a FileAST node), analyzes each AST node to populate `file_info` dict with file details, such as dependencies, function names, class names, and their methods. It also creates a simplified version of the code without comments or docstrings using `remove_docs_and_comments`. \n- `code_graph` takes in the file summary (a dictionary containing all extracted information) and constructs a directed graph representing relationships between different functions and classes with method calls. This is done by first adding class nodes and method nodes, then iterating through each function/method to add edges for their respective calls. It uses `add_edges_for_calls` helper function to handle special cases such as calling methods within the same class or calling a constructor of another class. \n- `get_python_file_details` takes in a file path, extracts information using the AST and the `CodeVisitor` class, and returns a dictionary encompassing all extracted details, including the entire code graph as a dictionary representation. It uses `code_graph` to create the call graph, and then adds it to the final output dict. \n\n#### Variables: \n- `file_path`: The path to the Python file. Used in `get_python_file_details`.\n- `calls`: Dictionary of all function calls in a given node. Used in `get_all_calls` and `add_edges_for_calls`. \n- `code`: The source code. Used in `remove_docs_and_comments`, `CodeVisitor.__init__`, and `analyze`. \n- `node`: AST node being visited. Used in `visit_FunctionDef` and `visit_ClassDef`. \n- `details`: Dict containing extracted information about a given function/class definition, used in `extract_details` and `CodeVisitor.__init__`. \n- `node_walk`: List of all nodes within the AST. Used in `get_all_calls`, `visit_FunctionDef`, and `visit_ClassDef`. \n- `function_defs`: Dict containing details about functions, used in `code_graph` to create the final graph. \n- `class_defs`: List of dicts containing details about each class defined in the code, used in `code_graph` to create the final graph. \n- `G`: Directed graph created using networkx library. Used in `code_graph`. \n- `edge_data`: Dict containing edge data for a given node, used in `add_edge_with_data` and `get_edge_data_from_details`. \n- `file_info`: Dict containing file details such as dependencies, function names, class names, and their methods. Used in `analyze`, `code_graph`, and `get_python_file_details`. \n- `visitor`: Instance of the `CodeVisitor` class. Used in `get_python_file_details` to populate `functions` and `classes` attributes, then analyze the AST tree. \n- `current_class`: The current class being visited. Used in `visit_ClassDef`. \n- `qualified_method_name`: Fully qualified name of a method (e.g., `ClassName.method_name`). Used in `add_edges_for_calls` and `CodeVisitor.__init__`. \n- `function_details_lookup`: Dict containing details about all functions, used in `code_graph` to create the final graph. \n- `class_method_details_lookup`: Dict containing details about methods of each class, used in `add_edges_for_calls`. \n- `source_name`: Name of the source node (either a function or method). Used in `add_edge_with_data` and `add_edges_for_calls` when dealing with nested class definitions.\n#### Returns:\nThe `code_graph` function returns a dictionary representation of the code call graph, containing nodes and edges between them. The nodes are all functions/methods defined in the file, and the edges represent relationships between them (e.g., calling one another). Each edge has additional data such as input parameters, return values, and target inputs for each call. \nThe `get_python_file_details` function returns a dictionary containing information about the Python source code, including its dependencies, functions, classes, and their methods, as well as the entire code graph in a dictionary representation.",
        "output": "\"\"\"\nReturn file_details dictionary for python source code.\nRequirements:\n[req00] The `remove_docs_and_comments` function shall:\n        a. Accept a Python code string as an argument.\n        b. Remove docstrings and comments from the provided code.\n        c. Return the sanitized code string.\n[req01] The get_all_calls function shall:\n        a. Accept a node of type ast.AST as an argument.\n        b. Recursively find all function calls in the subtree rooted at the node.\n        c. Return a dictionary of all function calls in the subtree rooted at the node.\n[req02] The `CodeVisitor` class shall:\n        a. Accept the source code as input when instantiated.\n        b. Use the AST to extract details about the code.\n        c. Inherit from `ast.NodeVisitor`.\n        d. Implement `visit_FunctionDef` method to gather details about functions.\n        e. Implement `visit_ClassDef` method to gather details about classes.\n        f. Implement `extract_details` method to parse information about a given node.\n        g. Implement `analyze` method to traverse the AST and 'file_info'. \n        h. Maintain a current class context using the attribute 'current_class'.\n[req03] The `code_graph` function shall:\n        a. Accept the file summary as input.\n        b. Construct a directed graph with nodes and edges using networkx library.\n        c. Define elements such as function nodes, class nodes, and method nodes.\n        d. Specify edges to represent relationships. \n        e. Return a dictionary representation of the code call graph. \n[req04] The `get_python_file_details` function shall:\n        a. Accept a file path as an argument.\n        b. Extract info from Python file using the AST and the `CodeVisitor` class.\n        c. Include the entire code graph in the returned details.\n        d. Return a dictionary encompassing the extracted file details. \n\"\"\"\nimport ast\nimport json\nimport logging\nfrom typing import Dict, List, Optional, Union\nimport networkx as nx\nimport astor\n\ndef remove_docs_and_comments(code: str) -> str:\n    \"\"\"\n    Remove docstrings and comments from the provided code.\n    Args:\n        code: str: The source code.\n    Returns:\n        str: The sanitized code.\n    \"\"\"\n    parsed = ast.parse(code)\n    for node in ast.walk(parsed):\n        if isinstance(node, (ast.Expr, ast.Constant)) and isinstance(node.value, (ast.Str, ast.Bytes)):\n            node.value = ast.Constant(value='')\n        elif isinstance(node, ast.Constant) and isinstance(node.value, str):\n            node.value = node.value.replace('\"\"\"', '').replace(\"'''\", '')\n    return astor.to_source(parsed).strip()\n\n\ndef get_all_calls(node: ast.AST) -> Dict[str, List[str]]:\n    \"\"\"\n    Recursively find all function calls in the subtree rooted at `node`.\n    Args:\n        node (ast.AST): The node to start the search from.\n    Returns:\n        Dict[str, List[str]]: Dictionary with function calls as keys and arguments as values.\n    \"\"\"\n    calls = {}\n    for child in ast.iter_child_nodes(node):\n        if isinstance(child, ast.Call):\n            calls[ast.unparse(child.func)] = [ast.unparse(arg) for arg in child.args]\n        calls.update(get_all_calls(child))\n    return calls\n\n\nclass CodeVisitor(ast.NodeVisitor):\n    \"\"\"\n    Visitor class for traversing an AST (Abstract Syntax Tree) and extracting details about the code.\n    Attributes:\n        code (str): The source code.\n        functions(Dict): details about functions in the code.\n        classes (Dict): details about classes in the code.\n        file_info (Dict): details about the file.\n    Methods:\n        visit_FunctionDef(node: ast.FunctionDef) -> None: \n            Extract details about a function.\n        visit_ClassDef(node: ast.ClassDef) -> None: \n            Extract details about a class.\n        extract_details(node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]: \n            Extract details about a node.\n        analyze(node: ast.AST) -> None: \n            Populate file_info with details about the file.\n    \"\"\"\n    def __init__(self, code: str):\n        \"\"\"\n        Initialize a new instance of the class.\n        Args:\n            code: str: The source code.\n        Returns:\n            None\n        \"\"\"\n        self.code: str = code\n        self.functions: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.classes: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.file_info: Dict[str, Union[str, List[str]]] = {}\n        self.current_class: str = None\n\n    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n        \"\"\"\n        Extract details about a function.\n        Args:\n            node: ast.FunctionDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        details = self.extract_details(node, 'method' if self.current_class else 'function')\n        if self.current_class:\n            self.classes[self.current_class][f'class_method_{node.name}'] = details\n        else:\n            self.functions[node.name] = details\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n        \"\"\"\n        Extract details about a class.\n        Args:\n            node: ast.ClassDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        self.classes[node.name] = self.extract_details(node, 'class') # populate class dictionary when class definition found in AST\n        self.current_class = node.name  # set current_class to indicate inside a class\n        self.generic_visit(node) # continue AST traversal to the next node\n        self.current_class = None  # reset current_class when finished with this class\n\n    def extract_details(self, node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]:\n        \"\"\"\n        Extract details about a node.\n        Args:\n            node: ast.AST: The node to extract details from.\n            node_type: str: The type of node.\n        Returns:\n            Dict[str, Union[str, List[str]]]: The details extracted from the node.\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        call_data = get_all_calls(node)\n        details = {\n            f'{node_type}_name': node.name, \n            f'{node_type}_code': ast.unparse(node),\n            f'{node_type}_ast': ast.dump(node), \n            f'{node_type}_docstring': next((n.value.s for n in node_walk if isinstance(n, ast.Expr) and isinstance(n.value, ast.Str)), None),\n            f'{node_type}_inputs': [arg.arg for arg in node.args.args] if node_type in ['function', 'method'] else None,\n            f'{node_type}_defaults': [ast.unparse(d) for d in node.args.defaults] if node_type in ['function', 'method'] else None,\n            f'{node_type}_returns': [ast.unparse(subnode.value) if subnode.value is not None else \"None\" for subnode in node_walk if isinstance(subnode, ast.Return)],\n            f'{node_type}_calls': list(call_data.keys()),\n            f'{node_type}_call_inputs': call_data, \n            f'{node_type}_variables': list({ast.unparse(target) for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Name)}),\n            f'{node_type}_decorators': list({ast.unparse(decorator) for decorator in node.decorator_list} if node.decorator_list else set()),\n            f'{node_type}_annotations': list({ast.unparse(subnode.annotation) for subnode in node_walk if isinstance(subnode, ast.AnnAssign) and subnode.annotation is not None}),\n            f'{node_type}_properties': list({ast.unparse(subnode) for subnode in node_walk if isinstance(subnode, ast.Attribute) and isinstance(subnode.ctx, ast.Store)}),\n        }\n        if node_type in ['class', 'method']:\n            if node_type == 'method' and self.current_class: # find attributes defined as self.attribute\n                attributes = [target.attr for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute) and isinstance(target.value, ast.Name) and target.value.id == 'self']\n                self.classes[self.current_class].setdefault('class_attributes', []).extend(attributes)\n            if node_type == 'class':\n                details.update({\n                    'class_attributes': [target.attr for subnode in node.body if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute)],\n                    'class_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\"],\n                    'class_inheritance': [ast.unparse(base) for base in node.bases] if node.bases else [],\n                    'class_static_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\" and any(isinstance(decorator, ast.Name) and decorator.id == \"staticmethod\" for decorator in subnode.decorator_list)],\n                    })\n        return details\n\n    def analyze(self, node: ast.AST) -> None:\n        \"\"\"\n        Traverse the AST rooted at 'node', create a list of all nodes within the current file, and populate 'file_info' with file details\n        Args:\n            node: ast.AST: The node to analyze.\n        Returns:\n            None\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        self.visit(node)\n        self.file_info = {\n            'file_code': self.code,\n            'file_ast' : ast.dump(node),\n            'file_dependencies': list({alias.name for subnode in node_walk if isinstance(subnode, ast.Import) for alias in subnode.names} | {subnode.module for subnode in node_walk if isinstance(subnode, ast.ImportFrom)}),\n            'file_functions': list(self.functions.keys()),\n            'file_classes': list(self.classes.keys()),\n        }\n\n        # add file_summary to file_info\n        function_defs = [{func_name: {'inputs': details['function_inputs'], 'calls': details['function_calls'], 'call_inputs': details['function_call_inputs'], 'returns': details['function_returns']}} for func_name, details in self.functions.items()]\n        class_defs = []\n        for class_name, class_details in self.classes.items():\n            method_defs = {}\n            for method_name, details in class_details.items():\n                if method_name.startswith('class_method_'):\n                    method_defs[method_name[len('class_method_'):]] = {'inputs': details['method_inputs'], 'calls': details['method_calls'], 'call_inputs': details['method_call_inputs'], 'returns': details['method_returns']}\n            class_defs.append({class_name: {'method_defs': method_defs}})\n        self.file_info['file_summary'] = { 'dependencies': self.file_info['file_dependencies'], 'function_defs' : function_defs, 'class_defs' : class_defs}\n\n        file_code_simplified = remove_docs_and_comments(ast.unparse(node))\n        self.file_info['file_code_simplified'] = file_code_simplified\n\n\ndef code_graph(file_summary: Dict[str, Union[Dict, str]]) -> Dict[str, Union[List[str], Dict[str, List[str]]]]:\n    \"\"\"\n    Create a dictionary representation of file details.\n    Args:\n        file_summary: Dict[str, Union[Dict, str]]: The details extracted from the file.\n    Returns:\n        dict: A dictionary with nodes and edges representing the relationships in the code.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Create lookup dictionaries for function and class method details\n    function_details_lookup = {}\n    for function_def in file_summary['function_defs']:\n        function_details_lookup.update(function_def)\n    class_method_details_lookup = {}\n    for class_def in file_summary['class_defs']:\n        for class_name, class_details in class_def.items(): # Extract class name and details\n            G.add_node(class_name) # Add class as a graph node\n            for method_name, method_details in class_details['method_defs'].items():\n                qualified_method_name = f'{class_name}.{method_name}' # Create method fully qualified name\n                G.add_node(qualified_method_name) # Add method as a graph node\n                class_method_details_lookup[qualified_method_name] = method_details  # Store method details\n                G.add_edge(class_name, qualified_method_name) # Add edge from class to method\n\n    # Helper function to extract edge data from target details\n    def get_edge_data_from_details(target_details: dict, source_details: dict, target: str) -> dict:\n        edge_data = {}\n        if target_details:\n            edge_data['target_inputs'] = target_details.get('inputs')\n            edge_data['target_returns'] = list(set(target_details.get('returns', [])))\n        if source_details and 'call_inputs' in source_details and target in source_details['call_inputs']:\n            edge_data['target_inputs'] = source_details['call_inputs'][target]\n        return edge_data\n\n    # Helper function to add edge with data\n    def add_edge_with_data(source: str, target: str, init_method: Optional[str] = None) -> None:\n        target_details = class_method_details_lookup.get(init_method or target) or function_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        G.add_edge(source, target, **get_edge_data_from_details(target_details, source_details, target))\n\n    # Helper function to add edges for function or class method calls\n    def add_edges_for_calls(source_name, calls):\n        class_names = [list(class_def.keys())[0] for class_def in file_summary['class_defs']]\n        for called in calls:\n            called_class_name = called.split('.')[0]\n            if called.startswith(\"self.\"):\n                method_name = called.replace(\"self.\", \"\")\n                fully_qualified_name = f\"{source_name.split('.')[0]}.{method_name}\"\n                if fully_qualified_name in class_method_details_lookup:\n                    add_edge_with_data(source_name, fully_qualified_name)\n                    continue\n            if (\n                called in function_details_lookup or\n                called in class_method_details_lookup or\n                f\"{source_name.split('.')[0]}.{called}\" in class_method_details_lookup\n            ):\n                add_edge_with_data(source_name, called)\n            elif called_class_name in class_names:\n                init_method = None\n                init_method_name = f\"{called}.__init__\"\n                if init_method_name in class_method_details_lookup:\n                    init_method = init_method_name\n                add_edge_with_data(source_name, called, init_method)\n            else:\n                G.add_node(called)\n                add_edge_with_data(source_name, called)\n\n    # Add function nodes to graph and edges for function calls\n    for function_name in function_details_lookup:\n        G.add_node(function_name)\n    for func_name, details in function_details_lookup.items():\n        add_edges_for_calls(func_name, details['calls'])\n\n    # Add edges for method calls\n    for qualified_method_name, details in class_method_details_lookup.items():\n        add_edges_for_calls(qualified_method_name, details['calls'])\n\n    # Add edge data to edges and create node and edges to return\n    for edge in G.edges:\n        source, target = edge\n        target_details = function_details_lookup.get(target) or class_method_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        edge_data = get_edge_data_from_details(target_details, source_details, target)\n        G[source][target].update(edge_data)\n    nodes = list(G.nodes)\n    edges = [{\"source\": edge[0], \"target\": edge[1], **edge[2]} for edge in G.edges.data()]\n    return {\"nodes\": nodes, \"edges\": edges}\n\n\ndef get_python_file_details(file_path: str) -> Dict[str, Union[Dict, str]]:\n    \"\"\"\n    Extract details from a Python file.\n    Args:\n        file_path: str: The path to the Python file.\n    Returns:\n        Dict[str, Union[Dict, str]]: The details extracted from the file.\n    \"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors='ignore') as f:\n            code = f.read()\n            tree = ast.parse(code)\n    except (PermissionError, SyntaxError) as e:\n        logging.warning(f\"{e} error in file: {file_path}\")\n        return None\n\n    visitor = CodeVisitor(code)\n    visitor.analyze(tree)\n    file_details = {'file_info': visitor.file_info, 'functions': visitor.functions, 'classes': visitor.classes}\n    file_details['file_info']['entire_code_graph'] = code_graph(file_details['file_info']['file_summary'])\n    file_details['file_info']['file_summary'] = json.dumps(file_details['file_info']['file_summary']).replace('\\\"','')\n    return file_details\n"
    },
    {
        "instruction": "Define a Python code file that is described as follows:\nThe purpose of this Python file is to generate datasets that include responses to questions about a given directory of Python files. The `py2dataset` function processes all Python files within the specified directory, generates question-answer pairs, and stores them as JSON files for later use. The `process_single_file` function handles processing a single Python file by getting details from AST and answering provided questions with LLM (if used) and then storing them in JSON format. The main function provides a CLI interface for processing arguments such as the start directory, output directory, questions file path, model configuration pathname, use of LLM, and quiet mode.\n\n### Itemized and Detailed Description:\n- `process_single_file` - This function accepts parameters for Python file path, start directory, model config pathname, questions dictionary, use of LLM, and output dir. It then uses the 'get_python_file_details' function to retrieve details about the Python file using AST, and if 'use_llm' is True, it instantiates an LLM with `get_model`. Using this info along with `get_questions` from another Python module ('get_questions') generates 'instruct.json'-type data based on specific questions for each Python file. The function then saves the details and instruct.json data using the 'save_python_data' function.\n- `py2dataset` - This function accepts parameters for start directory, output dir, questions path, model config path, use of LLM, and quiet mode. It adjusts logging level based on 'quiet', uses the current working directory if no valid start directory is provided, retrieves questions dictionary with 'get_questions' and then searches for Python files using 'rglob', spawning a child process with 'process_single_file' to get file details and instruct.json data (if single_process is False). If not, it instantiates LLM once before processing all files. Finally, the function combines all of the 'instruct.json' files using `combine_json_files` and returns datasets as a dictionary of lists of dictionaries.\n- `main` - This function accepts command line arguments and determines parameters based on these to be passed to `py2dataset`. It then calls `py2dataset` with the derived parameters, handling any errors that may occur during processing.",
        "output": "\"\"\"\nFor each Python file within given directory, generate, save, and return datasets\nthat include responses to questions about the code.\nRequirements:\n[req00] The process_single_file function shall:\n    a. Accept parameters for Python file path, start directory, model config \n    pathname, questions dict, use of LLM, and output dir.\n    b. If 'use_llm' is True, use 'get_model' to instantiate LLM model config.\n    c. Use 'get_python_file_details' to retrieve Python file info.\n    d. Use 'get_python_datasets' to acquire instruct.json datasets.\n    e. Use 'save_python_data' to store file details and instruct.json data.\n[req01] The py2dataset function shall:\n    a. Accept parameters for start directory, output dir, questions path, model\n    config path, use of LLM, and quiet mode.\n    b. Adjust logging level based on 'quiet'.\n    c. Use current working dir if no valid start dir is provided.\n    d. Get output dir with 'get_output_dir'.\n    e. Retrieve questions dict with 'get_questions'.\n    f. Search for Python files using 'rglob', excluding those starting with \"_\".\n    g. For each Python file, spawn a child process with 'process_single_file'\n    to get file details and instruct.json data, if single_process is False.\n    h. Combine instruct.json files with 'combine_json_files'.\n    i. Return datasets.\n[req02] The main function shall:\n    a. Accept and process command-line args.\n    b. Determine py2dataset parameters based on processed arguments.\n    c. Call py2dataset with derived parameters.\n\"\"\"\nimport os\nimport sys\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List\nfrom multiprocessing import Process\n\nfrom get_python_file_details import get_python_file_details\nfrom get_python_datasets import get_python_datasets\nfrom get_py2dataset_params import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output import combine_json_files, save_python_data\n\ndef process_single_file(pythonfile_path: str, start_dir: str, model_config_pathname: str,\n                        questions: Dict, use_llm: bool, output_dir: str,\n                        model_config: Dict = None, single_process: bool = False) -> None:\n    \"\"\"\n    Process a single Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path (str): Path to the Python file.\n        start_dir (str): Starting directory to search for Python files.\n        model_config_pathname (str): Path to the model configuration file.\n        questions (Dict): Questions dictionary to answer about the Python file.\n        use_llm (bool): If True, use a Large Language Model for generating JSON answers.\n        output_dir (str): Directory to write the output files.\n        model_config (Dict): Model configuration dictionary for the LLM.\n        single_process (bool, optional): Set True to use single process. Defaults to False.\n    Returns:\n        none\n    \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    if not single_process:\n        # Instantiate llm and prompt if use_llm is True for each file to avoid\n        # multiprocessing pickling problem\n        model_config = get_model(model_config_pathname) if use_llm else (None, '', 0)\n\n    # Use AST to get python file details\n    file_details = get_python_file_details(pythonfile_path)\n    if file_details is None or isinstance(file_details, tuple):\n        return\n\n    # Get lists for instruct.json for python file\n    instruct_list = get_python_datasets(\n        pythonfile_path,\n        file_details,\n        base_name,\n        questions,\n        model_config\n        )\n    if instruct_list is None:\n        return\n\n    save_python_data(file_details, instruct_list, relative_path, output_dir)\n\ndef py2dataset(start_dir: str = '', output_dir: str = '', questions_pathname: str = '',\n               model_config_pathname: str = '', use_llm: bool = False, quiet: bool = False,\n               single_process: bool = False) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process Python files to generate question-answer pairs and instructions.\n    Args:\n        start_dir (str, optional): Starting directory for Python files.\n        Defaults to current working directory.\n        output_dir (str, optional): Directory to write the output files.\n        questions_pathname (str, optional): Path to the questions file.\n        model_config_pathname (str, optional): Path to the model\n        configuration file.\n        use_llm (bool, optional): If True, use a Large Language Model\n        for generating JSON answers. Defaults to False.\n        quiet (bool, optional): Limit logging output. Defaults to False.\n        single_process(bool, optional): If True, only a single process \n        will be used to process Python files. Defaults to False. Set to True to\n        instantiate LLM once before processing all files.\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)  # Increase the recursion limit for AST\n\n    # If start dir is empty or not a valid directory, use current working directory\n    if not start_dir:\n        logging.info('No valid start path provided. Using current working directory.')\n        start_dir = os.getcwd()\n    start_dir = os.path.abspath(start_dir)\n    output_dir = get_output_dir(output_dir)\n    questions = get_questions(questions_pathname)\n\n    # If single_process is True, load model config here\n    if single_process:\n        model_config = get_model(model_config_pathname) if use_llm else (None, '', 0)\n\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n        if pythonfile_path.is_dir():\n            continue\n        if single_process:\n            process_single_file(\n                pythonfile_path,\n                start_dir,\n                model_config_pathname,\n                questions,\n                use_llm,\n                output_dir,\n                model_config,\n                single_process)\n            continue\n        # Spawn a new child process to manage python memory leaks\n        proc = Process(\n            target=process_single_file,\n            args=(\n                pythonfile_path,\n                start_dir,\n                model_config_pathname,\n                questions,\n                use_llm,\n                output_dir)\n            )\n        proc.start()\n        proc.join()\n\n    # Combine all of the instruct.json files together\n    datasets = combine_json_files(output_dir)\n    return datasets\n\ndef main():\n    \"\"\"\n    Command-line entry point for processing Python files and generating datasets.\n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname = ''\n    use_llm = False\n    quiet = False\n    single_process = False\n\n    if '--start_dir' in arg_string:\n        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n    if '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n        model_config_pathname = arg_string.split('--model_config_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}', '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--questions_pathname {questions_pathname}', '')\n    if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string = arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n        quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n    if '--single_process' in arg_string:\n        single_process = True\n        arg_string = arg_string.replace('--single_process', '')\n\n    py2dataset(\n        start_dir,\n        output_dir,\n        questions_pathname,\n        model_config_pathname,\n        use_llm,\n        quiet,\n        single_process)\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    {
        "instruction": "Define a Python code file that is described as follows:\nThis Python file provides utilities for reading files (JSON or YAML), converting JSON files to HTML format, merging JSON files into a single JSON file, creating code graphs based on provided file details, and saving Python data as YAML files. \n\nFunctions defined in `py2dataset.save_py2dataset_output.py`:\n1. `read_file` - reads the contents of a JSON or YAML file as a dictionary.\n   Input: file path (str)\n   Output: dictionary containing the contents of the file\n   Variables: file type, f (file object), json/yaml loader\n2. `write_file` - writes a dictionary to a JSON or YAML file. \n   Inputs: data (dict), file path (Path)\n   Output: None\n   Variables: file type, f (file object), json/yaml dumper\n3. `convert_json_to_html` - convert JSON files within a given directory to HTML format, save each converted file with a .html extension while preserving input's spacing and tabs for the 'input' field. \n   Input: directory (str)\n   Output: None\n   Variables: html_content (HTML formatted content), Path(), html_file_path (file path of the output HTML file)\n4. `combine_json_files` - merge all JSON files in a given directory, remove duplicates from the combined JSON files, and write them to 'instruct.json' while generating HTML versions for each input dataset.\n   Inputs: directory (str)\n   Outputs: `{'instruct_list': List[Dict]}` containing the merged datasets without duplicates\n   Variables: instruct_data (List[Dict]), seen (set), result (List[Dict]), json_file, combined_data (List[Dict])\n5. `create_code_graph` - generate code graphs based on provided file details and save them as PNG images in the specified output directory. \n   Inputs: file_details (dict), base_name (str), output_subdir (Path)\n   Output: None\n   Variables: G (Graph object), pos (node positions), edge_labels (edge labels for graph), output_file (file path of the PNG image)\n6. `save_python_data` - save details of a Python file as YAML, generate and save instruction data as JSON files, and create code graphs. \n   Inputs: file_details (dict), instruct_list (List[Dict]), relative_path (Path), output_dir (str)\n   Output: None\n   Variables: output_subdir (Path object), base_name (str), file_names, contents, graph_type, pos, edge_labels, label, output_file\n\nFunctions in `py2dataset.save_py2dataset_output.py` perform the following tasks:\n1. Read a JSON or YAML file and return its contents as a dictionary using `read_file`. The purpose of this function is to simplify file read operations for all files. This ensures consistency when handling different formats for reading data from files.\n2. Write a dictionary to a JSON or YAML file using `write_file` to ensure consistency in writing the output data to disk. \n3. Convert JSON files within a given directory to HTML format using `convert_json_to_html`. The purpose of this function is to simplify file conversion operations and maintain consistency in handling different formats for output files. \n4. Combine all JSON files in an output directory into 'instruct.json' and remove duplicates from the combined data using `combine_json_files`. This function also generates HTML versions of each input dataset, which is useful for displaying the data visually.\n5. Generate code graphs based on provided file details using `create_code_graph` and save them as PNG images in a specified output directory using `save_python_data`. The purpose of this function is to visualize the relationships between different functions in a Python script, which can help with understanding the flow of execution. \n6. Save Python file details as a YAML file and the instruction data as JSON files using `save_python_data`, which allows for easy modification and updating of the input data. This function also ensures consistency in handling different formats for output files.",
        "output": "\"\"\"\nUtility functions for reading the input and saving the output of the py2dataset script.\nRequirements:\n[req01] The `read_file` function shall:\n        a. Accept a file path as an argument.\n        b. Read and return the contents of a JSON or YAML file as a dictionary.\n[req02] The `write_file` function shall:\n        a. Accept a dictionary and a file path as arguments.\n        b. Write the dictionary to a file in either JSON or YAML format.\n[req03] The `convert_json_to_html` function shall:\n        a. Convert JSON files within a given directory to HTML format.\n        b. Save each converted file with a .html extension.\n        c. Preserve spacing and tabs for the 'input' field.\n[req04] The `combine_json_files` function shall:\n        a. Accept a directory path as an argument.\n        b. Merge all JSON files in the directory.\n        c. Remove duplicates from the combined JSON files.\n        d. Write the combined data to 'instruct.json' files.\n        e. Convert the merged JSON files to HTML format.\n        f. Return the 'instruct_list' datasets.\n[req05] The `create_code_graph` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Generate code graphs based on the provided file details.\n        c. Save the graphs as PNG images in the specified output directory.\n[req06] The `save_python_data` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Save the details of the Python file as a YAML file.\n        c. Save the instruction data as JSON files.\n        d. Generate and save code graphs.\n\"\"\"\nimport json\nimport logging\nfrom html import escape\nfrom pathlib import Path\nfrom typing import Dict, List\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport yaml\n\ndef read_file(file_path: Path) -> Dict:\n    \"\"\"\n    Reads a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n    Returns:\n        The contents of the file as a dictionary.\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open() as f:\n        if file_type == 'json':\n            return json.load(f)\n        if file_type == 'yaml':\n            return yaml.load(f, Loader=yaml.SafeLoader)\n        return {}\n\ndef write_file(data: Dict, file_path: Path) -> None:\n    \"\"\"\n    Writes a dictionary to a JSON or YAML file. \n    Args:\n        data (Dict): The data to write to the file.\n        file_path (Path): The path to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open('w') as f:\n        if file_type == 'json':\n            json.dump(data, f, indent=4)\n        elif file_type == 'yaml':\n            yaml.SafeDumper.ignore_aliases = lambda *args: True\n            yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)\n\n\ndef convert_json_to_html(directory: str) -> None:\n    \"\"\"\n    Convert JSON files within a given directory to HTML format.\n    Args:\n        directory (str): The directory where the JSON files are located.\n    Returns:\n        None    \n    \"\"\"\n    def preserve_spacing(text: str, tab_width: int = 4) -> str:\n        \"\"\"Preserve spaces and tabs in the provided text.\"\"\"\n        return text.replace(\" \", \"&nbsp;\").replace(\"\\t\", \"&nbsp;\" * tab_width)\n\n    for json_file in Path(directory).rglob('*.json'):\n        dataset = read_file(json_file)\n        if not dataset:\n            continue\n\n        html_content = \"\"\"\n        <html>\n        <head>\n            <style>\n                table {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th, td {\n                    border: 1px solid black;\n                    padding: 8px;\n                    text-align: left;\n                    white-space: pre-line;\n                    vertical-align: top;\n                    word-wrap: break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        \"\"\"\n        column_count = len(dataset[0].keys())\n        column_width = 100 / column_count  # Calculate the width for each column based on the number of columns\n        for key in dataset[0].keys():\n            html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\n        html_content += \"\"\"\n                    </tr>\n                </thead>\n                <tbody>\n        \"\"\"\n        for entry in dataset:\n            html_content += \"<tr>\"\n            for key in entry:\n                # Convert \\n to HTML line breaks\n                value = escape(str(entry[key]))\n                value = preserve_spacing(value)\n                value = value.replace('\\n', '<br/>')\n                html_content += f\"<td>{value}</td>\"\n            html_content += \"</tr>\"\n\n        html_content += \"\"\"\n                </tbody>\n            </table>\n        </body>\n        </html>\n        \"\"\"\n        html_file_path = json_file.with_suffix('.html')\n        try:\n            with open(html_file_path, 'w', encoding='utf-8') as file:\n                file.write(html_content)\n        except Exception:\n            logging.info(f'Failed saving: {html_file_path}')\n\n\ndef combine_json_files(directory: str) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Combine all JSON files in the output directory into 'instruct.json', and \n    then remove duplicates.\n    Args:\n        directory (str): The directory where the output files are located.\n    Returns:\n        A dictionary containing the 'instruct_list' datasets.\n    \"\"\"\n\n    def remove_duplicate_dataset_entries(dataset: List[Dict], key1: str, key2: str) -> List[Dict]:\n        \"\"\"\n        Remove duplicate entries from the provided dataset based on the provided keys.\n        Args:\n            dataset (List[Dict]): The dataset to remove duplicates from.\n            key1 (str): The first key to check for duplicates.\n            key2 (str): The second key to check for duplicates.\n        Returns:\n            A dataset without duplicate entries.\n        \"\"\"\n        seen = set()\n        result = []\n        for item in dataset:\n            if (item[key1], item[key2]) not in seen:\n                seen.add((item[key1], item[key2]))\n                result.append(item)\n        return result\n\n    instruct_data = []\n    for file_name in ['instruct.json']:\n        file_path = Path(directory) / file_name\n        combined_data = []\n        for json_file in Path(directory).rglob(f'*.{file_name}'):\n            json_file_data = read_file(json_file)\n            combined_data.extend(json_file_data)\n            combined_data = remove_duplicate_dataset_entries(combined_data, 'instruction', 'output')\n            instruct_data = combined_data.copy()\n            # gen training datasets that contains purpose and graph data formatted for each item:\n            purpose_data = [item for item in combined_data if item['instruction'].startswith('1) DESCRIBE the purpose')]\n            graph_data = [item for item in combined_data if item['instruction'].startswith('Call code graph')]\n            code_output = []\n            graph_output = []\n            for item in purpose_data:\n                instruction = 'Define a Python code file that is described as follows:\\n'+ item['output']\n                code_output.append({'instruction': instruction, 'output': item['input']})\n            for item in graph_data:\n                instruction = 'Define the call code graph for this Python file:\\n' + item['input']\n                graph_output.append({'instruction': instruction, 'output': item['output']})\n            code_graph_output = code_output + graph_output\n            write_file(code_graph_output, Path(directory) / 'training.json')\n\n        write_file(combined_data, file_path)\n\n    # Save html file for each json file in the output directory\n    convert_json_to_html(directory)\n    return {'instruct_list': instruct_data}\n\n\ndef create_code_graph(file_details: Dict, base_name: str, output_subdir: Path) -> None:\n    \"\"\"\n    Generate graphs from the file_details and save them as PNG images.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        base_name (str): The base name of the output files.\n        output_subdir (Path): The subdirectory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    graph_type = 'entire_code_graph'\n    output_file = output_subdir / f'{base_name}.{graph_type}.png'\n\n    # Create graphs, add nodes, and add edges\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n    for edge in file_details['file_info'][graph_type]['edges']:\n        source, target = edge['source'], edge['target']\n        if source in G.nodes and target in G.nodes:\n            G.add_edge(source, target, **{k: v for k, v in edge.items() if k in ['target_inputs', 'target_returns']})\n    # Draw graphs\n    plt.figure(figsize=(20, 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True, font_weight='bold', font_size = 8, node_shape='s', node_size=500, width=1, arrowsize=12)\n    edge_labels = {}\n    for edge in G.edges(data=True):\n        label = []\n        if 'target_inputs' in edge[2] and edge[2]['target_inputs']:\n            label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\")\n        if 'target_returns' in edge[2] and edge[2]['target_returns']:\n            label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\")\n        edge_labels[(edge[0], edge[1])] = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n    plt.savefig(output_file) # Save the figure\n    plt.close()  # Close the figure\n\n\ndef save_python_data(file_details: dict, instruct_list: list, relative_path: Path, output_dir: str) -> None:\n    \"\"\"\n    Save Python file details as a YAML file, the instruction data as a JSON file, and code graphs.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        instruct_list (list): The instruction data extracted from the Python file.\n        relative_path (Path): The relative path to the Python file.\n        output_dir (str): The directory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir = Path(output_dir) / relative_path.parts[0]\n    output_subdir.mkdir(parents=True, exist_ok=True)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    # write instrunct.json files\n    file_names = [f'{base_name}.instruct.json', f'{base_name}.details.yaml']\n    contents = [instruct_list, file_details]\n\n    for file_name, content in zip(file_names, contents):\n        write_file(content, output_subdir / file_name)\n\n    try:\n        create_code_graph(file_details, base_name, output_subdir)\n    except Exception as e:\n        logging.info(f'Error creating graph for {base_name}: {e}')\n"
    },
    {
        "instruction": "Define a Python code file that is described as follows:\nThe purpose of this Python file is to generate a structured dataset from Python source code using AI generated context. The `setup()` function is used to create a package for distribution and installation, as per best practices defined by PEP 517 (Python packaging guidelines). Here are the step-by-step details:\n\nStep 1. The setup() function creates an object from setuptools which specifies metadata about the project such as name, version, author, and description. It also defines the package name, module name, and version requirements for installation.\n\nStep 2. The `long_description` variable is assigned to a Markdown-formatted README file, which contains detailed information about the package and its usage.\n\nStep 3. The `packages` argument specifies that only one Python module is included in this package: `py2dataset`. This is specified as a list of strings with the name of the directory containing the code.\n\nStep 4. The `package_dir` argument specifies where to look for the package, which is in the current directory ('.').\n\nStep 5. The `entry_points` argument defines a console script that can be run from the command line to execute the `py2dataset:main` function from the module.\n\nStep 6. Finally, it calls setup() and saves all these attributes to a `setup()` object and passes it as an argument.\n\nThere are no other classes or functions defined in this file, as everything is taken care of within the setup() function itself.\n\n1) Function: The only function present in `py2dataset.setup.py` is the `main()` function that executes when running `pip install py2dataset`. This function imports necessary modules and then uses setuptools to create a package with all its dependencies and metadata specified in the setup() function. \n\n2) Inputs: None, as this file is only used for installation purposes. \n\n3) Output: The output of `py2dataset.setup.py` is a Python package that can be installed using pip. This package includes all the necessary dependencies and metadata to create a structured dataset from Python source code.",
        "output": "from setuptools import setup\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"py2dataset\",\n    version=\"0.1\",\n    author=\"Jeff Meloy\",\n    author_email=\"jeffmeloy@gmail.com\",\n    description=\"A tool to generate structured datasets from Python source code\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/jeffmeloy/py2dataset\",\n    py_modules=[\"py2dataset\", \"get_python_file_details\", \"get_python_json\"],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires='>=3.8',\n    install_requires=[\n        \"matplotlib\",\n        \"networkx\",\n        \"ctransformers\",\n        \"pyyaml\"\n    ],\n    entry_points={'console_scripts': ['py2dataset = py2dataset:main']},\n    packages=['py2dataset'],\n    package_dir={'py2dataset': '.\\\\'},\n)"
    },
    {
        "instruction": "Define the call code graph for this Python file:\n\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returned items from function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible\n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 14000,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "{'nodes': ['get_default_questions', 'get_default_model_config', 'get_output_dir', 'get_questions', 'instantiate_model', 'get_model', 'write_questions_file', 'write_model_config_file', 'os.path.abspath', 'os.makedirs', 'logging.info', 'os.path.join', 'os.getcwd', 'open', 'json.load', \"model_config['model_import_path'].rsplit\", 'getattr', 'importlib.import_module', 'inference_function', 'model_params.pop', 'ModelClass', 'yaml.safe_load', 'Path(output_dir).is_dir', 'Path', 'json.dump', 'yaml.dump'], 'edges': [{'source': 'get_output_dir', 'target': 'os.path.abspath', 'target_inputs': ['output_dir or OUTPUT_DIR']}, {'source': 'get_output_dir', 'target': 'os.makedirs', 'target_inputs': ['output_dir']}, {'source': 'get_output_dir', 'target': 'logging.info', 'target_inputs': [\"f'Using output directory: {output_dir}'\"]}, {'source': 'get_questions', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'QUESTIONS_FILE']}, {'source': 'get_questions', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_questions', 'target': 'open', 'target_inputs': ['questions_pathname', \"'r'\"]}, {'source': 'get_questions', 'target': 'json.load', 'target_inputs': ['f']}, {'source': 'get_questions', 'target': 'logging.info', 'target_inputs': [\"f'Questions file not valid: {questions_pathname} Using default questions'\"]}, {'source': 'get_questions', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'instantiate_model', 'target': \"model_config['model_import_path'].rsplit\", 'target_inputs': [\"'.'\", '1']}, {'source': 'instantiate_model', 'target': 'getattr', 'target_inputs': ['ModelClass', 'inference_function_name']}, {'source': 'instantiate_model', 'target': 'importlib.import_module', 'target_inputs': ['module_name']}, {'source': 'instantiate_model', 'target': 'inference_function', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'model_params.pop', 'target_inputs': [\"'model_path'\"]}, {'source': 'instantiate_model', 'target': 'ModelClass', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'logging.info', 'target_inputs': [\"f'Failed to instantiate the model. Error: {e}'\"]}, {'source': 'get_model', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'MODEL_CONFIG_FILE']}, {'source': 'get_model', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_model', 'target': 'open', 'target_inputs': ['model_config_pathname', \"'r'\"]}, {'source': 'get_model', 'target': 'yaml.safe_load', 'target_inputs': ['config_file']}, {'source': 'get_model', 'target': 'logging.info', 'target_inputs': [\"f'Model config file not valid: {model_config_pathname} Using default model config'\"]}, {'source': 'get_model', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'get_model', 'target': 'instantiate_model', 'target_inputs': [\"model_config['inference_model']\"], 'target_returns': ['model', 'None']}, {'source': 'write_questions_file', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'write_questions_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_questions_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, QUESTIONS_FILE)', \"'w'\"]}, {'source': 'write_questions_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'QUESTIONS_FILE']}, {'source': 'write_questions_file', 'target': 'json.dump', 'target_inputs': ['questions', 'file']}, {'source': 'write_model_config_file', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'write_model_config_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_model_config_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, MODEL_CONFIG_FILE)', \"'w'\"]}, {'source': 'write_model_config_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'MODEL_CONFIG_FILE']}, {'source': 'write_model_config_file', 'target': 'yaml.dump', 'target_inputs': ['model_config', 'file']}]}"
    },
    {
        "instruction": "Define the call code graph for this Python file:\n\"\"\"\nGenerates JSON format question-answer pairs and instructions for a Python file\nRequirements:\n[req01] The `DatasetGenerator` class shall:\n        a. Accept Python file path, file details, base name, list of questions,\n        and model configuration as input during instantiation.\n        b. Initialize and store Python file path, file details, base name,\n        question list, llm, and use_llm flag as class attributes.\n        d. Provide `get_response_from_llm` method to retrieve llm response.\n        e. Provide `process_question` method to process each question, generate\n        corresponding responses, and add to the instruct_list.\n        f. Provide `process_question_type` method to process questions\n        related to the file, functions, classes, and methods.\n        g. Provide `generate` method to generate responses for all questions\n        and return the instruct_list.\n        h. Internally manage question mapping to file details.\n[req02] The `get_python_datasets` function shall:\n        a. Accept a Python file path, file details, base name, questions list,\n        and model config as input.\n        b. Instantiate `DatasetGenerator` class using the provided input.\n        c. Generate instruct_list using `DatasetGenerator` `generate` method.\n        d. Return the generated `instruct_list`.\n[req03] The `clean_and_get_unique_elements` function shall:\n        a. Clean an input string (str) and return a string of unique elements.\n\"\"\"\nimport logging\nimport re\nimport math\nfrom typing import Dict, List, Tuple\n\ndef clean_and_get_unique_elements(input_str: str) -> str:\n    \"\"\"\n    Clean input string and return string of unique elements.\n    Args:\n        input_str (str): The input string to be cleaned.\n    Returns:\n        str: The cleaned string.\n    \"\"\"\n    cleaned_elements = set(re.sub(r'[^\\w\\-_>\\s:/.]', '', element.strip())\n                            for element in re.sub(r'\\s+', ' ', input_str).split(','))\n    return ', '.join(cleaned_elements)\n\n\nclass DatasetGenerator:\n    \"\"\"\n    Generate JSON formatted dictionary outputs for a Python file.\n    Attributes:\n        file_path (str): The path to the Python file.\n        file_details (Dict[str, Any]): Details of the Python file.\n        base_name (str): The base name of the Python file.\n        questions (List[Dict[str, str]]): Questions for generating responses.\n        instruct_list (List[Dict[str, str]]): Storage for generated instructions.\n        question_mapping (Dict[str, str]): Mapping of question types to keys in file details.\n        use_llm (bool): Flag indicating if a language model should be used.\n        llm (object): The language model for generating responses.\n        prompt (str): The prompt format for querying the language model.\n    Methods:\n        add_to_list(list_to_update: List[Dict], query: str, response: str, \n        additional_field=None) -> List[Dict]: \n            Add response to the instruct list.\n        get_response_from_llm(query: str, context: str) -> str:\n            Get language model response to query for given context.\n        process_question(question_type: str, question_id: str, query: str, \n        context: str, info: Dict) -> None:\n            Process question and add generated response to the instruct_list.\n        process_question_type(question_type: str, question_id: str, \n        question_text: str) -> None:\n            Process question related to file, function, class, or method.\n        generate() -> Tuple[List[Dict], List[Dict]]:\n            Generate responses for all the questions and return the instruct_list.\n    \"\"\"\n\n    def __init__(self, file_path: str, file_details: Dict, base_name: str,\n                 questions: List[Dict], model_config: Dict) -> None:\n        \"\"\"\n        Initialize the DatasetGenerator class.\n        Args:\n            file_path (str): The path to the Python file.\n            file_details (Dict[str, Any]): Details of the Python file.\n            base_name (str): The base name of the Python file.\n            questions (List[Dict[str, str]]): Questions for generating responses.\n            model_config (Dict): Configuration for the language model.\n        Returns:\n            None\n        \"\"\"\n        self.file_path = file_path\n        self.file_details = file_details\n        self.base_name = base_name\n        self.questions = questions\n        self.model_config = model_config\n        self.llm = model_config['model']\n        if self.llm is None:\n            self.use_llm = False\n        else:\n            self.use_llm = True\n        self.instruct_list = []\n        self.question_mapping = {\n            'file': 'file',\n            'function': 'functions',\n            'class': 'classes',\n            'method': 'classes'\n        }\n\n    def add_to_list(\n        self,\n        list_to_update: List[Dict],\n        query: str,\n        response: str,\n        additional_field=None\n        ) -> List[Dict]:\n        \"\"\"\n        Add response to the instruct list.\n        Args:\n            list_to_update (List[Dict]): The list to update.\n            query (str): The query to be added.\n            response (str): The response to be added.\n            additional_field (Any): Additional field to be added.\n        Returns:\n            List[Dict]: The updated list.\n        \"\"\"\n        list_to_update.append({'instruction': query, 'input': additional_field, 'output': response})\n        return list_to_update\n\n    def get_response_from_llm(self, query: str, context: str) -> str:\n        \"\"\"\n        Get language model response to query for given context.\n        Args:\n            query (str): The query to be used for generating the response.\n            context (str): The context to be used for generating the response.\n        Returns:\n            str: The generated response.\n        \"\"\"\n        def get_context_and_prompt(query, context, code_qa):\n            full_context = f\"{context}\\nCODE Q and A:\\n{code_qa}\"\n            prompt = self.model_config['prompt_template'].format(context=full_context, query=query)\n            context_size = len(self.llm.tokenize(prompt))\n            return prompt, context_size\n\n        max_context_length = self.model_config['inference_model']['model_params']['context_length']\n        excluded_instructions = [\"Call code graph\", \"Docstring\"]\n        code_qa = (\n            \"\\n\".join([f\"Q: {item['instruction']} \\nA: {item['output']}\" \n            for item in self.instruct_list if not any(item['instruction'].startswith(prefix)\n            for prefix in excluded_instructions)])\n            )\n\n        # manage context length for LLM starting with the longest and most comprehensive\n        context_strategies = [\n            lambda: '```python\\n' + str(context) + '\\n```',\n            lambda: '```python\\n' + str(self.file_details['file_info']['file_code_simplified']) + '\\n```',\n            lambda: self.get_string_from_info(self.file_details['file_info'], 'file_summary'),\n            lambda: ''\n        ]\n        for strategy in context_strategies:\n            context = strategy()\n            prompt, context_size = get_context_and_prompt(query, context, code_qa)\n            if context_size <= 0.70 * max_context_length:\n                break\n        else:\n            logging.error(f'Model response failed, increase py2dataset_model_config.yaml context_length > {math.ceil(context_size/0.70)}')\n            return ''\n\n        try:\n            response = re.sub(r'\\n\\s*\\n', '\\n\\n', self.llm(prompt))\n            logging.info(f'Response: {response}')\n        except Exception as error:\n            logging.error(f'Failed to generate model response: {error}')\n            response = ''\n        return response\n\n    def process_question(self, question_type: str, question_id: str, query: str,\n                         context: str, info: Dict) -> None:\n        \"\"\"\n        Process question and add the generated response to the instruct_list.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            query (str): The query to be processed.\n            context (str): The context to be used for generating the response.\n            info (Dict): The information of the Python file.\n        Returns:\n            None\n        \"\"\"\n        if question_id.endswith('code_graph') or question_id.endswith('docstring'):\n            response = info.get(question_id, {})\n        else:\n            response = (\n                self.get_response_from_llm(query, context)\n                if self.use_llm and question_id.endswith('purpose')\n                else clean_and_get_unique_elements(str(info.get(question_id, '')))\n                )\n        if question_type == 'file':\n            context = self.file_details['file_info']['file_code']\n        if response and response != 'None':\n            response_str = str(response).strip()\n            if response_str:\n                self.instruct_list.append({\n                    'instruction': query,\n                    'input': context,\n                    'output': response_str\n                })\n\n    @staticmethod\n    def get_string_from_info(info, item_type):\n        \"\"\"\n        Get string from info dictionary.\n        Args:\n            info (Dict): The information of the Python file.\n            item_type (str): The type of item to get the string from.\n        Returns:\n            str: The string from the info.\n        \"\"\"\n        if info[item_type]:\n            items = [item.strip() for item in str(info[item_type]).split(',') if item]\n            return ', '.join(items)\n        return ''\n\n    def process_question_type(self, question_type: str, question_id: str,\n                              question_text: str) -> None:\n        \"\"\"\n        Process questions related to a file, function, class, or method.\n        Args:\n            question_type (str): The type of question to be processed.\n            question_id (str): The ID of the question to be processed.\n            question_text (str): The text of the question to be processed.\n        Returns:\n            None\n        \"\"\"\n        if question_type == 'file':\n            query = question_text.format(filename=self.base_name)\n            info = self.file_details['file_info']\n            context = self.file_details['file_info']['file_code']\n            self.process_question(question_type, question_id, query, context, info)\n        elif question_type == 'method':\n            for class_name, class_info in self.file_details['classes'].items():\n                for key, method_info in class_info.items():\n                    if key.startswith('class_method_'):\n                        method_name = key[len('class_method_'):]\n                        context = method_info['method_code']\n                        mapping = {'class_name': class_name, 'method_name': method_name}\n                        query = question_text.format(filename=self.base_name, **mapping)\n                        self.process_question(question_type, question_id, query, context, method_info)\n        else:  # if question_type == 'function' or question_type == 'class'\n            for name, info in self.file_details[self.question_mapping[question_type]].items():\n                context = info[f'{question_type}_code']\n                mapping = {f'{question_type}_name': name}\n                if question_id == f'{question_type}_purpose' and self.use_llm:\n                    variables_string = self.get_string_from_info(info, f'{question_type}_variables')\n                    inputs_string = self.get_string_from_info(info, f'{question_type}_inputs')\n                    combined_string = ', '.join([s for s in [variables_string, inputs_string] if s])\n                    mapping[f'{question_type}_variables'] = clean_and_get_unique_elements(combined_string)\n                    # get methods to include in mapping for query\n                    if question_type == 'class':\n                        methods_string = self.get_string_from_info(info, f'{question_type}_methods')\n                        mapping[f'{question_type}_methods'] = methods_string\n\n                query = question_text.format(filename=self.base_name, **mapping)\n                self.process_question(question_type, question_id, query, context, info)\n\n    def generate(self) -> Tuple[List[Dict], List[Dict]]:\n\n        \"\"\"\n        Generate responses for all the questions and returns the instruct_list.\n        Args:\n            None\n        Returns:\n            Tuple[List[Dict], List[Dict]]: The generated question-answer pairs and instructions.\n        \"\"\"\n        for question in self.questions:\n            self.process_question_type(question['type'], question['id'], question['text'])\n        return self.instruct_list\n\n\ndef get_python_datasets(file_path: str, file_details: Dict, base_name: str, questions: List[Dict],\n                        model_config: Dict) -> Tuple[List[Dict], List[Dict]]:\n    \"\"\"\n    Extract information from a Python file and return it in JSON format.\n    Args:\n        file_path (str): The path to the Python file.\n        file_details (Dict): The details of the file.\n        base_name (str): The base Python code filename.\n        questions (List[Dict]): The list of questions.\n        llm (object): The language model to be used for generating responses.\n        prompt (str): The prompt to be used for generating responses.\n    Returns:\n        Tuple[List[Dict], List[Dict]]: Extracted information in JSON format.\n    \"\"\"\n    generator = DatasetGenerator(file_path, file_details, base_name, questions, model_config)\n    return generator.generate()\n",
        "output": "{'nodes': ['DatasetGenerator', 'DatasetGenerator.__init__', 'DatasetGenerator.add_to_list', 'DatasetGenerator.get_response_from_llm', 'DatasetGenerator.get_context_and_prompt', 'DatasetGenerator.process_question', 'DatasetGenerator.get_string_from_info', 'DatasetGenerator.process_question_type', 'DatasetGenerator.generate', 'clean_and_get_unique_elements', 'get_python_datasets', 'set', 're.sub', 'element.strip', \"re.sub('\\\\\\\\s+', ' ', input_str).split\", \"', '.join\", 'generator.generate', 'list_to_update.append', \"self.model_config['prompt_template'].format\", 'len', 'self.llm.tokenize', \"'\\\\n'.join\", 'any', \"item['instruction'].startswith\", 'str', 'strategy', 'get_context_and_prompt', 'logging.error', 'math.ceil', 'self.llm', 'logging.info', 'question_id.endswith', 'info.get', 'str(response).strip', 'self.instruct_list.append', 'item.strip', 'str(info[item_type]).split', 'question_text.format', \"self.file_details['classes'].items\", 'class_info.items', 'key.startswith', 'self.file_details[self.question_mapping[question_type]].items'], 'edges': [{'source': 'DatasetGenerator', 'target': 'DatasetGenerator.__init__', 'target_inputs': ['self', 'file_path', 'file_details', 'base_name', 'questions', 'model_config'], 'target_returns': []}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.add_to_list', 'target_inputs': ['self', 'list_to_update', 'query', 'response', 'additional_field'], 'target_returns': ['list_to_update']}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.get_response_from_llm', 'target_inputs': ['self', 'query', 'context'], 'target_returns': ['response', \"''\", '(prompt, context_size)']}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.get_context_and_prompt', 'target_inputs': ['query', 'context', 'code_qa'], 'target_returns': ['(prompt, context_size)']}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.process_question', 'target_inputs': ['self', 'question_type', 'question_id', 'query', 'context', 'info'], 'target_returns': []}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.get_string_from_info', 'target_inputs': ['info', 'item_type'], 'target_returns': [\"', '.join(items)\", \"''\"]}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.process_question_type', 'target_inputs': ['self', 'question_type', 'question_id', 'question_text'], 'target_returns': []}, {'source': 'DatasetGenerator', 'target': 'DatasetGenerator.generate', 'target_inputs': ['self'], 'target_returns': ['self.instruct_list']}, {'source': 'DatasetGenerator.add_to_list', 'target': 'list_to_update.append', 'target_inputs': [\"{'instruction': query, 'input': additional_field, 'output': response}\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': \"self.model_config['prompt_template'].format\", 'target_inputs': []}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'len', 'target_inputs': ['self.llm.tokenize(prompt)']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'self.llm.tokenize', 'target_inputs': ['prompt']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': \"'\\\\n'.join\", 'target_inputs': ['[f\"Q: {item[\\'instruction\\']} \\\\nA: {item[\\'output\\']}\" for item in self.instruct_list if not any((item[\\'instruction\\'].startswith(prefix) for prefix in excluded_instructions))]']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'any', 'target_inputs': [\"(item['instruction'].startswith(prefix) for prefix in excluded_instructions)\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': \"item['instruction'].startswith\", 'target_inputs': ['prefix']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'str', 'target_inputs': [\"self.file_details['file_info']['file_code_simplified']\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'DatasetGenerator.get_string_from_info', 'target_inputs': ['info', 'item_type'], 'target_returns': [\"', '.join(items)\", \"''\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'strategy', 'target_inputs': []}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'get_context_and_prompt', 'target_inputs': ['query', 'context', 'code_qa']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'logging.error', 'target_inputs': [\"f'Failed to generate model response: {error}'\"]}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'math.ceil', 'target_inputs': ['context_size / 0.7']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 're.sub', 'target_inputs': [\"'\\\\\\\\n\\\\\\\\s*\\\\\\\\n'\", \"'\\\\n\\\\n'\", 'self.llm(prompt)']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'self.llm', 'target_inputs': ['prompt']}, {'source': 'DatasetGenerator.get_response_from_llm', 'target': 'logging.info', 'target_inputs': [\"f'Response: {response}'\"]}, {'source': 'DatasetGenerator.get_context_and_prompt', 'target': \"self.model_config['prompt_template'].format\", 'target_inputs': []}, {'source': 'DatasetGenerator.get_context_and_prompt', 'target': 'len', 'target_inputs': ['self.llm.tokenize(prompt)']}, {'source': 'DatasetGenerator.get_context_and_prompt', 'target': 'self.llm.tokenize', 'target_inputs': ['prompt']}, {'source': 'DatasetGenerator.process_question', 'target': 'question_id.endswith', 'target_inputs': [\"'purpose'\"]}, {'source': 'DatasetGenerator.process_question', 'target': 'info.get', 'target_inputs': ['question_id', \"''\"]}, {'source': 'DatasetGenerator.process_question', 'target': 'DatasetGenerator.get_response_from_llm', 'target_inputs': ['self', 'query', 'context'], 'target_returns': ['response', \"''\", '(prompt, context_size)']}, {'source': 'DatasetGenerator.process_question', 'target': 'clean_and_get_unique_elements', 'target_inputs': [\"str(info.get(question_id, ''))\"], 'target_returns': [\"', '.join(cleaned_elements)\"]}, {'source': 'DatasetGenerator.process_question', 'target': 'str', 'target_inputs': ['response']}, {'source': 'DatasetGenerator.process_question', 'target': 'str(response).strip', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question', 'target': 'self.instruct_list.append', 'target_inputs': [\"{'instruction': query, 'input': context, 'output': response_str}\"]}, {'source': 'DatasetGenerator.get_string_from_info', 'target': 'item.strip', 'target_inputs': []}, {'source': 'DatasetGenerator.get_string_from_info', 'target': 'str(info[item_type]).split', 'target_inputs': [\"','\"]}, {'source': 'DatasetGenerator.get_string_from_info', 'target': 'str', 'target_inputs': ['info[item_type]']}, {'source': 'DatasetGenerator.get_string_from_info', 'target': \"', '.join\", 'target_inputs': ['items']}, {'source': 'DatasetGenerator.process_question_type', 'target': 'question_text.format', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'DatasetGenerator.process_question', 'target_inputs': ['self', 'question_type', 'question_id', 'query', 'context', 'info'], 'target_returns': []}, {'source': 'DatasetGenerator.process_question_type', 'target': \"self.file_details['classes'].items\", 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'class_info.items', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'key.startswith', 'target_inputs': [\"'class_method_'\"]}, {'source': 'DatasetGenerator.process_question_type', 'target': 'len', 'target_inputs': [\"'class_method_'\"]}, {'source': 'DatasetGenerator.process_question_type', 'target': 'self.file_details[self.question_mapping[question_type]].items', 'target_inputs': []}, {'source': 'DatasetGenerator.process_question_type', 'target': 'DatasetGenerator.get_string_from_info', 'target_inputs': ['info', 'item_type'], 'target_returns': [\"', '.join(items)\", \"''\"]}, {'source': 'DatasetGenerator.process_question_type', 'target': \"', '.join\", 'target_inputs': ['[s for s in [variables_string, inputs_string] if s]']}, {'source': 'DatasetGenerator.process_question_type', 'target': 'clean_and_get_unique_elements', 'target_inputs': ['combined_string'], 'target_returns': [\"', '.join(cleaned_elements)\"]}, {'source': 'DatasetGenerator.generate', 'target': 'DatasetGenerator.process_question_type', 'target_inputs': ['self', 'question_type', 'question_id', 'question_text'], 'target_returns': []}, {'source': 'clean_and_get_unique_elements', 'target': 'set', 'target_inputs': [\"(re.sub('[^\\\\\\\\w\\\\\\\\-_>\\\\\\\\s:/.]', '', element.strip()) for element in re.sub('\\\\\\\\s+', ' ', input_str).split(','))\"]}, {'source': 'clean_and_get_unique_elements', 'target': 're.sub', 'target_inputs': [\"'\\\\\\\\s+'\", \"' '\", 'input_str']}, {'source': 'clean_and_get_unique_elements', 'target': 'element.strip', 'target_inputs': []}, {'source': 'clean_and_get_unique_elements', 'target': \"re.sub('\\\\\\\\s+', ' ', input_str).split\", 'target_inputs': [\"','\"]}, {'source': 'clean_and_get_unique_elements', 'target': \"', '.join\", 'target_inputs': ['cleaned_elements']}, {'source': 'get_python_datasets', 'target': 'DatasetGenerator', 'target_inputs': ['file_path', 'file_details', 'base_name', 'questions', 'model_config'], 'target_returns': []}, {'source': 'get_python_datasets', 'target': 'generator.generate', 'target_inputs': []}]}"
    },
    {
        "instruction": "Define the call code graph for this Python file:\n\"\"\"\nReturn file_details dictionary for python source code.\nRequirements:\n[req00] The `remove_docs_and_comments` function shall:\n        a. Accept a Python code string as an argument.\n        b. Remove docstrings and comments from the provided code.\n        c. Return the sanitized code string.\n[req01] The get_all_calls function shall:\n        a. Accept a node of type ast.AST as an argument.\n        b. Recursively find all function calls in the subtree rooted at the node.\n        c. Return a dictionary of all function calls in the subtree rooted at the node.\n[req02] The `CodeVisitor` class shall:\n        a. Accept the source code as input when instantiated.\n        b. Use the AST to extract details about the code.\n        c. Inherit from `ast.NodeVisitor`.\n        d. Implement `visit_FunctionDef` method to gather details about functions.\n        e. Implement `visit_ClassDef` method to gather details about classes.\n        f. Implement `extract_details` method to parse information about a given node.\n        g. Implement `analyze` method to traverse the AST and 'file_info'. \n        h. Maintain a current class context using the attribute 'current_class'.\n[req03] The `code_graph` function shall:\n        a. Accept the file summary as input.\n        b. Construct a directed graph with nodes and edges using networkx library.\n        c. Define elements such as function nodes, class nodes, and method nodes.\n        d. Specify edges to represent relationships. \n        e. Return a dictionary representation of the code call graph. \n[req04] The `get_python_file_details` function shall:\n        a. Accept a file path as an argument.\n        b. Extract info from Python file using the AST and the `CodeVisitor` class.\n        c. Include the entire code graph in the returned details.\n        d. Return a dictionary encompassing the extracted file details. \n\"\"\"\nimport ast\nimport json\nimport logging\nfrom typing import Dict, List, Optional, Union\nimport networkx as nx\nimport astor\n\ndef remove_docs_and_comments(code: str) -> str:\n    \"\"\"\n    Remove docstrings and comments from the provided code.\n    Args:\n        code: str: The source code.\n    Returns:\n        str: The sanitized code.\n    \"\"\"\n    parsed = ast.parse(code)\n    for node in ast.walk(parsed):\n        if isinstance(node, (ast.Expr, ast.Constant)) and isinstance(node.value, (ast.Str, ast.Bytes)):\n            node.value = ast.Constant(value='')\n        elif isinstance(node, ast.Constant) and isinstance(node.value, str):\n            node.value = node.value.replace('\"\"\"', '').replace(\"'''\", '')\n    return astor.to_source(parsed).strip()\n\n\ndef get_all_calls(node: ast.AST) -> Dict[str, List[str]]:\n    \"\"\"\n    Recursively find all function calls in the subtree rooted at `node`.\n    Args:\n        node (ast.AST): The node to start the search from.\n    Returns:\n        Dict[str, List[str]]: Dictionary with function calls as keys and arguments as values.\n    \"\"\"\n    calls = {}\n    for child in ast.iter_child_nodes(node):\n        if isinstance(child, ast.Call):\n            calls[ast.unparse(child.func)] = [ast.unparse(arg) for arg in child.args]\n        calls.update(get_all_calls(child))\n    return calls\n\n\nclass CodeVisitor(ast.NodeVisitor):\n    \"\"\"\n    Visitor class for traversing an AST (Abstract Syntax Tree) and extracting details about the code.\n    Attributes:\n        code (str): The source code.\n        functions(Dict): details about functions in the code.\n        classes (Dict): details about classes in the code.\n        file_info (Dict): details about the file.\n    Methods:\n        visit_FunctionDef(node: ast.FunctionDef) -> None: \n            Extract details about a function.\n        visit_ClassDef(node: ast.ClassDef) -> None: \n            Extract details about a class.\n        extract_details(node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]: \n            Extract details about a node.\n        analyze(node: ast.AST) -> None: \n            Populate file_info with details about the file.\n    \"\"\"\n    def __init__(self, code: str):\n        \"\"\"\n        Initialize a new instance of the class.\n        Args:\n            code: str: The source code.\n        Returns:\n            None\n        \"\"\"\n        self.code: str = code\n        self.functions: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.classes: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.file_info: Dict[str, Union[str, List[str]]] = {}\n        self.current_class: str = None\n\n    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n        \"\"\"\n        Extract details about a function.\n        Args:\n            node: ast.FunctionDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        details = self.extract_details(node, 'method' if self.current_class else 'function')\n        if self.current_class:\n            self.classes[self.current_class][f'class_method_{node.name}'] = details\n        else:\n            self.functions[node.name] = details\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n        \"\"\"\n        Extract details about a class.\n        Args:\n            node: ast.ClassDef: The node to visit.\n        Returns:\n            None\n        \"\"\"\n        self.classes[node.name] = self.extract_details(node, 'class') # populate class dictionary when class definition found in AST\n        self.current_class = node.name  # set current_class to indicate inside a class\n        self.generic_visit(node) # continue AST traversal to the next node\n        self.current_class = None  # reset current_class when finished with this class\n\n    def extract_details(self, node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]:\n        \"\"\"\n        Extract details about a node.\n        Args:\n            node: ast.AST: The node to extract details from.\n            node_type: str: The type of node.\n        Returns:\n            Dict[str, Union[str, List[str]]]: The details extracted from the node.\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        call_data = get_all_calls(node)\n        details = {\n            f'{node_type}_name': node.name, \n            f'{node_type}_code': ast.unparse(node),\n            f'{node_type}_ast': ast.dump(node), \n            f'{node_type}_docstring': next((n.value.s for n in node_walk if isinstance(n, ast.Expr) and isinstance(n.value, ast.Str)), None),\n            f'{node_type}_inputs': [arg.arg for arg in node.args.args] if node_type in ['function', 'method'] else None,\n            f'{node_type}_defaults': [ast.unparse(d) for d in node.args.defaults] if node_type in ['function', 'method'] else None,\n            f'{node_type}_returns': [ast.unparse(subnode.value) if subnode.value is not None else \"None\" for subnode in node_walk if isinstance(subnode, ast.Return)],\n            f'{node_type}_calls': list(call_data.keys()),\n            f'{node_type}_call_inputs': call_data, \n            f'{node_type}_variables': list({ast.unparse(target) for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Name)}),\n            f'{node_type}_decorators': list({ast.unparse(decorator) for decorator in node.decorator_list} if node.decorator_list else set()),\n            f'{node_type}_annotations': list({ast.unparse(subnode.annotation) for subnode in node_walk if isinstance(subnode, ast.AnnAssign) and subnode.annotation is not None}),\n            f'{node_type}_properties': list({ast.unparse(subnode) for subnode in node_walk if isinstance(subnode, ast.Attribute) and isinstance(subnode.ctx, ast.Store)}),\n        }\n        if node_type in ['class', 'method']:\n            if node_type == 'method' and self.current_class: # find attributes defined as self.attribute\n                attributes = [target.attr for subnode in node_walk if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute) and isinstance(target.value, ast.Name) and target.value.id == 'self']\n                self.classes[self.current_class].setdefault('class_attributes', []).extend(attributes)\n            if node_type == 'class':\n                details.update({\n                    'class_attributes': [target.attr for subnode in node.body if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute)],\n                    'class_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\"],\n                    'class_inheritance': [ast.unparse(base) for base in node.bases] if node.bases else [],\n                    'class_static_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != \"__init__\" and any(isinstance(decorator, ast.Name) and decorator.id == \"staticmethod\" for decorator in subnode.decorator_list)],\n                    })\n        return details\n\n    def analyze(self, node: ast.AST) -> None:\n        \"\"\"\n        Traverse the AST rooted at 'node', create a list of all nodes within the current file, and populate 'file_info' with file details\n        Args:\n            node: ast.AST: The node to analyze.\n        Returns:\n            None\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        self.visit(node)\n        self.file_info = {\n            'file_code': self.code,\n            'file_ast' : ast.dump(node),\n            'file_dependencies': list({alias.name for subnode in node_walk if isinstance(subnode, ast.Import) for alias in subnode.names} | {subnode.module for subnode in node_walk if isinstance(subnode, ast.ImportFrom)}),\n            'file_functions': list(self.functions.keys()),\n            'file_classes': list(self.classes.keys()),\n        }\n\n        # add file_summary to file_info\n        function_defs = [{func_name: {'inputs': details['function_inputs'], 'calls': details['function_calls'], 'call_inputs': details['function_call_inputs'], 'returns': details['function_returns']}} for func_name, details in self.functions.items()]\n        class_defs = []\n        for class_name, class_details in self.classes.items():\n            method_defs = {}\n            for method_name, details in class_details.items():\n                if method_name.startswith('class_method_'):\n                    method_defs[method_name[len('class_method_'):]] = {'inputs': details['method_inputs'], 'calls': details['method_calls'], 'call_inputs': details['method_call_inputs'], 'returns': details['method_returns']}\n            class_defs.append({class_name: {'method_defs': method_defs}})\n        self.file_info['file_summary'] = { 'dependencies': self.file_info['file_dependencies'], 'function_defs' : function_defs, 'class_defs' : class_defs}\n\n        file_code_simplified = remove_docs_and_comments(ast.unparse(node))\n        self.file_info['file_code_simplified'] = file_code_simplified\n\n\ndef code_graph(file_summary: Dict[str, Union[Dict, str]]) -> Dict[str, Union[List[str], Dict[str, List[str]]]]:\n    \"\"\"\n    Create a dictionary representation of file details.\n    Args:\n        file_summary: Dict[str, Union[Dict, str]]: The details extracted from the file.\n    Returns:\n        dict: A dictionary with nodes and edges representing the relationships in the code.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Create lookup dictionaries for function and class method details\n    function_details_lookup = {}\n    for function_def in file_summary['function_defs']:\n        function_details_lookup.update(function_def)\n    class_method_details_lookup = {}\n    for class_def in file_summary['class_defs']:\n        for class_name, class_details in class_def.items(): # Extract class name and details\n            G.add_node(class_name) # Add class as a graph node\n            for method_name, method_details in class_details['method_defs'].items():\n                qualified_method_name = f'{class_name}.{method_name}' # Create method fully qualified name\n                G.add_node(qualified_method_name) # Add method as a graph node\n                class_method_details_lookup[qualified_method_name] = method_details  # Store method details\n                G.add_edge(class_name, qualified_method_name) # Add edge from class to method\n\n    # Helper function to extract edge data from target details\n    def get_edge_data_from_details(target_details: dict, source_details: dict, target: str) -> dict:\n        edge_data = {}\n        if target_details:\n            edge_data['target_inputs'] = target_details.get('inputs')\n            edge_data['target_returns'] = list(set(target_details.get('returns', [])))\n        if source_details and 'call_inputs' in source_details and target in source_details['call_inputs']:\n            edge_data['target_inputs'] = source_details['call_inputs'][target]\n        return edge_data\n\n    # Helper function to add edge with data\n    def add_edge_with_data(source: str, target: str, init_method: Optional[str] = None) -> None:\n        target_details = class_method_details_lookup.get(init_method or target) or function_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        G.add_edge(source, target, **get_edge_data_from_details(target_details, source_details, target))\n\n    # Helper function to add edges for function or class method calls\n    def add_edges_for_calls(source_name, calls):\n        class_names = [list(class_def.keys())[0] for class_def in file_summary['class_defs']]\n        for called in calls:\n            called_class_name = called.split('.')[0]\n            if called.startswith(\"self.\"):\n                method_name = called.replace(\"self.\", \"\")\n                fully_qualified_name = f\"{source_name.split('.')[0]}.{method_name}\"\n                if fully_qualified_name in class_method_details_lookup:\n                    add_edge_with_data(source_name, fully_qualified_name)\n                    continue\n            if (\n                called in function_details_lookup or\n                called in class_method_details_lookup or\n                f\"{source_name.split('.')[0]}.{called}\" in class_method_details_lookup\n            ):\n                add_edge_with_data(source_name, called)\n            elif called_class_name in class_names:\n                init_method = None\n                init_method_name = f\"{called}.__init__\"\n                if init_method_name in class_method_details_lookup:\n                    init_method = init_method_name\n                add_edge_with_data(source_name, called, init_method)\n            else:\n                G.add_node(called)\n                add_edge_with_data(source_name, called)\n\n    # Add function nodes to graph and edges for function calls\n    for function_name in function_details_lookup:\n        G.add_node(function_name)\n    for func_name, details in function_details_lookup.items():\n        add_edges_for_calls(func_name, details['calls'])\n\n    # Add edges for method calls\n    for qualified_method_name, details in class_method_details_lookup.items():\n        add_edges_for_calls(qualified_method_name, details['calls'])\n\n    # Add edge data to edges and create node and edges to return\n    for edge in G.edges:\n        source, target = edge\n        target_details = function_details_lookup.get(target) or class_method_details_lookup.get(target)\n        source_details = function_details_lookup.get(source) or class_method_details_lookup.get(source)\n        edge_data = get_edge_data_from_details(target_details, source_details, target)\n        G[source][target].update(edge_data)\n    nodes = list(G.nodes)\n    edges = [{\"source\": edge[0], \"target\": edge[1], **edge[2]} for edge in G.edges.data()]\n    return {\"nodes\": nodes, \"edges\": edges}\n\n\ndef get_python_file_details(file_path: str) -> Dict[str, Union[Dict, str]]:\n    \"\"\"\n    Extract details from a Python file.\n    Args:\n        file_path: str: The path to the Python file.\n    Returns:\n        Dict[str, Union[Dict, str]]: The details extracted from the file.\n    \"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors='ignore') as f:\n            code = f.read()\n            tree = ast.parse(code)\n    except (PermissionError, SyntaxError) as e:\n        logging.warning(f\"{e} error in file: {file_path}\")\n        return None\n\n    visitor = CodeVisitor(code)\n    visitor.analyze(tree)\n    file_details = {'file_info': visitor.file_info, 'functions': visitor.functions, 'classes': visitor.classes}\n    file_details['file_info']['entire_code_graph'] = code_graph(file_details['file_info']['file_summary'])\n    file_details['file_info']['file_summary'] = json.dumps(file_details['file_info']['file_summary']).replace('\\\"','')\n    return file_details\n",
        "output": "{'nodes': ['CodeVisitor', 'CodeVisitor.__init__', 'CodeVisitor.visit_FunctionDef', 'CodeVisitor.visit_ClassDef', 'CodeVisitor.extract_details', 'CodeVisitor.analyze', 'remove_docs_and_comments', 'get_all_calls', 'code_graph', 'get_edge_data_from_details', 'add_edge_with_data', 'add_edges_for_calls', 'get_python_file_details', 'ast.parse', 'ast.walk', 'isinstance', 'ast.Constant', 'node.value.replace(\\'\"\"\"\\', \\'\\').replace', 'node.value.replace', 'astor.to_source(parsed).strip', 'astor.to_source', 'ast.iter_child_nodes', 'ast.unparse', 'calls.update', 'nx.DiGraph', 'function_details_lookup.update', 'class_def.items', 'G.add_node', \"class_details['method_defs'].items\", 'G.add_edge', 'target_details.get', 'list', 'set', 'class_method_details_lookup.get', 'function_details_lookup.get', 'class_def.keys', 'called.split', 'called.startswith', 'called.replace', 'source_name.split', 'function_details_lookup.items', 'class_method_details_lookup.items', 'G[source][target].update', 'G.edges.data', 'open', 'f.read', 'logging.warning', 'visitor.analyze', \"json.dumps(file_details['file_info']['file_summary']).replace\", 'json.dumps', 'self.generic_visit', 'ast.dump', 'next', 'call_data.keys', \"self.classes[self.current_class].setdefault('class_attributes', []).extend\", 'self.classes[self.current_class].setdefault', 'details.update', 'any', 'self.visit', 'self.functions.keys', 'self.classes.keys', 'self.functions.items', 'self.classes.items', 'class_details.items', 'method_name.startswith', 'len', 'class_defs.append'], 'edges': [{'source': 'CodeVisitor', 'target': 'CodeVisitor.__init__', 'target_inputs': ['self', 'code'], 'target_returns': []}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.visit_FunctionDef', 'target_inputs': ['self', 'node'], 'target_returns': []}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.visit_ClassDef', 'target_inputs': ['self', 'node'], 'target_returns': []}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.extract_details', 'target_inputs': ['self', 'node', 'node_type'], 'target_returns': ['details']}, {'source': 'CodeVisitor', 'target': 'CodeVisitor.analyze', 'target_inputs': ['self', 'node'], 'target_returns': []}, {'source': 'CodeVisitor.visit_FunctionDef', 'target': 'CodeVisitor.extract_details', 'target_inputs': ['self', 'node', 'node_type'], 'target_returns': ['details']}, {'source': 'CodeVisitor.visit_FunctionDef', 'target': 'self.generic_visit', 'target_inputs': ['node']}, {'source': 'CodeVisitor.visit_ClassDef', 'target': 'CodeVisitor.extract_details', 'target_inputs': ['self', 'node', 'node_type'], 'target_returns': ['details']}, {'source': 'CodeVisitor.visit_ClassDef', 'target': 'self.generic_visit', 'target_inputs': ['node']}, {'source': 'CodeVisitor.extract_details', 'target': 'list', 'target_inputs': ['{ast.unparse(subnode) for subnode in node_walk if isinstance(subnode, ast.Attribute) and isinstance(subnode.ctx, ast.Store)}']}, {'source': 'CodeVisitor.extract_details', 'target': 'ast.walk', 'target_inputs': ['node']}, {'source': 'CodeVisitor.extract_details', 'target': 'get_all_calls', 'target_inputs': ['node'], 'target_returns': ['calls']}, {'source': 'CodeVisitor.extract_details', 'target': 'ast.unparse', 'target_inputs': ['base']}, {'source': 'CodeVisitor.extract_details', 'target': 'ast.dump', 'target_inputs': ['node']}, {'source': 'CodeVisitor.extract_details', 'target': 'next', 'target_inputs': ['(n.value.s for n in node_walk if isinstance(n, ast.Expr) and isinstance(n.value, ast.Str))', 'None']}, {'source': 'CodeVisitor.extract_details', 'target': 'isinstance', 'target_inputs': ['decorator', 'ast.Name']}, {'source': 'CodeVisitor.extract_details', 'target': 'call_data.keys', 'target_inputs': []}, {'source': 'CodeVisitor.extract_details', 'target': 'set', 'target_inputs': []}, {'source': 'CodeVisitor.extract_details', 'target': \"self.classes[self.current_class].setdefault('class_attributes', []).extend\", 'target_inputs': ['attributes']}, {'source': 'CodeVisitor.extract_details', 'target': 'self.classes[self.current_class].setdefault', 'target_inputs': [\"'class_attributes'\", '[]']}, {'source': 'CodeVisitor.extract_details', 'target': 'details.update', 'target_inputs': [\"{'class_attributes': [target.attr for subnode in node.body if isinstance(subnode, ast.Assign) for target in subnode.targets if isinstance(target, ast.Attribute)], 'class_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != '__init__'], 'class_inheritance': [ast.unparse(base) for base in node.bases] if node.bases else [], 'class_static_methods': [subnode.name for subnode in node.body if isinstance(subnode, ast.FunctionDef) and subnode.name != '__init__' and any((isinstance(decorator, ast.Name) and decorator.id == 'staticmethod' for decorator in subnode.decorator_list))]}\"]}, {'source': 'CodeVisitor.extract_details', 'target': 'any', 'target_inputs': [\"(isinstance(decorator, ast.Name) and decorator.id == 'staticmethod' for decorator in subnode.decorator_list)\"]}, {'source': 'CodeVisitor.analyze', 'target': 'list', 'target_inputs': ['self.classes.keys()']}, {'source': 'CodeVisitor.analyze', 'target': 'ast.walk', 'target_inputs': ['node']}, {'source': 'CodeVisitor.analyze', 'target': 'self.visit', 'target_inputs': ['node']}, {'source': 'CodeVisitor.analyze', 'target': 'ast.dump', 'target_inputs': ['node']}, {'source': 'CodeVisitor.analyze', 'target': 'isinstance', 'target_inputs': ['subnode', 'ast.ImportFrom']}, {'source': 'CodeVisitor.analyze', 'target': 'self.functions.keys', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'self.classes.keys', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'self.functions.items', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'self.classes.items', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'class_details.items', 'target_inputs': []}, {'source': 'CodeVisitor.analyze', 'target': 'method_name.startswith', 'target_inputs': [\"'class_method_'\"]}, {'source': 'CodeVisitor.analyze', 'target': 'len', 'target_inputs': [\"'class_method_'\"]}, {'source': 'CodeVisitor.analyze', 'target': 'class_defs.append', 'target_inputs': [\"{class_name: {'method_defs': method_defs}}\"]}, {'source': 'CodeVisitor.analyze', 'target': 'remove_docs_and_comments', 'target_inputs': ['ast.unparse(node)'], 'target_returns': ['astor.to_source(parsed).strip()']}, {'source': 'CodeVisitor.analyze', 'target': 'ast.unparse', 'target_inputs': ['node']}, {'source': 'remove_docs_and_comments', 'target': 'ast.parse', 'target_inputs': ['code']}, {'source': 'remove_docs_and_comments', 'target': 'ast.walk', 'target_inputs': ['parsed']}, {'source': 'remove_docs_and_comments', 'target': 'isinstance', 'target_inputs': ['node.value', 'str']}, {'source': 'remove_docs_and_comments', 'target': 'ast.Constant', 'target_inputs': []}, {'source': 'remove_docs_and_comments', 'target': 'node.value.replace(\\'\"\"\"\\', \\'\\').replace', 'target_inputs': ['\"\\'\\'\\'\"', \"''\"]}, {'source': 'remove_docs_and_comments', 'target': 'node.value.replace', 'target_inputs': ['\\'\"\"\"\\'', \"''\"]}, {'source': 'remove_docs_and_comments', 'target': 'astor.to_source(parsed).strip', 'target_inputs': []}, {'source': 'remove_docs_and_comments', 'target': 'astor.to_source', 'target_inputs': ['parsed']}, {'source': 'get_all_calls', 'target': 'ast.iter_child_nodes', 'target_inputs': ['node']}, {'source': 'get_all_calls', 'target': 'isinstance', 'target_inputs': ['child', 'ast.Call']}, {'source': 'get_all_calls', 'target': 'ast.unparse', 'target_inputs': ['arg']}, {'source': 'get_all_calls', 'target': 'calls.update', 'target_inputs': ['get_all_calls(child)']}, {'source': 'get_all_calls', 'target': 'get_all_calls', 'target_inputs': ['child'], 'target_returns': ['calls']}, {'source': 'code_graph', 'target': 'nx.DiGraph', 'target_inputs': []}, {'source': 'code_graph', 'target': 'function_details_lookup.update', 'target_inputs': ['function_def']}, {'source': 'code_graph', 'target': 'class_def.items', 'target_inputs': []}, {'source': 'code_graph', 'target': 'G.add_node', 'target_inputs': ['function_name']}, {'source': 'code_graph', 'target': \"class_details['method_defs'].items\", 'target_inputs': []}, {'source': 'code_graph', 'target': 'G.add_edge', 'target_inputs': ['source', 'target']}, {'source': 'code_graph', 'target': 'target_details.get', 'target_inputs': [\"'returns'\", '[]']}, {'source': 'code_graph', 'target': 'list', 'target_inputs': ['G.nodes']}, {'source': 'code_graph', 'target': 'set', 'target_inputs': [\"target_details.get('returns', [])\"]}, {'source': 'code_graph', 'target': 'class_method_details_lookup.get', 'target_inputs': ['source']}, {'source': 'code_graph', 'target': 'function_details_lookup.get', 'target_inputs': ['source']}, {'source': 'code_graph', 'target': 'get_edge_data_from_details', 'target_inputs': ['target_details', 'source_details', 'target'], 'target_returns': ['edge_data']}, {'source': 'code_graph', 'target': 'class_def.keys', 'target_inputs': []}, {'source': 'code_graph', 'target': 'called.split', 'target_inputs': [\"'.'\"]}, {'source': 'code_graph', 'target': 'called.startswith', 'target_inputs': [\"'self.'\"]}, {'source': 'code_graph', 'target': 'called.replace', 'target_inputs': [\"'self.'\", \"''\"]}, {'source': 'code_graph', 'target': 'source_name.split', 'target_inputs': [\"'.'\"]}, {'source': 'code_graph', 'target': 'add_edge_with_data', 'target_inputs': ['source_name', 'called'], 'target_returns': []}, {'source': 'code_graph', 'target': 'function_details_lookup.items', 'target_inputs': []}, {'source': 'code_graph', 'target': 'add_edges_for_calls', 'target_inputs': ['qualified_method_name', \"details['calls']\"], 'target_returns': []}, {'source': 'code_graph', 'target': 'class_method_details_lookup.items', 'target_inputs': []}, {'source': 'code_graph', 'target': 'G[source][target].update', 'target_inputs': ['edge_data']}, {'source': 'code_graph', 'target': 'G.edges.data', 'target_inputs': []}, {'source': 'get_edge_data_from_details', 'target': 'target_details.get', 'target_inputs': [\"'returns'\", '[]']}, {'source': 'get_edge_data_from_details', 'target': 'list', 'target_inputs': [\"set(target_details.get('returns', []))\"]}, {'source': 'get_edge_data_from_details', 'target': 'set', 'target_inputs': [\"target_details.get('returns', [])\"]}, {'source': 'add_edge_with_data', 'target': 'class_method_details_lookup.get', 'target_inputs': ['source']}, {'source': 'add_edge_with_data', 'target': 'function_details_lookup.get', 'target_inputs': ['source']}, {'source': 'add_edge_with_data', 'target': 'G.add_edge', 'target_inputs': ['source', 'target']}, {'source': 'add_edge_with_data', 'target': 'get_edge_data_from_details', 'target_inputs': ['target_details', 'source_details', 'target'], 'target_returns': ['edge_data']}, {'source': 'add_edges_for_calls', 'target': 'list', 'target_inputs': ['class_def.keys()']}, {'source': 'add_edges_for_calls', 'target': 'class_def.keys', 'target_inputs': []}, {'source': 'add_edges_for_calls', 'target': 'called.split', 'target_inputs': [\"'.'\"]}, {'source': 'add_edges_for_calls', 'target': 'called.startswith', 'target_inputs': [\"'self.'\"]}, {'source': 'add_edges_for_calls', 'target': 'called.replace', 'target_inputs': [\"'self.'\", \"''\"]}, {'source': 'add_edges_for_calls', 'target': 'source_name.split', 'target_inputs': [\"'.'\"]}, {'source': 'add_edges_for_calls', 'target': 'add_edge_with_data', 'target_inputs': ['source_name', 'called'], 'target_returns': []}, {'source': 'add_edges_for_calls', 'target': 'G.add_node', 'target_inputs': ['called']}, {'source': 'get_python_file_details', 'target': 'open', 'target_inputs': ['file_path', \"'r'\"]}, {'source': 'get_python_file_details', 'target': 'f.read', 'target_inputs': []}, {'source': 'get_python_file_details', 'target': 'ast.parse', 'target_inputs': ['code']}, {'source': 'get_python_file_details', 'target': 'logging.warning', 'target_inputs': [\"f'{e} error in file: {file_path}'\"]}, {'source': 'get_python_file_details', 'target': 'CodeVisitor', 'target_inputs': ['code'], 'target_returns': []}, {'source': 'get_python_file_details', 'target': 'visitor.analyze', 'target_inputs': ['tree']}, {'source': 'get_python_file_details', 'target': 'code_graph', 'target_inputs': [\"file_details['file_info']['file_summary']\"], 'target_returns': [\"{'nodes': nodes, 'edges': edges}\", 'edge_data']}, {'source': 'get_python_file_details', 'target': \"json.dumps(file_details['file_info']['file_summary']).replace\", 'target_inputs': ['\\'\"\\'', \"''\"]}, {'source': 'get_python_file_details', 'target': 'json.dumps', 'target_inputs': [\"file_details['file_info']['file_summary']\"]}]}"
    },
    {
        "instruction": "Define the call code graph for this Python file:\n\"\"\"\nFor each Python file within given directory, generate, save, and return datasets\nthat include responses to questions about the code.\nRequirements:\n[req00] The process_single_file function shall:\n    a. Accept parameters for Python file path, start directory, model config \n    pathname, questions dict, use of LLM, and output dir.\n    b. If 'use_llm' is True, use 'get_model' to instantiate LLM model config.\n    c. Use 'get_python_file_details' to retrieve Python file info.\n    d. Use 'get_python_datasets' to acquire instruct.json datasets.\n    e. Use 'save_python_data' to store file details and instruct.json data.\n[req01] The py2dataset function shall:\n    a. Accept parameters for start directory, output dir, questions path, model\n    config path, use of LLM, and quiet mode.\n    b. Adjust logging level based on 'quiet'.\n    c. Use current working dir if no valid start dir is provided.\n    d. Get output dir with 'get_output_dir'.\n    e. Retrieve questions dict with 'get_questions'.\n    f. Search for Python files using 'rglob', excluding those starting with \"_\".\n    g. For each Python file, spawn a child process with 'process_single_file'\n    to get file details and instruct.json data, if single_process is False.\n    h. Combine instruct.json files with 'combine_json_files'.\n    i. Return datasets.\n[req02] The main function shall:\n    a. Accept and process command-line args.\n    b. Determine py2dataset parameters based on processed arguments.\n    c. Call py2dataset with derived parameters.\n\"\"\"\nimport os\nimport sys\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List\nfrom multiprocessing import Process\n\nfrom get_python_file_details import get_python_file_details\nfrom get_python_datasets import get_python_datasets\nfrom get_py2dataset_params import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output import combine_json_files, save_python_data\n\ndef process_single_file(pythonfile_path: str, start_dir: str, model_config_pathname: str,\n                        questions: Dict, use_llm: bool, output_dir: str,\n                        model_config: Dict = None, single_process: bool = False) -> None:\n    \"\"\"\n    Process a single Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path (str): Path to the Python file.\n        start_dir (str): Starting directory to search for Python files.\n        model_config_pathname (str): Path to the model configuration file.\n        questions (Dict): Questions dictionary to answer about the Python file.\n        use_llm (bool): If True, use a Large Language Model for generating JSON answers.\n        output_dir (str): Directory to write the output files.\n        model_config (Dict): Model configuration dictionary for the LLM.\n        single_process (bool, optional): Set True to use single process. Defaults to False.\n    Returns:\n        none\n    \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    if not single_process:\n        # Instantiate llm and prompt if use_llm is True for each file to avoid\n        # multiprocessing pickling problem\n        model_config = get_model(model_config_pathname) if use_llm else (None, '', 0)\n\n    # Use AST to get python file details\n    file_details = get_python_file_details(pythonfile_path)\n    if file_details is None or isinstance(file_details, tuple):\n        return\n\n    # Get lists for instruct.json for python file\n    instruct_list = get_python_datasets(\n        pythonfile_path,\n        file_details,\n        base_name,\n        questions,\n        model_config\n        )\n    if instruct_list is None:\n        return\n\n    save_python_data(file_details, instruct_list, relative_path, output_dir)\n\ndef py2dataset(start_dir: str = '', output_dir: str = '', questions_pathname: str = '',\n               model_config_pathname: str = '', use_llm: bool = False, quiet: bool = False,\n               single_process: bool = False) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process Python files to generate question-answer pairs and instructions.\n    Args:\n        start_dir (str, optional): Starting directory for Python files.\n        Defaults to current working directory.\n        output_dir (str, optional): Directory to write the output files.\n        questions_pathname (str, optional): Path to the questions file.\n        model_config_pathname (str, optional): Path to the model\n        configuration file.\n        use_llm (bool, optional): If True, use a Large Language Model\n        for generating JSON answers. Defaults to False.\n        quiet (bool, optional): Limit logging output. Defaults to False.\n        single_process(bool, optional): If True, only a single process \n        will be used to process Python files. Defaults to False. Set to True to\n        instantiate LLM once before processing all files.\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)  # Increase the recursion limit for AST\n\n    # If start dir is empty or not a valid directory, use current working directory\n    if not start_dir:\n        logging.info('No valid start path provided. Using current working directory.')\n        start_dir = os.getcwd()\n    start_dir = os.path.abspath(start_dir)\n    output_dir = get_output_dir(output_dir)\n    questions = get_questions(questions_pathname)\n\n    # If single_process is True, load model config here\n    if single_process:\n        model_config = get_model(model_config_pathname) if use_llm else (None, '', 0)\n\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n        if pythonfile_path.is_dir():\n            continue\n        if single_process:\n            process_single_file(\n                pythonfile_path,\n                start_dir,\n                model_config_pathname,\n                questions,\n                use_llm,\n                output_dir,\n                model_config,\n                single_process)\n            continue\n        # Spawn a new child process to manage python memory leaks\n        proc = Process(\n            target=process_single_file,\n            args=(\n                pythonfile_path,\n                start_dir,\n                model_config_pathname,\n                questions,\n                use_llm,\n                output_dir)\n            )\n        proc.start()\n        proc.join()\n\n    # Combine all of the instruct.json files together\n    datasets = combine_json_files(output_dir)\n    return datasets\n\ndef main():\n    \"\"\"\n    Command-line entry point for processing Python files and generating datasets.\n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname = ''\n    use_llm = False\n    quiet = False\n    single_process = False\n\n    if '--start_dir' in arg_string:\n        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n    if '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n        model_config_pathname = arg_string.split('--model_config_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}', '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--questions_pathname {questions_pathname}', '')\n    if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string = arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n        quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n    if '--single_process' in arg_string:\n        single_process = True\n        arg_string = arg_string.replace('--single_process', '')\n\n    py2dataset(\n        start_dir,\n        output_dir,\n        questions_pathname,\n        model_config_pathname,\n        use_llm,\n        quiet,\n        single_process)\n\nif __name__ == \"__main__\":\n    main()\n",
        "output": "{'nodes': ['process_single_file', 'py2dataset', 'main', 'logging.info', 'pythonfile_path.relative_to', \"'.'.join\", 'get_model', 'get_python_file_details', 'isinstance', 'get_python_datasets', 'save_python_data', 'logging.getLogger().setLevel', 'logging.getLogger', 'sys.setrecursionlimit', 'os.getcwd', 'os.path.abspath', 'get_output_dir', 'get_questions', 'Path(start_dir).rglob', 'Path', 'pythonfile_path.is_dir', 'Process', 'proc.start', 'proc.join', 'combine_json_files', \"' '.join\", \"arg_string.split('--start_dir ')[1].split\", 'arg_string.split', 'arg_string.replace', \"arg_string.split('--output_dir ')[1].split\", \"arg_string.split('--model_config_pathname ')[1].split\", \"arg_string.split('--questions_pathname ')[1].split\"], 'edges': [{'source': 'process_single_file', 'target': 'logging.info', 'target_inputs': [\"f'Processing: {pythonfile_path}'\"]}, {'source': 'process_single_file', 'target': 'pythonfile_path.relative_to', 'target_inputs': ['start_dir']}, {'source': 'process_single_file', 'target': \"'.'.join\", 'target_inputs': ['(part for part in relative_path.parts)']}, {'source': 'process_single_file', 'target': 'get_model', 'target_inputs': ['model_config_pathname']}, {'source': 'process_single_file', 'target': 'get_python_file_details', 'target_inputs': ['pythonfile_path']}, {'source': 'process_single_file', 'target': 'isinstance', 'target_inputs': ['file_details', 'tuple']}, {'source': 'process_single_file', 'target': 'get_python_datasets', 'target_inputs': ['pythonfile_path', 'file_details', 'base_name', 'questions', 'model_config']}, {'source': 'process_single_file', 'target': 'save_python_data', 'target_inputs': ['file_details', 'instruct_list', 'relative_path', 'output_dir']}, {'source': 'py2dataset', 'target': 'logging.getLogger().setLevel', 'target_inputs': ['logging.INFO']}, {'source': 'py2dataset', 'target': 'logging.getLogger', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'sys.setrecursionlimit', 'target_inputs': ['3000']}, {'source': 'py2dataset', 'target': 'logging.info', 'target_inputs': [\"'No valid start path provided. Using current working directory.'\"]}, {'source': 'py2dataset', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'os.path.abspath', 'target_inputs': ['start_dir']}, {'source': 'py2dataset', 'target': 'get_output_dir', 'target_inputs': ['output_dir']}, {'source': 'py2dataset', 'target': 'get_questions', 'target_inputs': ['questions_pathname']}, {'source': 'py2dataset', 'target': 'get_model', 'target_inputs': ['model_config_pathname']}, {'source': 'py2dataset', 'target': 'Path(start_dir).rglob', 'target_inputs': [\"'[!_]*.py'\"]}, {'source': 'py2dataset', 'target': 'Path', 'target_inputs': ['start_dir']}, {'source': 'py2dataset', 'target': 'pythonfile_path.is_dir', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'process_single_file', 'target_inputs': ['pythonfile_path', 'start_dir', 'model_config_pathname', 'questions', 'use_llm', 'output_dir', 'model_config', 'single_process'], 'target_returns': ['None']}, {'source': 'py2dataset', 'target': 'Process', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'proc.start', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'proc.join', 'target_inputs': []}, {'source': 'py2dataset', 'target': 'combine_json_files', 'target_inputs': ['output_dir']}, {'source': 'main', 'target': \"' '.join\", 'target_inputs': ['sys.argv[1:]']}, {'source': 'main', 'target': \"arg_string.split('--start_dir ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': 'arg_string.split', 'target_inputs': [\"'--questions_pathname '\"]}, {'source': 'main', 'target': 'arg_string.replace', 'target_inputs': [\"'--single_process'\", \"''\"]}, {'source': 'main', 'target': \"arg_string.split('--output_dir ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': \"arg_string.split('--model_config_pathname ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': \"arg_string.split('--questions_pathname ')[1].split\", 'target_inputs': [\"' '\"]}, {'source': 'main', 'target': 'py2dataset', 'target_inputs': ['start_dir', 'output_dir', 'questions_pathname', 'model_config_pathname', 'use_llm', 'quiet', 'single_process'], 'target_returns': ['datasets']}]}"
    },
    {
        "instruction": "Define the call code graph for this Python file:\n\"\"\"\nUtility functions for reading the input and saving the output of the py2dataset script.\nRequirements:\n[req01] The `read_file` function shall:\n        a. Accept a file path as an argument.\n        b. Read and return the contents of a JSON or YAML file as a dictionary.\n[req02] The `write_file` function shall:\n        a. Accept a dictionary and a file path as arguments.\n        b. Write the dictionary to a file in either JSON or YAML format.\n[req03] The `convert_json_to_html` function shall:\n        a. Convert JSON files within a given directory to HTML format.\n        b. Save each converted file with a .html extension.\n        c. Preserve spacing and tabs for the 'input' field.\n[req04] The `combine_json_files` function shall:\n        a. Accept a directory path as an argument.\n        b. Merge all JSON files in the directory.\n        c. Remove duplicates from the combined JSON files.\n        d. Write the combined data to 'instruct.json' files.\n        e. Convert the merged JSON files to HTML format.\n        f. Return the 'instruct_list' datasets.\n[req05] The `create_code_graph` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Generate code graphs based on the provided file details.\n        c. Save the graphs as PNG images in the specified output directory.\n[req06] The `save_python_data` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Save the details of the Python file as a YAML file.\n        c. Save the instruction data as JSON files.\n        d. Generate and save code graphs.\n\"\"\"\nimport json\nimport logging\nfrom html import escape\nfrom pathlib import Path\nfrom typing import Dict, List\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport yaml\n\ndef read_file(file_path: Path) -> Dict:\n    \"\"\"\n    Reads a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n    Returns:\n        The contents of the file as a dictionary.\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open() as f:\n        if file_type == 'json':\n            return json.load(f)\n        if file_type == 'yaml':\n            return yaml.load(f, Loader=yaml.SafeLoader)\n        return {}\n\ndef write_file(data: Dict, file_path: Path) -> None:\n    \"\"\"\n    Writes a dictionary to a JSON or YAML file. \n    Args:\n        data (Dict): The data to write to the file.\n        file_path (Path): The path to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open('w') as f:\n        if file_type == 'json':\n            json.dump(data, f, indent=4)\n        elif file_type == 'yaml':\n            yaml.SafeDumper.ignore_aliases = lambda *args: True\n            yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)\n\n\ndef convert_json_to_html(directory: str) -> None:\n    \"\"\"\n    Convert JSON files within a given directory to HTML format.\n    Args:\n        directory (str): The directory where the JSON files are located.\n    Returns:\n        None    \n    \"\"\"\n    def preserve_spacing(text: str, tab_width: int = 4) -> str:\n        \"\"\"Preserve spaces and tabs in the provided text.\"\"\"\n        return text.replace(\" \", \"&nbsp;\").replace(\"\\t\", \"&nbsp;\" * tab_width)\n\n    for json_file in Path(directory).rglob('*.json'):\n        dataset = read_file(json_file)\n        if not dataset:\n            continue\n\n        html_content = \"\"\"\n        <html>\n        <head>\n            <style>\n                table {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th, td {\n                    border: 1px solid black;\n                    padding: 8px;\n                    text-align: left;\n                    white-space: pre-line;\n                    vertical-align: top;\n                    word-wrap: break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        \"\"\"\n        column_count = len(dataset[0].keys())\n        column_width = 100 / column_count  # Calculate the width for each column based on the number of columns\n        for key in dataset[0].keys():\n            html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\n        html_content += \"\"\"\n                    </tr>\n                </thead>\n                <tbody>\n        \"\"\"\n        for entry in dataset:\n            html_content += \"<tr>\"\n            for key in entry:\n                # Convert \\n to HTML line breaks\n                value = escape(str(entry[key]))\n                value = preserve_spacing(value)\n                value = value.replace('\\n', '<br/>')\n                html_content += f\"<td>{value}</td>\"\n            html_content += \"</tr>\"\n\n        html_content += \"\"\"\n                </tbody>\n            </table>\n        </body>\n        </html>\n        \"\"\"\n        html_file_path = json_file.with_suffix('.html')\n        try:\n            with open(html_file_path, 'w', encoding='utf-8') as file:\n                file.write(html_content)\n        except Exception:\n            logging.info(f'Failed saving: {html_file_path}')\n\n\ndef combine_json_files(directory: str) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Combine all JSON files in the output directory into 'instruct.json', and \n    then remove duplicates.\n    Args:\n        directory (str): The directory where the output files are located.\n    Returns:\n        A dictionary containing the 'instruct_list' datasets.\n    \"\"\"\n\n    def remove_duplicate_dataset_entries(dataset: List[Dict], key1: str, key2: str) -> List[Dict]:\n        \"\"\"\n        Remove duplicate entries from the provided dataset based on the provided keys.\n        Args:\n            dataset (List[Dict]): The dataset to remove duplicates from.\n            key1 (str): The first key to check for duplicates.\n            key2 (str): The second key to check for duplicates.\n        Returns:\n            A dataset without duplicate entries.\n        \"\"\"\n        seen = set()\n        result = []\n        for item in dataset:\n            if (item[key1], item[key2]) not in seen:\n                seen.add((item[key1], item[key2]))\n                result.append(item)\n        return result\n\n    instruct_data = []\n    for file_name in ['instruct.json']:\n        file_path = Path(directory) / file_name\n        combined_data = []\n        for json_file in Path(directory).rglob(f'*.{file_name}'):\n            json_file_data = read_file(json_file)\n            combined_data.extend(json_file_data)\n            combined_data = remove_duplicate_dataset_entries(combined_data, 'instruction', 'output')\n            instruct_data = combined_data.copy()\n            # gen training datasets that contains purpose and graph data formatted for each item:\n            purpose_data = [item for item in combined_data if item['instruction'].startswith('1) DESCRIBE the purpose')]\n            graph_data = [item for item in combined_data if item['instruction'].startswith('Call code graph')]\n            code_output = []\n            graph_output = []\n            for item in purpose_data:\n                instruction = 'Define a Python code file that is described as follows:\\n'+ item['output']\n                code_output.append({'instruction': instruction, 'output': item['input']})\n            for item in graph_data:\n                instruction = 'Define the call code graph for this Python file:\\n' + item['input']\n                graph_output.append({'instruction': instruction, 'output': item['output']})\n            code_graph_output = code_output + graph_output\n            write_file(code_graph_output, Path(directory) / 'training.json')\n\n        write_file(combined_data, file_path)\n\n    # Save html file for each json file in the output directory\n    convert_json_to_html(directory)\n    return {'instruct_list': instruct_data}\n\n\ndef create_code_graph(file_details: Dict, base_name: str, output_subdir: Path) -> None:\n    \"\"\"\n    Generate graphs from the file_details and save them as PNG images.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        base_name (str): The base name of the output files.\n        output_subdir (Path): The subdirectory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    graph_type = 'entire_code_graph'\n    output_file = output_subdir / f'{base_name}.{graph_type}.png'\n\n    # Create graphs, add nodes, and add edges\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n    for edge in file_details['file_info'][graph_type]['edges']:\n        source, target = edge['source'], edge['target']\n        if source in G.nodes and target in G.nodes:\n            G.add_edge(source, target, **{k: v for k, v in edge.items() if k in ['target_inputs', 'target_returns']})\n    # Draw graphs\n    plt.figure(figsize=(20, 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True, font_weight='bold', font_size = 8, node_shape='s', node_size=500, width=1, arrowsize=12)\n    edge_labels = {}\n    for edge in G.edges(data=True):\n        label = []\n        if 'target_inputs' in edge[2] and edge[2]['target_inputs']:\n            label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\")\n        if 'target_returns' in edge[2] and edge[2]['target_returns']:\n            label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\")\n        edge_labels[(edge[0], edge[1])] = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n    plt.savefig(output_file) # Save the figure\n    plt.close()  # Close the figure\n\n\ndef save_python_data(file_details: dict, instruct_list: list, relative_path: Path, output_dir: str) -> None:\n    \"\"\"\n    Save Python file details as a YAML file, the instruction data as a JSON file, and code graphs.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        instruct_list (list): The instruction data extracted from the Python file.\n        relative_path (Path): The relative path to the Python file.\n        output_dir (str): The directory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir = Path(output_dir) / relative_path.parts[0]\n    output_subdir.mkdir(parents=True, exist_ok=True)\n    base_name = '.'.join(part for part in relative_path.parts)\n\n    # write instrunct.json files\n    file_names = [f'{base_name}.instruct.json', f'{base_name}.details.yaml']\n    contents = [instruct_list, file_details]\n\n    for file_name, content in zip(file_names, contents):\n        write_file(content, output_subdir / file_name)\n\n    try:\n        create_code_graph(file_details, base_name, output_subdir)\n    except Exception as e:\n        logging.info(f'Error creating graph for {base_name}: {e}')\n",
        "output": "{'nodes': ['read_file', 'write_file', 'convert_json_to_html', 'preserve_spacing', 'combine_json_files', 'remove_duplicate_dataset_entries', 'create_code_graph', 'save_python_data', 'file_path.open', 'json.load', 'yaml.load', 'json.dump', 'yaml.dump', \"text.replace(' ', '&nbsp;').replace\", 'text.replace', 'Path(directory).rglob', 'Path', 'len', 'dataset[0].keys', 'escape', 'str', 'value.replace', 'json_file.with_suffix', 'open', 'file.write', 'logging.info', 'set', 'seen.add', 'result.append', 'combined_data.extend', 'combined_data.copy', \"item['instruction'].startswith\", 'code_output.append', 'graph_output.append', 'nx.DiGraph', 'G.add_nodes_from', 'G.add_edge', 'edge.items', 'plt.figure', 'nx.spring_layout', 'nx.draw', 'G.edges', 'label.append', \"', '.join\", \"'\\\\n'.join\", 'nx.draw_networkx_edge_labels', 'plt.savefig', 'plt.close', 'output_subdir.mkdir', \"'.'.join\", 'zip'], 'edges': [{'source': 'read_file', 'target': 'file_path.open', 'target_inputs': []}, {'source': 'read_file', 'target': 'json.load', 'target_inputs': ['f']}, {'source': 'read_file', 'target': 'yaml.load', 'target_inputs': ['f']}, {'source': 'write_file', 'target': 'file_path.open', 'target_inputs': [\"'w'\"]}, {'source': 'write_file', 'target': 'json.dump', 'target_inputs': ['data', 'f']}, {'source': 'write_file', 'target': 'yaml.dump', 'target_inputs': ['data', 'f']}, {'source': 'convert_json_to_html', 'target': \"text.replace(' ', '&nbsp;').replace\", 'target_inputs': [\"'\\\\t'\", \"'&nbsp;' * tab_width\"]}, {'source': 'convert_json_to_html', 'target': 'text.replace', 'target_inputs': [\"' '\", \"'&nbsp;'\"]}, {'source': 'convert_json_to_html', 'target': 'Path(directory).rglob', 'target_inputs': [\"'*.json'\"]}, {'source': 'convert_json_to_html', 'target': 'Path', 'target_inputs': ['directory']}, {'source': 'convert_json_to_html', 'target': 'read_file', 'target_inputs': ['json_file'], 'target_returns': ['yaml.load(f, Loader=yaml.SafeLoader)', 'json.load(f)', '{}']}, {'source': 'convert_json_to_html', 'target': 'len', 'target_inputs': ['dataset[0].keys()']}, {'source': 'convert_json_to_html', 'target': 'dataset[0].keys', 'target_inputs': []}, {'source': 'convert_json_to_html', 'target': 'escape', 'target_inputs': ['str(entry[key])']}, {'source': 'convert_json_to_html', 'target': 'str', 'target_inputs': ['entry[key]']}, {'source': 'convert_json_to_html', 'target': 'preserve_spacing', 'target_inputs': ['value'], 'target_returns': [\"text.replace(' ', '&nbsp;').replace('\\\\t', '&nbsp;' * tab_width)\"]}, {'source': 'convert_json_to_html', 'target': 'value.replace', 'target_inputs': [\"'\\\\n'\", \"'<br/>'\"]}, {'source': 'convert_json_to_html', 'target': 'json_file.with_suffix', 'target_inputs': [\"'.html'\"]}, {'source': 'convert_json_to_html', 'target': 'open', 'target_inputs': ['html_file_path', \"'w'\"]}, {'source': 'convert_json_to_html', 'target': 'file.write', 'target_inputs': ['html_content']}, {'source': 'convert_json_to_html', 'target': 'logging.info', 'target_inputs': [\"f'Failed saving: {html_file_path}'\"]}, {'source': 'preserve_spacing', 'target': \"text.replace(' ', '&nbsp;').replace\", 'target_inputs': [\"'\\\\t'\", \"'&nbsp;' * tab_width\"]}, {'source': 'preserve_spacing', 'target': 'text.replace', 'target_inputs': [\"' '\", \"'&nbsp;'\"]}, {'source': 'combine_json_files', 'target': 'set', 'target_inputs': []}, {'source': 'combine_json_files', 'target': 'seen.add', 'target_inputs': ['(item[key1], item[key2])']}, {'source': 'combine_json_files', 'target': 'result.append', 'target_inputs': ['item']}, {'source': 'combine_json_files', 'target': 'Path', 'target_inputs': ['directory']}, {'source': 'combine_json_files', 'target': 'Path(directory).rglob', 'target_inputs': [\"f'*.{file_name}'\"]}, {'source': 'combine_json_files', 'target': 'read_file', 'target_inputs': ['json_file'], 'target_returns': ['yaml.load(f, Loader=yaml.SafeLoader)', 'json.load(f)', '{}']}, {'source': 'combine_json_files', 'target': 'combined_data.extend', 'target_inputs': ['json_file_data']}, {'source': 'combine_json_files', 'target': 'remove_duplicate_dataset_entries', 'target_inputs': ['combined_data', \"'instruction'\", \"'output'\"], 'target_returns': ['result']}, {'source': 'combine_json_files', 'target': 'combined_data.copy', 'target_inputs': []}, {'source': 'combine_json_files', 'target': \"item['instruction'].startswith\", 'target_inputs': [\"'Call code graph'\"]}, {'source': 'combine_json_files', 'target': 'code_output.append', 'target_inputs': [\"{'instruction': instruction, 'output': item['input']}\"]}, {'source': 'combine_json_files', 'target': 'graph_output.append', 'target_inputs': [\"{'instruction': instruction, 'output': item['output']}\"]}, {'source': 'combine_json_files', 'target': 'write_file', 'target_inputs': ['combined_data', 'file_path'], 'target_returns': []}, {'source': 'combine_json_files', 'target': 'convert_json_to_html', 'target_inputs': ['directory'], 'target_returns': [\"text.replace(' ', '&nbsp;').replace('\\\\t', '&nbsp;' * tab_width)\"]}, {'source': 'remove_duplicate_dataset_entries', 'target': 'set', 'target_inputs': []}, {'source': 'remove_duplicate_dataset_entries', 'target': 'seen.add', 'target_inputs': ['(item[key1], item[key2])']}, {'source': 'remove_duplicate_dataset_entries', 'target': 'result.append', 'target_inputs': ['item']}, {'source': 'create_code_graph', 'target': 'nx.DiGraph', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'G.add_nodes_from', 'target_inputs': [\"file_details['file_info'][graph_type]['nodes']\"]}, {'source': 'create_code_graph', 'target': 'G.add_edge', 'target_inputs': ['source', 'target']}, {'source': 'create_code_graph', 'target': 'edge.items', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'plt.figure', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'nx.spring_layout', 'target_inputs': ['G']}, {'source': 'create_code_graph', 'target': 'nx.draw', 'target_inputs': ['G', 'pos']}, {'source': 'create_code_graph', 'target': 'G.edges', 'target_inputs': []}, {'source': 'create_code_graph', 'target': 'label.append', 'target_inputs': ['f\"\\\\nReturns: {\\', \\'.join(edge[2][\\'target_returns\\'])}\"']}, {'source': 'create_code_graph', 'target': \"', '.join\", 'target_inputs': [\"edge[2]['target_returns']\"]}, {'source': 'create_code_graph', 'target': \"'\\\\n'.join\", 'target_inputs': ['label']}, {'source': 'create_code_graph', 'target': 'nx.draw_networkx_edge_labels', 'target_inputs': ['G', 'pos']}, {'source': 'create_code_graph', 'target': 'plt.savefig', 'target_inputs': ['output_file']}, {'source': 'create_code_graph', 'target': 'plt.close', 'target_inputs': []}, {'source': 'save_python_data', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'save_python_data', 'target': 'output_subdir.mkdir', 'target_inputs': []}, {'source': 'save_python_data', 'target': \"'.'.join\", 'target_inputs': ['(part for part in relative_path.parts)']}, {'source': 'save_python_data', 'target': 'zip', 'target_inputs': ['file_names', 'contents']}, {'source': 'save_python_data', 'target': 'write_file', 'target_inputs': ['content', 'output_subdir / file_name'], 'target_returns': []}, {'source': 'save_python_data', 'target': 'create_code_graph', 'target_inputs': ['file_details', 'base_name', 'output_subdir'], 'target_returns': []}, {'source': 'save_python_data', 'target': 'logging.info', 'target_inputs': [\"f'Error creating graph for {base_name}: {e}'\"]}]}"
    },
    {
        "instruction": "Define the call code graph for this Python file:\nfrom setuptools import setup\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"py2dataset\",\n    version=\"0.1\",\n    author=\"Jeff Meloy\",\n    author_email=\"jeffmeloy@gmail.com\",\n    description=\"A tool to generate structured datasets from Python source code\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/jeffmeloy/py2dataset\",\n    py_modules=[\"py2dataset\", \"get_python_file_details\", \"get_python_json\"],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires='>=3.8',\n    install_requires=[\n        \"matplotlib\",\n        \"networkx\",\n        \"ctransformers\",\n        \"pyyaml\"\n    ],\n    entry_points={'console_scripts': ['py2dataset = py2dataset:main']},\n    packages=['py2dataset'],\n    package_dir={'py2dataset': '.\\\\'},\n)",
        "output": "{'nodes': [], 'edges': []}"
    }
]