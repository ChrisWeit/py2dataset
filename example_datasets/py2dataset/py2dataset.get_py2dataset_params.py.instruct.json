[
    {
        "instruction": "Dependencies of Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returned items from function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible\n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 14000,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "os, importlib, typing, json, pathlib, logging, yaml"
    },
    {
        "instruction": "Call code graph of Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returned items from function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible\n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 14000,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "{'nodes': ['get_default_questions', 'get_default_model_config', 'get_output_dir', 'get_questions', 'instantiate_model', 'get_model', 'write_questions_file', 'write_model_config_file', 'os.path.abspath', 'os.makedirs', 'logging.info', 'os.path.join', 'os.getcwd', 'open', 'json.load', \"model_config['model_import_path'].rsplit\", 'getattr', 'importlib.import_module', 'inference_function', 'model_params.pop', 'ModelClass', 'yaml.safe_load', 'Path(output_dir).is_dir', 'Path', 'json.dump', 'yaml.dump'], 'edges': [{'source': 'get_output_dir', 'target': 'os.path.abspath', 'target_inputs': ['output_dir or OUTPUT_DIR']}, {'source': 'get_output_dir', 'target': 'os.makedirs', 'target_inputs': ['output_dir']}, {'source': 'get_output_dir', 'target': 'logging.info', 'target_inputs': [\"f'Using output directory: {output_dir}'\"]}, {'source': 'get_questions', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'QUESTIONS_FILE']}, {'source': 'get_questions', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_questions', 'target': 'open', 'target_inputs': ['questions_pathname', \"'r'\"]}, {'source': 'get_questions', 'target': 'json.load', 'target_inputs': ['f']}, {'source': 'get_questions', 'target': 'logging.info', 'target_inputs': [\"f'Questions file not valid: {questions_pathname} Using default questions'\"]}, {'source': 'get_questions', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'instantiate_model', 'target': \"model_config['model_import_path'].rsplit\", 'target_inputs': [\"'.'\", '1']}, {'source': 'instantiate_model', 'target': 'getattr', 'target_inputs': ['ModelClass', 'inference_function_name']}, {'source': 'instantiate_model', 'target': 'importlib.import_module', 'target_inputs': ['module_name']}, {'source': 'instantiate_model', 'target': 'inference_function', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'model_params.pop', 'target_inputs': [\"'model_path'\"]}, {'source': 'instantiate_model', 'target': 'ModelClass', 'target_inputs': [\"model_params.pop('model_path')\"]}, {'source': 'instantiate_model', 'target': 'logging.info', 'target_inputs': [\"f'Failed to instantiate the model. Error: {e}'\"]}, {'source': 'get_model', 'target': 'os.path.join', 'target_inputs': ['os.getcwd()', 'MODEL_CONFIG_FILE']}, {'source': 'get_model', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'get_model', 'target': 'open', 'target_inputs': ['model_config_pathname', \"'r'\"]}, {'source': 'get_model', 'target': 'yaml.safe_load', 'target_inputs': ['config_file']}, {'source': 'get_model', 'target': 'logging.info', 'target_inputs': [\"f'Model config file not valid: {model_config_pathname} Using default model config'\"]}, {'source': 'get_model', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'get_model', 'target': 'instantiate_model', 'target_inputs': [\"model_config['inference_model']\"], 'target_returns': ['model', 'None']}, {'source': 'write_questions_file', 'target': 'get_default_questions', 'target_inputs': [], 'target_returns': ['questions']}, {'source': 'write_questions_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_questions_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_questions_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, QUESTIONS_FILE)', \"'w'\"]}, {'source': 'write_questions_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'QUESTIONS_FILE']}, {'source': 'write_questions_file', 'target': 'json.dump', 'target_inputs': ['questions', 'file']}, {'source': 'write_model_config_file', 'target': 'get_default_model_config', 'target_inputs': [], 'target_returns': ['model_config']}, {'source': 'write_model_config_file', 'target': 'Path(output_dir).is_dir', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'Path', 'target_inputs': ['output_dir']}, {'source': 'write_model_config_file', 'target': 'os.getcwd', 'target_inputs': []}, {'source': 'write_model_config_file', 'target': 'open', 'target_inputs': ['os.path.join(output_dir, MODEL_CONFIG_FILE)', \"'w'\"]}, {'source': 'write_model_config_file', 'target': 'os.path.join', 'target_inputs': ['output_dir', 'MODEL_CONFIG_FILE']}, {'source': 'write_model_config_file', 'target': 'yaml.dump', 'target_inputs': ['model_config', 'file']}]}"
    },
    {
        "instruction": "Functions defined in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returned items from function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible\n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 14000,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "get_questions, get_model, write_model_config_file, get_output_dir, write_questions_file, get_default_questions, get_default_model_config, instantiate_model"
    },
    {
        "instruction": "Inputs to function: `get_output_dir` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "output_dir"
    },
    {
        "instruction": "Inputs to function: `get_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "questions_pathname"
    },
    {
        "instruction": "Inputs to function: `instantiate_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "model_config"
    },
    {
        "instruction": "Inputs to function: `get_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config",
        "output": "model_config_pathname"
    },
    {
        "instruction": "Inputs to function: `write_questions_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "output_dir"
    },
    {
        "instruction": "Inputs to function: `write_model_config_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "output_dir"
    },
    {
        "instruction": "Docstring of function: `get_default_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies', 'text': \"Dependencies of Python file: '{filename}'?\", 'type': 'file'}, {'id': 'entire_code_graph', 'text': \"Call code graph of Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_functions', 'text': \"Functions defined in Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_classes', 'text': \"Classes defined in Python file: '{filename}'?\", 'type': 'file'}, {'id': 'function_inputs', 'text': \"Inputs to function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_docstring', 'text': \"Docstring of function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_calls', 'text': \"Calls made in function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_variables', 'text': \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_returns', 'text': \"Returned items from function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'class_methods', 'text': \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_docstring', 'text': \"Docstring of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_attributes', 'text': \"Attributes of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_variables', 'text': \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_inheritance', 'text': \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'method_inputs', 'text': \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_docstring', 'text': \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_calls', 'text': \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_returns', 'text': \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'file_purpose', 'text': \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\", 'type': 'file'}]\n    return questions",
        "output": "Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list"
    },
    {
        "instruction": "Docstring of function: `get_default_model_config` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {'prompt_template': \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\", 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF', 'model_type': 'llama', 'local_files_only': False, 'threads': 28, 'batch_size': 128, 'context_length': 14000, 'max_new_tokens': 8092, 'gpu_layers': 100, 'reset': True}}}\n    return model_config",
        "output": "Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary"
    },
    {
        "instruction": "Docstring of function: `get_output_dir` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created."
    },
    {
        "instruction": "Docstring of function: `get_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions"
    },
    {
        "instruction": "Docstring of function: `instantiate_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error."
    },
    {
        "instruction": "Docstring of function: `get_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config",
        "output": "Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template"
    },
    {
        "instruction": "Docstring of function: `write_questions_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None"
    },
    {
        "instruction": "Docstring of function: `write_model_config_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None"
    },
    {
        "instruction": "Calls made in function: `get_output_dir` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "os.makedirs, logging.info, os.path.abspath"
    },
    {
        "instruction": "Calls made in function: `get_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "logging.info, get_default_questions, open, json.load, os.path.join, os.getcwd"
    },
    {
        "instruction": "Calls made in function: `instantiate_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "model_params.pop, model_configmodel_import_path.rsplit, logging.info, ModelClass, getattr, inference_function, importlib.import_module"
    },
    {
        "instruction": "Calls made in function: `get_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config",
        "output": "logging.info, get_default_model_config, open, yaml.safe_load, instantiate_model, os.path.join, os.getcwd"
    },
    {
        "instruction": "Calls made in function: `write_questions_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "Path, get_default_questions, json.dump, open, Pathoutput_dir.is_dir, os.path.join, os.getcwd"
    },
    {
        "instruction": "Calls made in function: `write_model_config_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "Path, get_default_model_config, yaml.dump, open, Pathoutput_dir.is_dir, os.path.join, os.getcwd"
    },
    {
        "instruction": "Variables defined in function: `get_default_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies', 'text': \"Dependencies of Python file: '{filename}'?\", 'type': 'file'}, {'id': 'entire_code_graph', 'text': \"Call code graph of Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_functions', 'text': \"Functions defined in Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_classes', 'text': \"Classes defined in Python file: '{filename}'?\", 'type': 'file'}, {'id': 'function_inputs', 'text': \"Inputs to function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_docstring', 'text': \"Docstring of function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_calls', 'text': \"Calls made in function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_variables', 'text': \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_returns', 'text': \"Returned items from function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'class_methods', 'text': \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_docstring', 'text': \"Docstring of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_attributes', 'text': \"Attributes of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_variables', 'text': \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_inheritance', 'text': \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'method_inputs', 'text': \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_docstring', 'text': \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_calls', 'text': \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_returns', 'text': \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'file_purpose', 'text': \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\", 'type': 'file'}]\n    return questions",
        "output": "questions"
    },
    {
        "instruction": "Variables defined in function: `get_default_model_config` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {'prompt_template': \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\", 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF', 'model_type': 'llama', 'local_files_only': False, 'threads': 28, 'batch_size': 128, 'context_length': 14000, 'max_new_tokens': 8092, 'gpu_layers': 100, 'reset': True}}}\n    return model_config",
        "output": "model_config"
    },
    {
        "instruction": "Variables defined in function: `get_output_dir` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "output_dir"
    },
    {
        "instruction": "Variables defined in function: `get_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "questions, questions_pathname"
    },
    {
        "instruction": "Variables defined in function: `instantiate_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "model, inference_function_name, ModelClass, model_params, inference_function"
    },
    {
        "instruction": "Variables defined in function: `get_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config",
        "output": "model_config, model_config_pathname"
    },
    {
        "instruction": "Variables defined in function: `write_questions_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)",
        "output": "questions, output_dir"
    },
    {
        "instruction": "Variables defined in function: `write_model_config_file` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)",
        "output": "model_config, output_dir"
    },
    {
        "instruction": "Returned items from function: `get_default_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies', 'text': \"Dependencies of Python file: '{filename}'?\", 'type': 'file'}, {'id': 'entire_code_graph', 'text': \"Call code graph of Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_functions', 'text': \"Functions defined in Python file: '{filename}'?\", 'type': 'file'}, {'id': 'file_classes', 'text': \"Classes defined in Python file: '{filename}'?\", 'type': 'file'}, {'id': 'function_inputs', 'text': \"Inputs to function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_docstring', 'text': \"Docstring of function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_calls', 'text': \"Calls made in function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_variables', 'text': \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'function_returns', 'text': \"Returned items from function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id': 'class_methods', 'text': \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_docstring', 'text': \"Docstring of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_attributes', 'text': \"Attributes of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_variables', 'text': \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_inheritance', 'text': \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'method_inputs', 'text': \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_docstring', 'text': \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_calls', 'text': \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'method_returns', 'text': \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\", 'type': 'method'}, {'id': 'file_purpose', 'text': \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\", 'type': 'file'}]\n    return questions",
        "output": "questions"
    },
    {
        "instruction": "Returned items from function: `get_default_model_config` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {'prompt_template': \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\", 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF', 'model_type': 'llama', 'local_files_only': False, 'threads': 28, 'batch_size': 128, 'context_length': 14000, 'max_new_tokens': 8092, 'gpu_layers': 100, 'reset': True}}}\n    return model_config",
        "output": "model_config"
    },
    {
        "instruction": "Returned items from function: `get_output_dir` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir",
        "output": "output_dir"
    },
    {
        "instruction": "Returned items from function: `get_questions` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions",
        "output": "questions"
    },
    {
        "instruction": "Returned items from function: `instantiate_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None",
        "output": "model, None"
    },
    {
        "instruction": "Returned items from function: `get_model` in Python file: `py2dataset.get_py2dataset_params.py`?",
        "input": "def get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config",
        "output": "model_config"
    },
    {
        "instruction": "1) DESCRIBE the purpose and processing summary of Python file: `py2dataset.get_py2dataset_params.py`; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.",
        "input": "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes defined in Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returned items from function: '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"function\"\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_variables\",\n            \"text\": \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"1) DESCRIBE the purpose and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description of each applicable function, class, and method; 3) EXPLAIN what each input, output, and variable does in the code.\",\n            \"type\": \"file\"\n        }\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze this code you created provide a comprehensive response without duplicating the input code, include enough detail for me to implement the same logic, and include your reasoning step by step: {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\": \"llama\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)\n                #avx2 and gpu_layers are not compatible\n                #\"lib\": \"avx2\",\n                \"threads\": 28,\n                \"batch_size\": 128,\n                \"context_length\": 14000,\n                \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n                \"reset\": True\n                }\n            }\n        }\n    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try: # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'), **model_params)\n        return model\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config\n\n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n",
        "output": "The purpose of this Python file is to obtain parameters needed by the py2dataset application for creating a dataset. These parameters include: a list of questions that define what types of data py2dataset can generate based on user-provided prompts, a model configuration dictionary specifying the type and settings of the language model used for inference, an output directory for writing generated datasets, and paths to files containing customized questions or model configurations. The file also includes functions for obtaining these parameters from various sources (default values, provided files, or arguments passed in) and instantiating the desired language model with its appropriate parameters based on those inputs. It can write default or customized prompt templates, questions, and model configurations to JSON or YAML format files if needed. \n\nFunctions:\n- `get_default_questions()` returns a list of default questions that py2dataset can generate data for. Each question is represented as a dictionary with an ID, text, and type (file, function, class, etc.).\n- `get_default_model_config()` returns the default model configuration in YAML format, which includes the prompt template and the settings used to instantiate a language model from ctransformers library.\n- `get_output_dir(output_dir='')` takes an optional output directory argument and returns its absolute path if it exists or can be created. If no valid output directory is provided, it uses the default OUTPUT_DIR variable defined in the file.\n- `get_questions(questions_pathname)` gets questions from a specified file or falls back to default settings when it is invalid (no valid question files exist or fail to parse as JSON) \n- `instantiate_model(model_config: dict) -> object` imports and instantiates the desired language model based on the provided configuration.\n- `get_model(model_config_pathname)` gets a model from a specified file or falls back to default settings when it is invalid (no valid config files exist or fail to parse as YAML). It also returns an appropriate prompt template for that model based on its settings in the dictionary. \n- `write_questions_file(output_dir='')` writes default questions to the QUESTIONS_FILE if no valid output directory is provided. This function calls get_default_questions(). \n- `write_model_config_file(output_dir='')` writes a YAML file containing the default model configuration (the template prompt and any model settings).\n\nInputs: \n1) filename for all functions except `get_model` - this is the path to the Python file being analyzed. \n2) function_name for `function_inputs`, `method_inputs`, and `class_methods`. \n3) class_name for `class_inheritance`, `class_attributes`, `method_returns`, and `file_functions` - the name of a class in the file. \n4) model_config_pathname for `get_model` - path to the YAML configuration file for the desired language model.\n5) questions_pathname for `get_questions` - path to a JSON file containing customized questions.\n6) output_dir for all functions that write files - where to save generated data or configuration files. \n\nOutputs: \n1) A list of dictionaries representing the questions py2dataset can generate data for, with each dictionary having an ID, text, and type (file, function, class). \n2) A dictionary containing a prompt template and model settings. \n3) An instance of a language model from the ctransformers library instantiated according to the specified parameters.\n4) Two JSON or YAML files in the desired output directory. One is the `QUESTIONS_FILE` file, which contains default questions (or customized questions if provided), and the other is the `MODEL_CONFIG_FILE`, containing the default prompt template and any model settings that can be adjusted by the user. \n\"\"\"\nQ: In `instantiate_model(model_config)`, what happens if the specified module or class cannot be imported? \nA: The function returns None, indicating an error in importing the module or class. This is logged to the console and handled later on when attempting to use the model instance."
    }
]