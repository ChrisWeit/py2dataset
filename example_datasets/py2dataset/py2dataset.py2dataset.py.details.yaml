file_info:
  file_code: "\"\"\"\nFor each Python file within given directory, generate, save,\
    \ and return datasets that include responses to questions about the code.\nRequirements:\n\
    [req00] The process_single_file function shall:\n    a. Accept parameters for\
    \ the Python file path, starting directory, model configuration pathname, questions\
    \ dictionary, use of LLM, and output directory.\n    b. If the use_llm parameter\
    \ is True, use the 'get_model' function to instantiate the model configuration\
    \ for the LLM.\n    c. Use the 'get_python_file_details' function to get the Python\
    \ file details.\n    d. Use the 'get_python_datasets' function to get the instruct.json\
    \ datasets.\n    e. Use the 'save_python_data' function to save the file details\
    \ and instruct.json dataset.\n\n[req01] The process_python_directories function\
    \ shall:\n    a. Accept parameters for the starting directory, output directory,\
    \ model configuration pathname, questions dictionary, and use of LLM.\n    b.\
    \ Search for all Python files within the given directory and its subdirectories\
    \ using the rglob method with a pattern that excludes files starting with \"_\"\
    .\n    c. For each valid Python file, spawn a new child process using 'process_single_file'\
    \ function to get the file details and instruct.json dataset.\n    d. After processing\
    \ all files, combine all of the instruct.json files together using the 'combine_json_files'\
    \ function.\n    e. Return the combined datasets.\n\n[req02] The py2dataset function\
    \ shall:\n    a. Accept parameters for the starting directory, output directory,\
    \ questions pathname, model configuration pathname, use of LLM, and quiet mode.\n\
    \    b. Adjust the logging level based on the quiet flag.\n    c. If no valid\
    \ starting directory is provided, use the current working directory.\n    d. Use\
    \ the 'get_output_dir' function to get the output directory.\n    e. Use the 'get_questions'\
    \ function to get the questions dictionary.\n    f. Call the process_python_directories\
    \ function to process the Python files and generate datasets.\n    g. Return the\
    \ datasets.\n\n[req03] The main function shall:\n    a. Accept and process command-line\
    \ arguments.\n    b. Determine the parameters for the py2dataset function based\
    \ on the processed command-line arguments.\n    c. Call the py2dataset function\
    \ with the derived parameters.\n\"\"\"\nimport os\nimport sys\nimport gc\nimport\
    \ logging\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Union\n\
    from multiprocessing import Process\n\nfrom get_python_file_details import get_python_file_details\n\
    from get_python_datasets import get_python_datasets\nfrom get_py2dataset_params\
    \ import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output\
    \ import combine_json_files, save_python_data\n\n\ndef process_single_file(pythonfile_path,\
    \ start_dir, model_config_pathname, questions, use_llm, output_dir):\n    \"\"\
    \"\n    Process a single Python file to generate question-answer pairs and instructions.\n\
    \    Args:\n        pythonfile_path (str): Path to the Python file.\n        start_dir\
    \ (str): Starting directory to search for Python files.\n        model_config_pathname\
    \ (str): Path to the model configuration file.\n        questions (Dict): Questions\
    \ dictionary to answer about the Python file.\n        use_llm (bool): If True,\
    \ use a Large Language Model for generating JSON answers.\n        output_dir\
    \ (str): Directory to write the output files.\n    Returns:\n        none\n  \
    \  \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path\
    \ = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for\
    \ part in relative_path.parts)\n\n    #instantiate llm and prompt if use_llm is\
    \ True for each file to aviod multiprocessing pickling problem\n    model_config\
    \ = get_model(model_config_pathname) if use_llm else (None, '', 0)\n\n    # use\
    \ AST to get python file details\n    file_details = None\n    instruct_list =\
    \ None \n    file_details = get_python_file_details(pythonfile_path)\n    if file_details\
    \ is None or isinstance(file_details, tuple):\n        return \n\n    # get lists\
    \ for instruct.json for python file\n    instruct_list = get_python_datasets(pythonfile_path,\
    \ file_details, base_name, questions, model_config)\n    if instruct_list is None:\n\
    \        return\n\n    save_python_data(file_details, instruct_list, relative_path,\
    \ output_dir)\n\ndef process_python_directories(start_dir: str, output_dir: str,\
    \ model_config_pathname: str, questions: Dict, \n                            \
    \   use_llm: bool) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Processes all Python\
    \ files in the provided directory and subdirectories.\n    Args:\n        start_dir\
    \ (str): Starting directory to search for Python files.\n        output_dir (str):\
    \ Directory to write the output files.\n        model_config_pathname (str): Path\
    \ to the model configuration file.\n        questions (Dict): Questions dictionary\
    \ to answer about each Python file.\n        use_llm (bool): If True, use the\
    \ LLM model to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]:\
    \ Datasets dictionary.\n    \"\"\"\n    datasets = {}\n    for pythonfile_path\
    \ in Path(start_dir).rglob('[!_]*.py'):\n\n        if pythonfile_path.is_dir():\n\
    \            continue\n\n        # spawn a new child process to manage python\
    \ memory leaks\n        proc = Process(target=process_single_file, args=(pythonfile_path,\
    \ start_dir, model_config_pathname, questions, use_llm, output_dir))\n       \
    \ proc.start()\n        proc.join()\n        \n    # combine all of the instruct.json\
    \ files together\n    datasets = combine_json_files(output_dir)   \n    return\
    \ datasets\n\n\ndef py2dataset(start_dir: str = '', output_dir: str = '', questions_pathname:\
    \ str = '', model_config_pathname: str = '', \n               use_llm: bool =\
    \ False, quiet: bool = False) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process\
    \ Python files to generate question-answer pairs and instructions.\n    Args:\n\
    \        start_dir (str, optional): Starting directory to search for Python files.\
    \ Defaults to current working directory.\n        output_dir (str, optional):\
    \ Directory to write the output files.\n        questions_pathname (str, optional):\
    \ Path to the questions file.\n        model_config_pathname (str, optional):\
    \ Path to the model configuration file.\n        use_llm (bool, optional): If\
    \ True, use a Large Language Model for generating JSON answers. Defaults to False.\n\
    \        quiet (bool, optional): Limit logging output. Defaults to False.\n  \
    \  Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\n\
    \    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n    else:\n\
    \        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\
    \  # Increase the recursion limit for AST\n    \n    # if start dir is empty or\
    \ not a valid directory, use current working directory\n    if start_dir == ''\
    \ :\n        logging.info('No valid start path provided. Using current working\
    \ directory.')\n        start_dir = os.getcwd()    \n    start_dir = os.path.abspath(start_dir)\n\
    \    \n    output_dir = get_output_dir(output_dir)\n    questions = get_questions(questions_pathname)\n\
    \n    datasets = process_python_directories(start_dir, output_dir, model_config_pathname,\
    \ questions, use_llm)\n    return datasets\n\n\ndef main():\n    \"\"\"\n    Command-line\
    \ entry point for processing Python files and generating datasets.\n    Args:\n\
    \        --start_dir (str, optional): Starting directory to search for Python\
    \ files. Defaults to the current working directory.\n        --output_dir (str,\
    \ optional): Directory to write the output files. Defaults to the 'datasets' directory\
    \ in the current working directory.\n        --questions_pathname (str, optional):\
    \ Path to the questions file. If not provided, defaults defined in 'get_py2dataset_params.py'\
    \ will be used.\n        --model_config_pathname (str, optional): Path to the\
    \ model configuration file. If not provided, defaults defined in 'get_py2dataset_params.py'\
    \ will be used.\n        --use_llm (bool, optional): Use a Large Language Model\
    \ for generating JSON answers. Defaults to False.\n        --quiet (bool, optional):\
    \ Limit logging output. If provided, only warnings and errors will be logged.\
    \ Defaults to False.\n        --_context (bool, optional): add the context from\
    \ the AST to the code as context use_llm is true to get better responses, at the\
    \ expense of more memory usage.  \n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n\
    \    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname\
    \ = ''\n    use_llm = False\n    quiet = False\n\n    if '--start_dir' in arg_string:\
    \    \n        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n\
    \        arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n   \
    \ if '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir\
    \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir\
    \ {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n      \
    \  model_config_pathname = arg_string.split('--model_config_pathname ')[1].split('\
    \ ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}',\
    \ '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname\
    \ = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string\
    \ = arg_string.replace(f'--questions_pathname {questions_pathname}', '') \n  \
    \  if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string =\
    \ arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n     \
    \   quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n\n \
    \   py2dataset(start_dir, output_dir, questions_pathname, model_config_pathname,\
    \ use_llm, quiet)\n\nif __name__ == \"__main__\":\n    main()"
  file_ast: 'Module(body=[Expr(value=Constant(value=''\nFor each Python file within
    given directory, generate, save, and return datasets that include responses to
    questions about the code.\nRequirements:\n[req00] The process_single_file function
    shall:\n    a. Accept parameters for the Python file path, starting directory,
    model configuration pathname, questions dictionary, use of LLM, and output directory.\n    b.
    If the use_llm parameter is True, use the \''get_model\'' function to instantiate
    the model configuration for the LLM.\n    c. Use the \''get_python_file_details\''
    function to get the Python file details.\n    d. Use the \''get_python_datasets\''
    function to get the instruct.json datasets.\n    e. Use the \''save_python_data\''
    function to save the file details and instruct.json dataset.\n\n[req01] The process_python_directories
    function shall:\n    a. Accept parameters for the starting directory, output directory,
    model configuration pathname, questions dictionary, and use of LLM.\n    b. Search
    for all Python files within the given directory and its subdirectories using the
    rglob method with a pattern that excludes files starting with "_".\n    c. For
    each valid Python file, spawn a new child process using \''process_single_file\''
    function to get the file details and instruct.json dataset.\n    d. After processing
    all files, combine all of the instruct.json files together using the \''combine_json_files\''
    function.\n    e. Return the combined datasets.\n\n[req02] The py2dataset function
    shall:\n    a. Accept parameters for the starting directory, output directory,
    questions pathname, model configuration pathname, use of LLM, and quiet mode.\n    b.
    Adjust the logging level based on the quiet flag.\n    c. If no valid starting
    directory is provided, use the current working directory.\n    d. Use the \''get_output_dir\''
    function to get the output directory.\n    e. Use the \''get_questions\'' function
    to get the questions dictionary.\n    f. Call the process_python_directories function
    to process the Python files and generate datasets.\n    g. Return the datasets.\n\n[req03]
    The main function shall:\n    a. Accept and process command-line arguments.\n    b.
    Determine the parameters for the py2dataset function based on the processed command-line
    arguments.\n    c. Call the py2dataset function with the derived parameters.\n'')),
    Import(names=[alias(name=''os'')]), Import(names=[alias(name=''sys'')]), Import(names=[alias(name=''gc'')]),
    Import(names=[alias(name=''logging'')]), ImportFrom(module=''pathlib'', names=[alias(name=''Path'')],
    level=0), ImportFrom(module=''typing'', names=[alias(name=''Dict''), alias(name=''List''),
    alias(name=''Tuple''), alias(name=''Union'')], level=0), ImportFrom(module=''multiprocessing'',
    names=[alias(name=''Process'')], level=0), ImportFrom(module=''get_python_file_details'',
    names=[alias(name=''get_python_file_details'')], level=0), ImportFrom(module=''get_python_datasets'',
    names=[alias(name=''get_python_datasets'')], level=0), ImportFrom(module=''get_py2dataset_params'',
    names=[alias(name=''get_questions''), alias(name=''get_model''), alias(name=''get_output_dir'')],
    level=0), ImportFrom(module=''save_py2dataset_output'', names=[alias(name=''combine_json_files''),
    alias(name=''save_python_data'')], level=0), FunctionDef(name=''process_single_file'',
    args=arguments(posonlyargs=[], args=[arg(arg=''pythonfile_path''), arg(arg=''start_dir''),
    arg(arg=''model_config_pathname''), arg(arg=''questions''), arg(arg=''use_llm''),
    arg(arg=''output_dir'')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Process
    a single Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path
    (str): Path to the Python file.\n        start_dir (str): Starting directory to
    search for Python files.\n        model_config_pathname (str): Path to the model
    configuration file.\n        questions (Dict): Questions dictionary to answer
    about the Python file.\n        use_llm (bool): If True, use a Large Language
    Model for generating JSON answers.\n        output_dir (str): Directory to write
    the output files.\n    Returns:\n        none\n    '')), Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Processing:
    ''), FormattedValue(value=Name(id=''pythonfile_path'', ctx=Load()), conversion=-1)])],
    keywords=[])), Assign(targets=[Name(id=''relative_path'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''pythonfile_path'',
    ctx=Load()), attr=''relative_to'', ctx=Load()), args=[Name(id=''start_dir'', ctx=Load())],
    keywords=[])), Assign(targets=[Name(id=''base_name'', ctx=Store())], value=Call(func=Attribute(value=Constant(value=''.''),
    attr=''join'', ctx=Load()), args=[GeneratorExp(elt=Name(id=''part'', ctx=Load()),
    generators=[comprehension(target=Name(id=''part'', ctx=Store()), iter=Attribute(value=Name(id=''relative_path'',
    ctx=Load()), attr=''parts'', ctx=Load()), ifs=[], is_async=0)])], keywords=[])),
    Assign(targets=[Name(id=''model_config'', ctx=Store())], value=IfExp(test=Name(id=''use_llm'',
    ctx=Load()), body=Call(func=Name(id=''get_model'', ctx=Load()), args=[Name(id=''model_config_pathname'',
    ctx=Load())], keywords=[]), orelse=Tuple(elts=[Constant(value=None), Constant(value=''''),
    Constant(value=0)], ctx=Load()))), Assign(targets=[Name(id=''file_details'', ctx=Store())],
    value=Constant(value=None)), Assign(targets=[Name(id=''instruct_list'', ctx=Store())],
    value=Constant(value=None)), Assign(targets=[Name(id=''file_details'', ctx=Store())],
    value=Call(func=Name(id=''get_python_file_details'', ctx=Load()), args=[Name(id=''pythonfile_path'',
    ctx=Load())], keywords=[])), If(test=BoolOp(op=Or(), values=[Compare(left=Name(id=''file_details'',
    ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), Call(func=Name(id=''isinstance'',
    ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''tuple'', ctx=Load())],
    keywords=[])]), body=[Return()], orelse=[]), Assign(targets=[Name(id=''instruct_list'',
    ctx=Store())], value=Call(func=Name(id=''get_python_datasets'', ctx=Load()), args=[Name(id=''pythonfile_path'',
    ctx=Load()), Name(id=''file_details'', ctx=Load()), Name(id=''base_name'', ctx=Load()),
    Name(id=''questions'', ctx=Load()), Name(id=''model_config'', ctx=Load())], keywords=[])),
    If(test=Compare(left=Name(id=''instruct_list'', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]),
    body=[Return()], orelse=[]), Expr(value=Call(func=Name(id=''save_python_data'',
    ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''instruct_list'',
    ctx=Load()), Name(id=''relative_path'', ctx=Load()), Name(id=''output_dir'', ctx=Load())],
    keywords=[]))], decorator_list=[]), FunctionDef(name=''process_python_directories'',
    args=arguments(posonlyargs=[], args=[arg(arg=''start_dir'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load())),
    arg(arg=''model_config_pathname'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''questions'',
    annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''use_llm'', annotation=Name(id=''bool'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Processes
    all Python files in the provided directory and subdirectories.\n    Args:\n        start_dir
    (str): Starting directory to search for Python files.\n        output_dir (str):
    Directory to write the output files.\n        model_config_pathname (str): Path
    to the model configuration file.\n        questions (Dict): Questions dictionary
    to answer about each Python file.\n        use_llm (bool): If True, use the LLM
    model to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]:
    Datasets dictionary.\n    '')), Assign(targets=[Name(id=''datasets'', ctx=Store())],
    value=Dict(keys=[], values=[])), For(target=Name(id=''pythonfile_path'', ctx=Store()),
    iter=Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''start_dir'',
    ctx=Load())], keywords=[]), attr=''rglob'', ctx=Load()), args=[Constant(value=''[!_]*.py'')],
    keywords=[]), body=[If(test=Call(func=Attribute(value=Name(id=''pythonfile_path'',
    ctx=Load()), attr=''is_dir'', ctx=Load()), args=[], keywords=[]), body=[Continue()],
    orelse=[]), Assign(targets=[Name(id=''proc'', ctx=Store())], value=Call(func=Name(id=''Process'',
    ctx=Load()), args=[], keywords=[keyword(arg=''target'', value=Name(id=''process_single_file'',
    ctx=Load())), keyword(arg=''args'', value=Tuple(elts=[Name(id=''pythonfile_path'',
    ctx=Load()), Name(id=''start_dir'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load()),
    Name(id=''output_dir'', ctx=Load())], ctx=Load()))])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
    ctx=Load()), attr=''start'', ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
    ctx=Load()), attr=''join'', ctx=Load()), args=[], keywords=[]))], orelse=[]),
    Assign(targets=[Name(id=''datasets'', ctx=Store())], value=Call(func=Name(id=''combine_json_files'',
    ctx=Load()), args=[Name(id=''output_dir'', ctx=Load())], keywords=[])), Return(value=Name(id=''datasets'',
    ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''Dict'', ctx=Load()),
    slice=Tuple(elts=[Name(id=''str'', ctx=Load()), Subscript(value=Name(id=''List'',
    ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())),
    FunctionDef(name=''py2dataset'', args=arguments(posonlyargs=[], args=[arg(arg=''start_dir'',
    annotation=Name(id=''str'', ctx=Load())), arg(arg=''output_dir'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''questions_pathname'', annotation=Name(id=''str'', ctx=Load())),
    arg(arg=''model_config_pathname'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''use_llm'',
    annotation=Name(id=''bool'', ctx=Load())), arg(arg=''quiet'', annotation=Name(id=''bool'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=''''),
    Constant(value=''''), Constant(value=''''), Constant(value=''''), Constant(value=False),
    Constant(value=False)]), body=[Expr(value=Constant(value=''\n    Process Python
    files to generate question-answer pairs and instructions.\n    Args:\n        start_dir
    (str, optional): Starting directory to search for Python files. Defaults to current
    working directory.\n        output_dir (str, optional): Directory to write the
    output files.\n        questions_pathname (str, optional): Path to the questions
    file.\n        model_config_pathname (str, optional): Path to the model configuration
    file.\n        use_llm (bool, optional): If True, use a Large Language Model for
    generating JSON answers. Defaults to False.\n        quiet (bool, optional): Limit
    logging output. Defaults to False.\n    Returns:\n        Dict[str, List[Dict]]:
    Datasets dictionary.\n    '')), If(test=Name(id=''quiet'', ctx=Load()), body=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
    ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''WARNING'',
    ctx=Load())], keywords=[]))], orelse=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
    ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''INFO'',
    ctx=Load())], keywords=[]))]), Expr(value=Call(func=Attribute(value=Name(id=''sys'',
    ctx=Load()), attr=''setrecursionlimit'', ctx=Load()), args=[Constant(value=3000)],
    keywords=[])), If(test=Compare(left=Name(id=''start_dir'', ctx=Load()), ops=[Eq()],
    comparators=[Constant(value='''')]), body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[Constant(value=''No valid start
    path provided. Using current working directory.'')], keywords=[])), Assign(targets=[Name(id=''start_dir'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''os'', ctx=Load()), attr=''getcwd'',
    ctx=Load()), args=[], keywords=[]))], orelse=[]), Assign(targets=[Name(id=''start_dir'',
    ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''path'', ctx=Load()), attr=''abspath'', ctx=Load()), args=[Name(id=''start_dir'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''output_dir'', ctx=Store())],
    value=Call(func=Name(id=''get_output_dir'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''questions'', ctx=Store())],
    value=Call(func=Name(id=''get_questions'', ctx=Load()), args=[Name(id=''questions_pathname'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''datasets'', ctx=Store())],
    value=Call(func=Name(id=''process_python_directories'', ctx=Load()), args=[Name(id=''start_dir'',
    ctx=Load()), Name(id=''output_dir'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load())],
    keywords=[])), Return(value=Name(id=''datasets'', ctx=Load()))], decorator_list=[],
    returns=Subscript(value=Name(id=''Dict'', ctx=Load()), slice=Tuple(elts=[Name(id=''str'',
    ctx=Load()), Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
    ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())), FunctionDef(name=''main'',
    args=arguments(posonlyargs=[], args=[], kwonlyargs=[], kw_defaults=[], defaults=[]),
    body=[Expr(value=Constant(value="\n    Command-line entry point for processing
    Python files and generating datasets.\n    Args:\n        --start_dir (str, optional):
    Starting directory to search for Python files. Defaults to the current working
    directory.\n        --output_dir (str, optional): Directory to write the output
    files. Defaults to the ''datasets'' directory in the current working directory.\n        --questions_pathname
    (str, optional): Path to the questions file. If not provided, defaults defined
    in ''get_py2dataset_params.py'' will be used.\n        --model_config_pathname
    (str, optional): Path to the model configuration file. If not provided, defaults
    defined in ''get_py2dataset_params.py'' will be used.\n        --use_llm (bool,
    optional): Use a Large Language Model for generating JSON answers. Defaults to
    False.\n        --quiet (bool, optional): Limit logging output. If provided, only
    warnings and errors will be logged. Defaults to False.\n        --_context (bool,
    optional): add the context from the AST to the code as context use_llm is true
    to get better responses, at the expense of more memory usage.  \n    ")), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Constant(value='' ''), attr=''join'',
    ctx=Load()), args=[Subscript(value=Attribute(value=Name(id=''sys'', ctx=Load()),
    attr=''argv'', ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())],
    keywords=[])), Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''output_dir'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''questions_pathname'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''model_config_pathname'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''use_llm'', ctx=Store())], value=Constant(value=False)),
    Assign(targets=[Name(id=''quiet'', ctx=Store())], value=Constant(value=False)),
    If(test=Compare(left=Constant(value=''--start_dir''), ops=[In()], comparators=[Name(id=''arg_string'',
    ctx=Load())]), body=[Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--start_dir '')],
    keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--start_dir
    ''), FormattedValue(value=Name(id=''start_dir'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--output_dir''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''output_dir'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--output_dir
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--output_dir
    ''), FormattedValue(value=Name(id=''output_dir'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--model_config_pathname''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''model_config_pathname'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--model_config_pathname
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--model_config_pathname
    ''), FormattedValue(value=Name(id=''model_config_pathname'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--questions_pathname''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''questions_pathname'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--questions_pathname
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--questions_pathname
    ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--use_llm''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''use_llm'',
    ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''--use_llm''), Constant(value='''')],
    keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--quiet''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''quiet'',
    ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''--quiet''), Constant(value='''')],
    keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''py2dataset'', ctx=Load()),
    args=[Name(id=''start_dir'', ctx=Load()), Name(id=''output_dir'', ctx=Load()),
    Name(id=''questions_pathname'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''use_llm'', ctx=Load()), Name(id=''quiet'', ctx=Load())],
    keywords=[]))], decorator_list=[]), If(test=Compare(left=Name(id=''__name__'',
    ctx=Load()), ops=[Eq()], comparators=[Constant(value=''__main__'')]), body=[Expr(value=Call(func=Name(id=''main'',
    ctx=Load()), args=[], keywords=[]))], orelse=[])], type_ignores=[])'
  file_dependencies:
  - gc
  - get_python_datasets
  - get_py2dataset_params
  - logging
  - multiprocessing
  - pathlib
  - sys
  - save_py2dataset_output
  - os
  - get_python_file_details
  - typing
  file_functions:
  - process_single_file
  - process_python_directories
  - py2dataset
  - main
  file_classes: []
  file_summary: '{dependencies: [gc, get_python_datasets, get_py2dataset_params, logging,
    multiprocessing, pathlib, sys, save_py2dataset_output, os, get_python_file_details,
    typing], function_defs: [{process_single_file: {inputs: [pythonfile_path, start_dir,
    model_config_pathname, questions, use_llm, output_dir], calls: [logging.info,
    pythonfile_path.relative_to, ''.''.join, get_model, get_python_file_details, isinstance,
    get_python_datasets, save_python_data], call_inputs: {logging.info: [f''Processing:
    {pythonfile_path}''], pythonfile_path.relative_to: [start_dir], ''.''.join: [(part
    for part in relative_path.parts)], get_model: [model_config_pathname], get_python_file_details:
    [pythonfile_path], isinstance: [file_details, tuple], get_python_datasets: [pythonfile_path,
    file_details, base_name, questions, model_config], save_python_data: [file_details,
    instruct_list, relative_path, output_dir]}, returns: [None, None]}}, {process_python_directories:
    {inputs: [start_dir, output_dir, model_config_pathname, questions, use_llm], calls:
    [Path(start_dir).rglob, Path, pythonfile_path.is_dir, Process, proc.start, proc.join,
    combine_json_files], call_inputs: {Path(start_dir).rglob: [''[!_]*.py''], Path:
    [start_dir], pythonfile_path.is_dir: [], Process: [], proc.start: [], proc.join:
    [], combine_json_files: [output_dir]}, returns: [datasets]}}, {py2dataset: {inputs:
    [start_dir, output_dir, questions_pathname, model_config_pathname, use_llm, quiet],
    calls: [logging.getLogger().setLevel, logging.getLogger, sys.setrecursionlimit,
    logging.info, os.getcwd, os.path.abspath, get_output_dir, get_questions, process_python_directories],
    call_inputs: {logging.getLogger().setLevel: [logging.INFO], logging.getLogger:
    [], sys.setrecursionlimit: [3000], logging.info: [''No valid start path provided.
    Using current working directory.''], os.getcwd: [], os.path.abspath: [start_dir],
    get_output_dir: [output_dir], get_questions: [questions_pathname], process_python_directories:
    [start_dir, output_dir, model_config_pathname, questions, use_llm]}, returns:
    [datasets]}}, {main: {inputs: [], calls: ['' ''.join, arg_string.split(''--start_dir
    '')[1].split, arg_string.split, arg_string.replace, arg_string.split(''--output_dir
    '')[1].split, arg_string.split(''--model_config_pathname '')[1].split, arg_string.split(''--questions_pathname
    '')[1].split, py2dataset], call_inputs: {'' ''.join: [sys.argv[1:]], arg_string.split(''--start_dir
    '')[1].split: ['' ''], arg_string.split: [''--questions_pathname ''], arg_string.replace:
    [''--quiet'', ''''], arg_string.split(''--output_dir '')[1].split: ['' ''], arg_string.split(''--model_config_pathname
    '')[1].split: ['' ''], arg_string.split(''--questions_pathname '')[1].split: [''
    ''], py2dataset: [start_dir, output_dir, questions_pathname, model_config_pathname,
    use_llm, quiet]}, returns: []}}], class_defs: []}'
  file_code_simplified: "\"\"\"\"\"\"\nimport os\nimport sys\nimport gc\nimport logging\n\
    from pathlib import Path\nfrom typing import Dict, List, Tuple, Union\nfrom multiprocessing\
    \ import Process\nfrom get_python_file_details import get_python_file_details\n\
    from get_python_datasets import get_python_datasets\nfrom get_py2dataset_params\
    \ import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output\
    \ import combine_json_files, save_python_data\n\n\ndef process_single_file(pythonfile_path,\
    \ start_dir, model_config_pathname,\n    questions, use_llm, output_dir):\n  \
    \  \"\"\"\"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path\
    \ = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for\
    \ part in relative_path.parts)\n    model_config = get_model(model_config_pathname)\
    \ if use_llm else (None,\n        '', 0)\n    file_details = None\n    instruct_list\
    \ = None\n    file_details = get_python_file_details(pythonfile_path)\n    if\
    \ file_details is None or isinstance(file_details, tuple):\n        return\n \
    \   instruct_list = get_python_datasets(pythonfile_path, file_details,\n     \
    \   base_name, questions, model_config)\n    if instruct_list is None:\n     \
    \   return\n    save_python_data(file_details, instruct_list, relative_path, output_dir)\n\
    \n\ndef process_python_directories(start_dir: str, output_dir: str,\n    model_config_pathname:\
    \ str, questions: Dict, use_llm: bool) ->Dict[str,\n    List[Dict]]:\n    \"\"\
    \"\"\"\"\n    datasets = {}\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n\
    \        if pythonfile_path.is_dir():\n            continue\n        proc = Process(target=process_single_file,\
    \ args=(pythonfile_path,\n            start_dir, model_config_pathname, questions,\
    \ use_llm, output_dir))\n        proc.start()\n        proc.join()\n    datasets\
    \ = combine_json_files(output_dir)\n    return datasets\n\n\ndef py2dataset(start_dir:\
    \ str='', output_dir: str='', questions_pathname:\n    str='', model_config_pathname:\
    \ str='', use_llm: bool=False, quiet: bool\n    =False) ->Dict[str, List[Dict]]:\n\
    \    \"\"\"\"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n\
    \    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\n\
    \    if start_dir == '':\n        logging.info(\n            'No valid start path\
    \ provided. Using current working directory.')\n        start_dir = os.getcwd()\n\
    \    start_dir = os.path.abspath(start_dir)\n    output_dir = get_output_dir(output_dir)\n\
    \    questions = get_questions(questions_pathname)\n    datasets = process_python_directories(start_dir,\
    \ output_dir,\n        model_config_pathname, questions, use_llm)\n    return\
    \ datasets\n\n\ndef main():\n    \"\"\"\"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n\
    \    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname\
    \ = ''\n    use_llm = False\n    quiet = False\n    if '--start_dir' in arg_string:\n\
    \        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n     \
    \   arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n    if '--output_dir'\
    \ in arg_string:\n        output_dir = arg_string.split('--output_dir ')[1].split('\
    \ ')[0]\n        arg_string = arg_string.replace(f'--output_dir {output_dir}',\
    \ '')\n    if '--model_config_pathname' in arg_string:\n        model_config_pathname\
    \ = arg_string.split('--model_config_pathname ')[1\n            ].split(' ')[0]\n\
    \        arg_string = arg_string.replace(\n            f'--model_config_pathname\
    \ {model_config_pathname}', '')\n    if '--questions_pathname' in arg_string:\n\
    \        questions_pathname = arg_string.split('--questions_pathname ')[1\n  \
    \          ].split(' ')[0]\n        arg_string = arg_string.replace(\n       \
    \     f'--questions_pathname {questions_pathname}', '')\n    if '--use_llm' in\
    \ arg_string:\n        use_llm = True\n        arg_string = arg_string.replace('--use_llm',\
    \ '')\n    if '--quiet' in arg_string:\n        quiet = True\n        arg_string\
    \ = arg_string.replace('--quiet', '')\n    py2dataset(start_dir, output_dir, questions_pathname,\n\
    \        model_config_pathname, use_llm, quiet)\n\n\nif __name__ == '__main__':\n\
    \    main()"
  entire_code_graph:
    nodes:
    - process_single_file
    - process_python_directories
    - py2dataset
    - main
    - logging.info
    - pythonfile_path.relative_to
    - '''.''.join'
    - get_model
    - get_python_file_details
    - isinstance
    - get_python_datasets
    - save_python_data
    - Path(start_dir).rglob
    - Path
    - pythonfile_path.is_dir
    - Process
    - proc.start
    - proc.join
    - combine_json_files
    - logging.getLogger().setLevel
    - logging.getLogger
    - sys.setrecursionlimit
    - os.getcwd
    - os.path.abspath
    - get_output_dir
    - get_questions
    - ''' ''.join'
    - arg_string.split('--start_dir ')[1].split
    - arg_string.split
    - arg_string.replace
    - arg_string.split('--output_dir ')[1].split
    - arg_string.split('--model_config_pathname ')[1].split
    - arg_string.split('--questions_pathname ')[1].split
    edges:
    - source: process_single_file
      target: logging.info
      target_inputs:
      - 'f''Processing: {pythonfile_path}'''
    - source: process_single_file
      target: pythonfile_path.relative_to
      target_inputs:
      - start_dir
    - source: process_single_file
      target: '''.''.join'
      target_inputs:
      - (part for part in relative_path.parts)
    - source: process_single_file
      target: get_model
      target_inputs:
      - model_config_pathname
    - source: process_single_file
      target: get_python_file_details
      target_inputs:
      - pythonfile_path
    - source: process_single_file
      target: isinstance
      target_inputs:
      - file_details
      - tuple
    - source: process_single_file
      target: get_python_datasets
      target_inputs:
      - pythonfile_path
      - file_details
      - base_name
      - questions
      - model_config
    - source: process_single_file
      target: save_python_data
      target_inputs:
      - file_details
      - instruct_list
      - relative_path
      - output_dir
    - source: process_python_directories
      target: Path(start_dir).rglob
      target_inputs:
      - '''[!_]*.py'''
    - source: process_python_directories
      target: Path
      target_inputs:
      - start_dir
    - source: process_python_directories
      target: pythonfile_path.is_dir
      target_inputs: []
    - source: process_python_directories
      target: Process
      target_inputs: []
    - source: process_python_directories
      target: proc.start
      target_inputs: []
    - source: process_python_directories
      target: proc.join
      target_inputs: []
    - source: process_python_directories
      target: combine_json_files
      target_inputs:
      - output_dir
    - source: py2dataset
      target: logging.getLogger().setLevel
      target_inputs:
      - logging.INFO
    - source: py2dataset
      target: logging.getLogger
      target_inputs: []
    - source: py2dataset
      target: sys.setrecursionlimit
      target_inputs:
      - '3000'
    - source: py2dataset
      target: logging.info
      target_inputs:
      - '''No valid start path provided. Using current working directory.'''
    - source: py2dataset
      target: os.getcwd
      target_inputs: []
    - source: py2dataset
      target: os.path.abspath
      target_inputs:
      - start_dir
    - source: py2dataset
      target: get_output_dir
      target_inputs:
      - output_dir
    - source: py2dataset
      target: get_questions
      target_inputs:
      - questions_pathname
    - source: py2dataset
      target: process_python_directories
      target_inputs:
      - start_dir
      - output_dir
      - model_config_pathname
      - questions
      - use_llm
      target_returns:
      - datasets
    - source: main
      target: ''' ''.join'
      target_inputs:
      - sys.argv[1:]
    - source: main
      target: arg_string.split('--start_dir ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split
      target_inputs:
      - '''--questions_pathname '''
    - source: main
      target: arg_string.replace
      target_inputs:
      - '''--quiet'''
      - ''''''
    - source: main
      target: arg_string.split('--output_dir ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split('--model_config_pathname ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split('--questions_pathname ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: py2dataset
      target_inputs:
      - start_dir
      - output_dir
      - questions_pathname
      - model_config_pathname
      - use_llm
      - quiet
      target_returns:
      - datasets
functions:
  process_single_file:
    function_name: process_single_file
    function_code: "def process_single_file(pythonfile_path, start_dir, model_config_pathname,\
      \ questions, use_llm, output_dir):\n    \"\"\"\n    Process a single Python\
      \ file to generate question-answer pairs and instructions.\n    Args:\n    \
      \    pythonfile_path (str): Path to the Python file.\n        start_dir (str):\
      \ Starting directory to search for Python files.\n        model_config_pathname\
      \ (str): Path to the model configuration file.\n        questions (Dict): Questions\
      \ dictionary to answer about the Python file.\n        use_llm (bool): If True,\
      \ use a Large Language Model for generating JSON answers.\n        output_dir\
      \ (str): Directory to write the output files.\n    Returns:\n        none\n\
      \    \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path\
      \ = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join((part for\
      \ part in relative_path.parts))\n    model_config = get_model(model_config_pathname)\
      \ if use_llm else (None, '', 0)\n    file_details = None\n    instruct_list\
      \ = None\n    file_details = get_python_file_details(pythonfile_path)\n    if\
      \ file_details is None or isinstance(file_details, tuple):\n        return\n\
      \    instruct_list = get_python_datasets(pythonfile_path, file_details, base_name,\
      \ questions, model_config)\n    if instruct_list is None:\n        return\n\
      \    save_python_data(file_details, instruct_list, relative_path, output_dir)"
    function_ast: 'FunctionDef(name=''process_single_file'', args=arguments(posonlyargs=[],
      args=[arg(arg=''pythonfile_path''), arg(arg=''start_dir''), arg(arg=''model_config_pathname''),
      arg(arg=''questions''), arg(arg=''use_llm''), arg(arg=''output_dir'')], kwonlyargs=[],
      kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Process
      a single Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path
      (str): Path to the Python file.\n        start_dir (str): Starting directory
      to search for Python files.\n        model_config_pathname (str): Path to the
      model configuration file.\n        questions (Dict): Questions dictionary to
      answer about the Python file.\n        use_llm (bool): If True, use a Large
      Language Model for generating JSON answers.\n        output_dir (str): Directory
      to write the output files.\n    Returns:\n        none\n    '')), Expr(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Processing:
      ''), FormattedValue(value=Name(id=''pythonfile_path'', ctx=Load()), conversion=-1)])],
      keywords=[])), Assign(targets=[Name(id=''relative_path'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''pythonfile_path'',
      ctx=Load()), attr=''relative_to'', ctx=Load()), args=[Name(id=''start_dir'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''base_name'', ctx=Store())],
      value=Call(func=Attribute(value=Constant(value=''.''), attr=''join'', ctx=Load()),
      args=[GeneratorExp(elt=Name(id=''part'', ctx=Load()), generators=[comprehension(target=Name(id=''part'',
      ctx=Store()), iter=Attribute(value=Name(id=''relative_path'', ctx=Load()), attr=''parts'',
      ctx=Load()), ifs=[], is_async=0)])], keywords=[])), Assign(targets=[Name(id=''model_config'',
      ctx=Store())], value=IfExp(test=Name(id=''use_llm'', ctx=Load()), body=Call(func=Name(id=''get_model'',
      ctx=Load()), args=[Name(id=''model_config_pathname'', ctx=Load())], keywords=[]),
      orelse=Tuple(elts=[Constant(value=None), Constant(value=''''), Constant(value=0)],
      ctx=Load()))), Assign(targets=[Name(id=''file_details'', ctx=Store())], value=Constant(value=None)),
      Assign(targets=[Name(id=''instruct_list'', ctx=Store())], value=Constant(value=None)),
      Assign(targets=[Name(id=''file_details'', ctx=Store())], value=Call(func=Name(id=''get_python_file_details'',
      ctx=Load()), args=[Name(id=''pythonfile_path'', ctx=Load())], keywords=[])),
      If(test=BoolOp(op=Or(), values=[Compare(left=Name(id=''file_details'', ctx=Load()),
      ops=[Is()], comparators=[Constant(value=None)]), Call(func=Name(id=''isinstance'',
      ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''tuple'',
      ctx=Load())], keywords=[])]), body=[Return()], orelse=[]), Assign(targets=[Name(id=''instruct_list'',
      ctx=Store())], value=Call(func=Name(id=''get_python_datasets'', ctx=Load()),
      args=[Name(id=''pythonfile_path'', ctx=Load()), Name(id=''file_details'', ctx=Load()),
      Name(id=''base_name'', ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''model_config'',
      ctx=Load())], keywords=[])), If(test=Compare(left=Name(id=''instruct_list'',
      ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Return()],
      orelse=[]), Expr(value=Call(func=Name(id=''save_python_data'', ctx=Load()),
      args=[Name(id=''file_details'', ctx=Load()), Name(id=''instruct_list'', ctx=Load()),
      Name(id=''relative_path'', ctx=Load()), Name(id=''output_dir'', ctx=Load())],
      keywords=[]))], decorator_list=[])'
    function_docstring: "\n    Process a single Python file to generate question-answer\
      \ pairs and instructions.\n    Args:\n        pythonfile_path (str): Path to\
      \ the Python file.\n        start_dir (str): Starting directory to search for\
      \ Python files.\n        model_config_pathname (str): Path to the model configuration\
      \ file.\n        questions (Dict): Questions dictionary to answer about the\
      \ Python file.\n        use_llm (bool): If True, use a Large Language Model\
      \ for generating JSON answers.\n        output_dir (str): Directory to write\
      \ the output files.\n    Returns:\n        none\n    "
    function_inputs:
    - pythonfile_path
    - start_dir
    - model_config_pathname
    - questions
    - use_llm
    - output_dir
    function_defaults: []
    function_returns:
    - None
    - None
    function_calls:
    - logging.info
    - pythonfile_path.relative_to
    - '''.''.join'
    - get_model
    - get_python_file_details
    - isinstance
    - get_python_datasets
    - save_python_data
    function_call_inputs:
      logging.info:
      - 'f''Processing: {pythonfile_path}'''
      pythonfile_path.relative_to:
      - start_dir
      '''.''.join':
      - (part for part in relative_path.parts)
      get_model:
      - model_config_pathname
      get_python_file_details:
      - pythonfile_path
      isinstance:
      - file_details
      - tuple
      get_python_datasets:
      - pythonfile_path
      - file_details
      - base_name
      - questions
      - model_config
      save_python_data:
      - file_details
      - instruct_list
      - relative_path
      - output_dir
    function_variables:
    - relative_path
    - file_details
    - instruct_list
    - model_config
    - base_name
    function_decorators: []
    function_annotations: []
    function_properties: []
  process_python_directories:
    function_name: process_python_directories
    function_code: "def process_python_directories(start_dir: str, output_dir: str,\
      \ model_config_pathname: str, questions: Dict, use_llm: bool) -> Dict[str, List[Dict]]:\n\
      \    \"\"\"\n    Processes all Python files in the provided directory and subdirectories.\n\
      \    Args:\n        start_dir (str): Starting directory to search for Python\
      \ files.\n        output_dir (str): Directory to write the output files.\n \
      \       model_config_pathname (str): Path to the model configuration file.\n\
      \        questions (Dict): Questions dictionary to answer about each Python\
      \ file.\n        use_llm (bool): If True, use the LLM model to generate answers\
      \ for JSON..\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n\
      \    \"\"\"\n    datasets = {}\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n\
      \        if pythonfile_path.is_dir():\n            continue\n        proc =\
      \ Process(target=process_single_file, args=(pythonfile_path, start_dir, model_config_pathname,\
      \ questions, use_llm, output_dir))\n        proc.start()\n        proc.join()\n\
      \    datasets = combine_json_files(output_dir)\n    return datasets"
    function_ast: 'FunctionDef(name=''process_python_directories'', args=arguments(posonlyargs=[],
      args=[arg(arg=''start_dir'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''output_dir'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''model_config_pathname'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''questions'', annotation=Name(id=''Dict'',
      ctx=Load())), arg(arg=''use_llm'', annotation=Name(id=''bool'', ctx=Load()))],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Processes
      all Python files in the provided directory and subdirectories.\n    Args:\n        start_dir
      (str): Starting directory to search for Python files.\n        output_dir (str):
      Directory to write the output files.\n        model_config_pathname (str): Path
      to the model configuration file.\n        questions (Dict): Questions dictionary
      to answer about each Python file.\n        use_llm (bool): If True, use the
      LLM model to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]:
      Datasets dictionary.\n    '')), Assign(targets=[Name(id=''datasets'', ctx=Store())],
      value=Dict(keys=[], values=[])), For(target=Name(id=''pythonfile_path'', ctx=Store()),
      iter=Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''start_dir'',
      ctx=Load())], keywords=[]), attr=''rglob'', ctx=Load()), args=[Constant(value=''[!_]*.py'')],
      keywords=[]), body=[If(test=Call(func=Attribute(value=Name(id=''pythonfile_path'',
      ctx=Load()), attr=''is_dir'', ctx=Load()), args=[], keywords=[]), body=[Continue()],
      orelse=[]), Assign(targets=[Name(id=''proc'', ctx=Store())], value=Call(func=Name(id=''Process'',
      ctx=Load()), args=[], keywords=[keyword(arg=''target'', value=Name(id=''process_single_file'',
      ctx=Load())), keyword(arg=''args'', value=Tuple(elts=[Name(id=''pythonfile_path'',
      ctx=Load()), Name(id=''start_dir'', ctx=Load()), Name(id=''model_config_pathname'',
      ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load()),
      Name(id=''output_dir'', ctx=Load())], ctx=Load()))])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
      ctx=Load()), attr=''start'', ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
      ctx=Load()), attr=''join'', ctx=Load()), args=[], keywords=[]))], orelse=[]),
      Assign(targets=[Name(id=''datasets'', ctx=Store())], value=Call(func=Name(id=''combine_json_files'',
      ctx=Load()), args=[Name(id=''output_dir'', ctx=Load())], keywords=[])), Return(value=Name(id=''datasets'',
      ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''Dict'',
      ctx=Load()), slice=Tuple(elts=[Name(id=''str'', ctx=Load()), Subscript(value=Name(id=''List'',
      ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())], ctx=Load()),
      ctx=Load()))'
    function_docstring: "\n    Processes all Python files in the provided directory\
      \ and subdirectories.\n    Args:\n        start_dir (str): Starting directory\
      \ to search for Python files.\n        output_dir (str): Directory to write\
      \ the output files.\n        model_config_pathname (str): Path to the model\
      \ configuration file.\n        questions (Dict): Questions dictionary to answer\
      \ about each Python file.\n        use_llm (bool): If True, use the LLM model\
      \ to generate answers for JSON..\n    Returns:\n        Dict[str, List[Dict]]:\
      \ Datasets dictionary.\n    "
    function_inputs:
    - start_dir
    - output_dir
    - model_config_pathname
    - questions
    - use_llm
    function_defaults: []
    function_returns:
    - datasets
    function_calls:
    - Path(start_dir).rglob
    - Path
    - pythonfile_path.is_dir
    - Process
    - proc.start
    - proc.join
    - combine_json_files
    function_call_inputs:
      Path(start_dir).rglob:
      - '''[!_]*.py'''
      Path:
      - start_dir
      pythonfile_path.is_dir: []
      Process: []
      proc.start: []
      proc.join: []
      combine_json_files:
      - output_dir
    function_variables:
    - proc
    - datasets
    function_decorators: []
    function_annotations: []
    function_properties: []
  py2dataset:
    function_name: py2dataset
    function_code: "def py2dataset(start_dir: str='', output_dir: str='', questions_pathname:\
      \ str='', model_config_pathname: str='', use_llm: bool=False, quiet: bool=False)\
      \ -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process Python files to generate\
      \ question-answer pairs and instructions.\n    Args:\n        start_dir (str,\
      \ optional): Starting directory to search for Python files. Defaults to current\
      \ working directory.\n        output_dir (str, optional): Directory to write\
      \ the output files.\n        questions_pathname (str, optional): Path to the\
      \ questions file.\n        model_config_pathname (str, optional): Path to the\
      \ model configuration file.\n        use_llm (bool, optional): If True, use\
      \ a Large Language Model for generating JSON answers. Defaults to False.\n \
      \       quiet (bool, optional): Limit logging output. Defaults to False.\n \
      \   Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    \"\"\"\
      \n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n   \
      \ else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\n\
      \    if start_dir == '':\n        logging.info('No valid start path provided.\
      \ Using current working directory.')\n        start_dir = os.getcwd()\n    start_dir\
      \ = os.path.abspath(start_dir)\n    output_dir = get_output_dir(output_dir)\n\
      \    questions = get_questions(questions_pathname)\n    datasets = process_python_directories(start_dir,\
      \ output_dir, model_config_pathname, questions, use_llm)\n    return datasets"
    function_ast: 'FunctionDef(name=''py2dataset'', args=arguments(posonlyargs=[],
      args=[arg(arg=''start_dir'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''output_dir'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''questions_pathname'', annotation=Name(id=''str'',
      ctx=Load())), arg(arg=''model_config_pathname'', annotation=Name(id=''str'',
      ctx=Load())), arg(arg=''use_llm'', annotation=Name(id=''bool'', ctx=Load())),
      arg(arg=''quiet'', annotation=Name(id=''bool'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[Constant(value=''''), Constant(value=''''), Constant(value=''''),
      Constant(value=''''), Constant(value=False), Constant(value=False)]), body=[Expr(value=Constant(value=''\n    Process
      Python files to generate question-answer pairs and instructions.\n    Args:\n        start_dir
      (str, optional): Starting directory to search for Python files. Defaults to
      current working directory.\n        output_dir (str, optional): Directory to
      write the output files.\n        questions_pathname (str, optional): Path to
      the questions file.\n        model_config_pathname (str, optional): Path to
      the model configuration file.\n        use_llm (bool, optional): If True, use
      a Large Language Model for generating JSON answers. Defaults to False.\n        quiet
      (bool, optional): Limit logging output. Defaults to False.\n    Returns:\n        Dict[str,
      List[Dict]]: Datasets dictionary.\n    '')), If(test=Name(id=''quiet'', ctx=Load()),
      body=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
      ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''WARNING'',
      ctx=Load())], keywords=[]))], orelse=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
      ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''INFO'',
      ctx=Load())], keywords=[]))]), Expr(value=Call(func=Attribute(value=Name(id=''sys'',
      ctx=Load()), attr=''setrecursionlimit'', ctx=Load()), args=[Constant(value=3000)],
      keywords=[])), If(test=Compare(left=Name(id=''start_dir'', ctx=Load()), ops=[Eq()],
      comparators=[Constant(value='''')]), body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''info'', ctx=Load()), args=[Constant(value=''No valid start
      path provided. Using current working directory.'')], keywords=[])), Assign(targets=[Name(id=''start_dir'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''os'', ctx=Load()),
      attr=''getcwd'', ctx=Load()), args=[], keywords=[]))], orelse=[]), Assign(targets=[Name(id=''start_dir'',
      ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''path'', ctx=Load()), attr=''abspath'', ctx=Load()), args=[Name(id=''start_dir'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''output_dir'', ctx=Store())],
      value=Call(func=Name(id=''get_output_dir'', ctx=Load()), args=[Name(id=''output_dir'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''questions'', ctx=Store())],
      value=Call(func=Name(id=''get_questions'', ctx=Load()), args=[Name(id=''questions_pathname'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''datasets'', ctx=Store())],
      value=Call(func=Name(id=''process_python_directories'', ctx=Load()), args=[Name(id=''start_dir'',
      ctx=Load()), Name(id=''output_dir'', ctx=Load()), Name(id=''model_config_pathname'',
      ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load())],
      keywords=[])), Return(value=Name(id=''datasets'', ctx=Load()))], decorator_list=[],
      returns=Subscript(value=Name(id=''Dict'', ctx=Load()), slice=Tuple(elts=[Name(id=''str'',
      ctx=Load()), Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
      ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()))'
    function_docstring: "\n    Process Python files to generate question-answer pairs\
      \ and instructions.\n    Args:\n        start_dir (str, optional): Starting\
      \ directory to search for Python files. Defaults to current working directory.\n\
      \        output_dir (str, optional): Directory to write the output files.\n\
      \        questions_pathname (str, optional): Path to the questions file.\n \
      \       model_config_pathname (str, optional): Path to the model configuration\
      \ file.\n        use_llm (bool, optional): If True, use a Large Language Model\
      \ for generating JSON answers. Defaults to False.\n        quiet (bool, optional):\
      \ Limit logging output. Defaults to False.\n    Returns:\n        Dict[str,\
      \ List[Dict]]: Datasets dictionary.\n    "
    function_inputs:
    - start_dir
    - output_dir
    - questions_pathname
    - model_config_pathname
    - use_llm
    - quiet
    function_defaults:
    - ''''''
    - ''''''
    - ''''''
    - ''''''
    - 'False'
    - 'False'
    function_returns:
    - datasets
    function_calls:
    - logging.getLogger().setLevel
    - logging.getLogger
    - sys.setrecursionlimit
    - logging.info
    - os.getcwd
    - os.path.abspath
    - get_output_dir
    - get_questions
    - process_python_directories
    function_call_inputs:
      logging.getLogger().setLevel:
      - logging.INFO
      logging.getLogger: []
      sys.setrecursionlimit:
      - '3000'
      logging.info:
      - '''No valid start path provided. Using current working directory.'''
      os.getcwd: []
      os.path.abspath:
      - start_dir
      get_output_dir:
      - output_dir
      get_questions:
      - questions_pathname
      process_python_directories:
      - start_dir
      - output_dir
      - model_config_pathname
      - questions
      - use_llm
    function_variables:
    - questions
    - output_dir
    - start_dir
    - datasets
    function_decorators: []
    function_annotations: []
    function_properties: []
  main:
    function_name: main
    function_code: "def main():\n    \"\"\"\n    Command-line entry point for processing\
      \ Python files and generating datasets.\n    Args:\n        --start_dir (str,\
      \ optional): Starting directory to search for Python files. Defaults to the\
      \ current working directory.\n        --output_dir (str, optional): Directory\
      \ to write the output files. Defaults to the 'datasets' directory in the current\
      \ working directory.\n        --questions_pathname (str, optional): Path to\
      \ the questions file. If not provided, defaults defined in 'get_py2dataset_params.py'\
      \ will be used.\n        --model_config_pathname (str, optional): Path to the\
      \ model configuration file. If not provided, defaults defined in 'get_py2dataset_params.py'\
      \ will be used.\n        --use_llm (bool, optional): Use a Large Language Model\
      \ for generating JSON answers. Defaults to False.\n        --quiet (bool, optional):\
      \ Limit logging output. If provided, only warnings and errors will be logged.\
      \ Defaults to False.\n        --_context (bool, optional): add the context from\
      \ the AST to the code as context use_llm is true to get better responses, at\
      \ the expense of more memory usage.  \n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n\
      \    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname\
      \ = ''\n    use_llm = False\n    quiet = False\n    if '--start_dir' in arg_string:\n\
      \        start_dir = arg_string.split('--start_dir ')[1].split(' ')[0]\n   \
      \     arg_string = arg_string.replace(f'--start_dir {start_dir}', '')\n    if\
      \ '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir\
      \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir\
      \ {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n    \
      \    model_config_pathname = arg_string.split('--model_config_pathname ')[1].split('\
      \ ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}',\
      \ '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname\
      \ = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string\
      \ = arg_string.replace(f'--questions_pathname {questions_pathname}', '')\n \
      \   if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string\
      \ = arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n \
      \       quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n\
      \    py2dataset(start_dir, output_dir, questions_pathname, model_config_pathname,\
      \ use_llm, quiet)"
    function_ast: 'FunctionDef(name=''main'', args=arguments(posonlyargs=[], args=[],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value="\n    Command-line
      entry point for processing Python files and generating datasets.\n    Args:\n        --start_dir
      (str, optional): Starting directory to search for Python files. Defaults to
      the current working directory.\n        --output_dir (str, optional): Directory
      to write the output files. Defaults to the ''datasets'' directory in the current
      working directory.\n        --questions_pathname (str, optional): Path to the
      questions file. If not provided, defaults defined in ''get_py2dataset_params.py''
      will be used.\n        --model_config_pathname (str, optional): Path to the
      model configuration file. If not provided, defaults defined in ''get_py2dataset_params.py''
      will be used.\n        --use_llm (bool, optional): Use a Large Language Model
      for generating JSON answers. Defaults to False.\n        --quiet (bool, optional):
      Limit logging output. If provided, only warnings and errors will be logged.
      Defaults to False.\n        --_context (bool, optional): add the context from
      the AST to the code as context use_llm is true to get better responses, at the
      expense of more memory usage.  \n    ")), Assign(targets=[Name(id=''arg_string'',
      ctx=Store())], value=Call(func=Attribute(value=Constant(value='' ''), attr=''join'',
      ctx=Load()), args=[Subscript(value=Attribute(value=Name(id=''sys'', ctx=Load()),
      attr=''argv'', ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())],
      keywords=[])), Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Constant(value='''')),
      Assign(targets=[Name(id=''output_dir'', ctx=Store())], value=Constant(value='''')),
      Assign(targets=[Name(id=''questions_pathname'', ctx=Store())], value=Constant(value='''')),
      Assign(targets=[Name(id=''model_config_pathname'', ctx=Store())], value=Constant(value='''')),
      Assign(targets=[Name(id=''use_llm'', ctx=Store())], value=Constant(value=False)),
      Assign(targets=[Name(id=''quiet'', ctx=Store())], value=Constant(value=False)),
      If(test=Compare(left=Constant(value=''--start_dir''), ops=[In()], comparators=[Name(id=''arg_string'',
      ctx=Load())]), body=[Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--start_dir
      '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
      args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--start_dir
      ''), FormattedValue(value=Name(id=''start_dir'', ctx=Load()), conversion=-1)]),
      Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--output_dir''),
      ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''output_dir'',
      ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--output_dir
      '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
      args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--output_dir
      ''), FormattedValue(value=Name(id=''output_dir'', ctx=Load()), conversion=-1)]),
      Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--model_config_pathname''),
      ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''model_config_pathname'',
      ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--model_config_pathname
      '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
      args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--model_config_pathname
      ''), FormattedValue(value=Name(id=''model_config_pathname'', ctx=Load()), conversion=-1)]),
      Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--questions_pathname''),
      ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''questions_pathname'',
      ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--questions_pathname
      '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
      args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
      ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--questions_pathname
      ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()), conversion=-1)]),
      Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--use_llm''),
      ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''use_llm'',
      ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
      attr=''replace'', ctx=Load()), args=[Constant(value=''--use_llm''), Constant(value='''')],
      keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--quiet''),
      ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''quiet'',
      ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
      attr=''replace'', ctx=Load()), args=[Constant(value=''--quiet''), Constant(value='''')],
      keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''py2dataset'', ctx=Load()),
      args=[Name(id=''start_dir'', ctx=Load()), Name(id=''output_dir'', ctx=Load()),
      Name(id=''questions_pathname'', ctx=Load()), Name(id=''model_config_pathname'',
      ctx=Load()), Name(id=''use_llm'', ctx=Load()), Name(id=''quiet'', ctx=Load())],
      keywords=[]))], decorator_list=[])'
    function_docstring: "\n    Command-line entry point for processing Python files\
      \ and generating datasets.\n    Args:\n        --start_dir (str, optional):\
      \ Starting directory to search for Python files. Defaults to the current working\
      \ directory.\n        --output_dir (str, optional): Directory to write the output\
      \ files. Defaults to the 'datasets' directory in the current working directory.\n\
      \        --questions_pathname (str, optional): Path to the questions file. If\
      \ not provided, defaults defined in 'get_py2dataset_params.py' will be used.\n\
      \        --model_config_pathname (str, optional): Path to the model configuration\
      \ file. If not provided, defaults defined in 'get_py2dataset_params.py' will\
      \ be used.\n        --use_llm (bool, optional): Use a Large Language Model for\
      \ generating JSON answers. Defaults to False.\n        --quiet (bool, optional):\
      \ Limit logging output. If provided, only warnings and errors will be logged.\
      \ Defaults to False.\n        --_context (bool, optional): add the context from\
      \ the AST to the code as context use_llm is true to get better responses, at\
      \ the expense of more memory usage.  \n    "
    function_inputs: []
    function_defaults: []
    function_returns: []
    function_calls:
    - ''' ''.join'
    - arg_string.split('--start_dir ')[1].split
    - arg_string.split
    - arg_string.replace
    - arg_string.split('--output_dir ')[1].split
    - arg_string.split('--model_config_pathname ')[1].split
    - arg_string.split('--questions_pathname ')[1].split
    - py2dataset
    function_call_inputs:
      ''' ''.join':
      - sys.argv[1:]
      arg_string.split('--start_dir ')[1].split:
      - ''' '''
      arg_string.split:
      - '''--questions_pathname '''
      arg_string.replace:
      - '''--quiet'''
      - ''''''
      arg_string.split('--output_dir ')[1].split:
      - ''' '''
      arg_string.split('--model_config_pathname ')[1].split:
      - ''' '''
      arg_string.split('--questions_pathname ')[1].split:
      - ''' '''
      py2dataset:
      - start_dir
      - output_dir
      - questions_pathname
      - model_config_pathname
      - use_llm
      - quiet
    function_variables:
    - quiet
    - start_dir
    - output_dir
    - model_config_pathname
    - use_llm
    - questions_pathname
    - arg_string
    function_decorators: []
    function_annotations: []
    function_properties: []
classes: {}
