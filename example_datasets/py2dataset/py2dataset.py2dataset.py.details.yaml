file_info:
  file_code: "\"\"\"\nFor each Python file within given directory, generate, save,\
    \ and return datasets\nthat include responses to questions about the code.\nRequirements:\n\
    [req00] The process_single_file function shall:\n    a. Accept parameters for\
    \ Python file path, start directory, model config \n    pathname, questions dict,\
    \ use of LLM, and output dir.\n    b. If 'use_llm' is True, use 'get_model' to\
    \ instantiate LLM model config.\n    c. Use 'get_python_file_details' to retrieve\
    \ Python file info.\n    d. Use 'get_python_datasets' to acquire instruct.json\
    \ datasets.\n    e. Use 'save_python_data' to store file details and instruct.json\
    \ data.\n[req01] The py2dataset function shall:\n    a. Accept parameters for\
    \ start directory, output dir, questions path, model\n    config path, use of\
    \ LLM, and quiet mode.\n    b. Adjust logging level based on 'quiet'.\n    c.\
    \ Use current working dir if no valid start dir is provided.\n    d. Get output\
    \ dir with 'get_output_dir'.\n    e. Retrieve questions dict with 'get_questions'.\n\
    \    f. Search for Python files using 'rglob', excluding those starting with \"\
    _\".\n    g. For each Python file, spawn a child process with 'process_single_file'\n\
    \    to get file details and instruct.json data, if single_process is False.\n\
    \    h. Combine instruct.json files with 'combine_json_files'.\n    i. Return\
    \ datasets.\n[req02] The main function shall:\n    a. Accept and process command-line\
    \ args.\n    b. Determine py2dataset parameters based on processed arguments.\n\
    \    c. Call py2dataset with derived parameters.\n\"\"\"\nimport os\nimport sys\n\
    import logging\nfrom pathlib import Path\nfrom typing import Dict, List\nfrom\
    \ multiprocessing import Process\n\nfrom get_python_file_details import get_python_file_details\n\
    from get_python_datasets import get_python_datasets\nfrom get_py2dataset_params\
    \ import get_questions, get_model, get_output_dir\nfrom save_py2dataset_output\
    \ import combine_json_files, save_python_data\n\ndef process_single_file(pythonfile_path:\
    \ str, start_dir: str, model_config_pathname: str,\n                        questions:\
    \ Dict, use_llm: bool, output_dir: str,\n                        model_config:\
    \ Dict = None, single_process: bool = False) -> None:\n    \"\"\"\n    Process\
    \ a single Python file to generate question-answer pairs and instructions.\n \
    \   Args:\n        pythonfile_path (str): Path to the Python file.\n        start_dir\
    \ (str): Starting directory to search for Python files.\n        model_config_pathname\
    \ (str): Path to the model configuration file.\n        questions (Dict): Questions\
    \ dictionary to answer about the Python file.\n        use_llm (bool): If True,\
    \ use a Large Language Model for generating JSON answers.\n        output_dir\
    \ (str): Directory to write the output files.\n        model_config (Dict): Model\
    \ configuration dictionary for the LLM.\n        single_process (bool, optional):\
    \ Set True to use single process. Defaults to False.\n    Returns:\n        none\n\
    \    \"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path\
    \ = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for\
    \ part in relative_path.parts)\n\n    if not single_process:\n        # Instantiate\
    \ llm and prompt if use_llm is True for each file to avoid\n        # multiprocessing\
    \ pickling problem\n        model_config = get_model(model_config_pathname) if\
    \ use_llm else (None, '', 0)\n\n    # Use AST to get python file details\n   \
    \ file_details = get_python_file_details(pythonfile_path)\n    if file_details\
    \ is None or isinstance(file_details, tuple):\n        return\n\n    # Get lists\
    \ for instruct.json for python file\n    instruct_list = get_python_datasets(\n\
    \        pythonfile_path,\n        file_details,\n        base_name,\n       \
    \ questions,\n        model_config\n        )\n    if instruct_list is None:\n\
    \        return\n\n    save_python_data(file_details, instruct_list, relative_path,\
    \ output_dir)\n\ndef py2dataset(start_dir: str = '', output_dir: str = '', questions_pathname:\
    \ str = '',\n               model_config_pathname: str = '', use_llm: bool = False,\
    \ quiet: bool = False,\n               single_process: bool = False) -> Dict[str,\
    \ List[Dict]]:\n    \"\"\"\n    Process Python files to generate question-answer\
    \ pairs and instructions.\n    Args:\n        start_dir (str, optional): Starting\
    \ directory for Python files.\n        Defaults to current working directory.\n\
    \        output_dir (str, optional): Directory to write the output files.\n  \
    \      questions_pathname (str, optional): Path to the questions file.\n     \
    \   model_config_pathname (str, optional): Path to the model\n        configuration\
    \ file.\n        use_llm (bool, optional): If True, use a Large Language Model\n\
    \        for generating JSON answers. Defaults to False.\n        quiet (bool,\
    \ optional): Limit logging output. Defaults to False.\n        single_process(bool,\
    \ optional): If True, only a single process \n        will be used to process\
    \ Python files. Defaults to False. Set to True to\n        instantiate LLM once\
    \ before processing all files.\n    Returns:\n        Dict[str, List[Dict]]: Datasets\
    \ dictionary.\n    \"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n\
    \    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\
    \  # Increase the recursion limit for AST\n\n    # If start dir is empty or not\
    \ a valid directory, use current working directory\n    if not start_dir:\n  \
    \      logging.info('No valid start path provided. Using current working directory.')\n\
    \        start_dir = os.getcwd()\n    start_dir = os.path.abspath(start_dir)\n\
    \    output_dir = get_output_dir(output_dir)\n    questions = get_questions(questions_pathname)\n\
    \n    # If single_process is True, load model config here\n    if single_process:\n\
    \        model_config = get_model(model_config_pathname) if use_llm else (None,\
    \ '', 0)\n\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n  \
    \      if pythonfile_path.is_dir():\n            continue\n        if single_process:\n\
    \            process_single_file(\n                pythonfile_path,\n        \
    \        start_dir,\n                model_config_pathname,\n                questions,\n\
    \                use_llm,\n                output_dir,\n                model_config,\n\
    \                single_process)\n            continue\n        # Spawn a new\
    \ child process to manage python memory leaks\n        proc = Process(\n     \
    \       target=process_single_file,\n            args=(\n                pythonfile_path,\n\
    \                start_dir,\n                model_config_pathname,\n        \
    \        questions,\n                use_llm,\n                output_dir)\n \
    \           )\n        proc.start()\n        proc.join()\n\n    # Combine all\
    \ of the instruct.json files together\n    datasets = combine_json_files(output_dir)\n\
    \    return datasets\n\ndef main():\n    \"\"\"\n    Command-line entry point\
    \ for processing Python files and generating datasets.\n    \"\"\"\n    arg_string\
    \ = ' '.join(sys.argv[1:])\n    start_dir = ''\n    output_dir = ''\n    questions_pathname\
    \ = ''\n    model_config_pathname = ''\n    use_llm = False\n    quiet = False\n\
    \    single_process = False\n\n    if '--start_dir' in arg_string:\n        start_dir\
    \ = arg_string.split('--start_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--start_dir\
    \ {start_dir}', '')\n    if '--output_dir' in arg_string:\n        output_dir\
    \ = arg_string.split('--output_dir ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir\
    \ {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n      \
    \  model_config_pathname = arg_string.split('--model_config_pathname ')[1].split('\
    \ ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname {model_config_pathname}',\
    \ '')\n    if '--questions_pathname' in arg_string:\n        questions_pathname\
    \ = arg_string.split('--questions_pathname ')[1].split(' ')[0]\n        arg_string\
    \ = arg_string.replace(f'--questions_pathname {questions_pathname}', '')\n   \
    \ if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string =\
    \ arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n     \
    \   quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n   \
    \ if '--single_process' in arg_string:\n        single_process = True\n      \
    \  arg_string = arg_string.replace('--single_process', '')\n\n    py2dataset(\n\
    \        start_dir,\n        output_dir,\n        questions_pathname,\n      \
    \  model_config_pathname,\n        use_llm,\n        quiet,\n        single_process)\n\
    \nif __name__ == \"__main__\":\n    main()\n"
  file_ast: 'Module(body=[Expr(value=Constant(value=''\nFor each Python file within
    given directory, generate, save, and return datasets\nthat include responses to
    questions about the code.\nRequirements:\n[req00] The process_single_file function
    shall:\n    a. Accept parameters for Python file path, start directory, model
    config \n    pathname, questions dict, use of LLM, and output dir.\n    b. If
    \''use_llm\'' is True, use \''get_model\'' to instantiate LLM model config.\n    c.
    Use \''get_python_file_details\'' to retrieve Python file info.\n    d. Use \''get_python_datasets\''
    to acquire instruct.json datasets.\n    e. Use \''save_python_data\'' to store
    file details and instruct.json data.\n[req01] The py2dataset function shall:\n    a.
    Accept parameters for start directory, output dir, questions path, model\n    config
    path, use of LLM, and quiet mode.\n    b. Adjust logging level based on \''quiet\''.\n    c.
    Use current working dir if no valid start dir is provided.\n    d. Get output
    dir with \''get_output_dir\''.\n    e. Retrieve questions dict with \''get_questions\''.\n    f.
    Search for Python files using \''rglob\'', excluding those starting with "_".\n    g.
    For each Python file, spawn a child process with \''process_single_file\''\n    to
    get file details and instruct.json data, if single_process is False.\n    h. Combine
    instruct.json files with \''combine_json_files\''.\n    i. Return datasets.\n[req02]
    The main function shall:\n    a. Accept and process command-line args.\n    b.
    Determine py2dataset parameters based on processed arguments.\n    c. Call py2dataset
    with derived parameters.\n'')), Import(names=[alias(name=''os'')]), Import(names=[alias(name=''sys'')]),
    Import(names=[alias(name=''logging'')]), ImportFrom(module=''pathlib'', names=[alias(name=''Path'')],
    level=0), ImportFrom(module=''typing'', names=[alias(name=''Dict''), alias(name=''List'')],
    level=0), ImportFrom(module=''multiprocessing'', names=[alias(name=''Process'')],
    level=0), ImportFrom(module=''get_python_file_details'', names=[alias(name=''get_python_file_details'')],
    level=0), ImportFrom(module=''get_python_datasets'', names=[alias(name=''get_python_datasets'')],
    level=0), ImportFrom(module=''get_py2dataset_params'', names=[alias(name=''get_questions''),
    alias(name=''get_model''), alias(name=''get_output_dir'')], level=0), ImportFrom(module=''save_py2dataset_output'',
    names=[alias(name=''combine_json_files''), alias(name=''save_python_data'')],
    level=0), FunctionDef(name=''process_single_file'', args=arguments(posonlyargs=[],
    args=[arg(arg=''pythonfile_path'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''start_dir'',
    annotation=Name(id=''str'', ctx=Load())), arg(arg=''model_config_pathname'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''questions'', annotation=Name(id=''Dict'', ctx=Load())),
    arg(arg=''use_llm'', annotation=Name(id=''bool'', ctx=Load())), arg(arg=''output_dir'',
    annotation=Name(id=''str'', ctx=Load())), arg(arg=''model_config'', annotation=Name(id=''Dict'',
    ctx=Load())), arg(arg=''single_process'', annotation=Name(id=''bool'', ctx=Load()))],
    kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=False)]),
    body=[Expr(value=Constant(value=''\n    Process a single Python file to generate
    question-answer pairs and instructions.\n    Args:\n        pythonfile_path (str):
    Path to the Python file.\n        start_dir (str): Starting directory to search
    for Python files.\n        model_config_pathname (str): Path to the model configuration
    file.\n        questions (Dict): Questions dictionary to answer about the Python
    file.\n        use_llm (bool): If True, use a Large Language Model for generating
    JSON answers.\n        output_dir (str): Directory to write the output files.\n        model_config
    (Dict): Model configuration dictionary for the LLM.\n        single_process (bool,
    optional): Set True to use single process. Defaults to False.\n    Returns:\n        none\n    '')),
    Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()), attr=''info'',
    ctx=Load()), args=[JoinedStr(values=[Constant(value=''Processing: ''), FormattedValue(value=Name(id=''pythonfile_path'',
    ctx=Load()), conversion=-1)])], keywords=[])), Assign(targets=[Name(id=''relative_path'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''pythonfile_path'', ctx=Load()),
    attr=''relative_to'', ctx=Load()), args=[Name(id=''start_dir'', ctx=Load())],
    keywords=[])), Assign(targets=[Name(id=''base_name'', ctx=Store())], value=Call(func=Attribute(value=Constant(value=''.''),
    attr=''join'', ctx=Load()), args=[GeneratorExp(elt=Name(id=''part'', ctx=Load()),
    generators=[comprehension(target=Name(id=''part'', ctx=Store()), iter=Attribute(value=Name(id=''relative_path'',
    ctx=Load()), attr=''parts'', ctx=Load()), ifs=[], is_async=0)])], keywords=[])),
    If(test=UnaryOp(op=Not(), operand=Name(id=''single_process'', ctx=Load())), body=[Assign(targets=[Name(id=''model_config'',
    ctx=Store())], value=IfExp(test=Name(id=''use_llm'', ctx=Load()), body=Call(func=Name(id=''get_model'',
    ctx=Load()), args=[Name(id=''model_config_pathname'', ctx=Load())], keywords=[]),
    orelse=Tuple(elts=[Constant(value=None), Constant(value=''''), Constant(value=0)],
    ctx=Load())))], orelse=[]), Assign(targets=[Name(id=''file_details'', ctx=Store())],
    value=Call(func=Name(id=''get_python_file_details'', ctx=Load()), args=[Name(id=''pythonfile_path'',
    ctx=Load())], keywords=[])), If(test=BoolOp(op=Or(), values=[Compare(left=Name(id=''file_details'',
    ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), Call(func=Name(id=''isinstance'',
    ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''tuple'', ctx=Load())],
    keywords=[])]), body=[Return()], orelse=[]), Assign(targets=[Name(id=''instruct_list'',
    ctx=Store())], value=Call(func=Name(id=''get_python_datasets'', ctx=Load()), args=[Name(id=''pythonfile_path'',
    ctx=Load()), Name(id=''file_details'', ctx=Load()), Name(id=''base_name'', ctx=Load()),
    Name(id=''questions'', ctx=Load()), Name(id=''model_config'', ctx=Load())], keywords=[])),
    If(test=Compare(left=Name(id=''instruct_list'', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]),
    body=[Return()], orelse=[]), Expr(value=Call(func=Name(id=''save_python_data'',
    ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''instruct_list'',
    ctx=Load()), Name(id=''relative_path'', ctx=Load()), Name(id=''output_dir'', ctx=Load())],
    keywords=[]))], decorator_list=[], returns=Constant(value=None)), FunctionDef(name=''py2dataset'',
    args=arguments(posonlyargs=[], args=[arg(arg=''start_dir'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load())),
    arg(arg=''questions_pathname'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''model_config_pathname'',
    annotation=Name(id=''str'', ctx=Load())), arg(arg=''use_llm'', annotation=Name(id=''bool'',
    ctx=Load())), arg(arg=''quiet'', annotation=Name(id=''bool'', ctx=Load())), arg(arg=''single_process'',
    annotation=Name(id=''bool'', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=''''),
    Constant(value=''''), Constant(value=''''), Constant(value=''''), Constant(value=False),
    Constant(value=False), Constant(value=False)]), body=[Expr(value=Constant(value=''\n    Process
    Python files to generate question-answer pairs and instructions.\n    Args:\n        start_dir
    (str, optional): Starting directory for Python files.\n        Defaults to current
    working directory.\n        output_dir (str, optional): Directory to write the
    output files.\n        questions_pathname (str, optional): Path to the questions
    file.\n        model_config_pathname (str, optional): Path to the model\n        configuration
    file.\n        use_llm (bool, optional): If True, use a Large Language Model\n        for
    generating JSON answers. Defaults to False.\n        quiet (bool, optional): Limit
    logging output. Defaults to False.\n        single_process(bool, optional): If
    True, only a single process \n        will be used to process Python files. Defaults
    to False. Set to True to\n        instantiate LLM once before processing all files.\n    Returns:\n        Dict[str,
    List[Dict]]: Datasets dictionary.\n    '')), If(test=Name(id=''quiet'', ctx=Load()),
    body=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
    ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''WARNING'',
    ctx=Load())], keywords=[]))], orelse=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
    ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''INFO'',
    ctx=Load())], keywords=[]))]), Expr(value=Call(func=Attribute(value=Name(id=''sys'',
    ctx=Load()), attr=''setrecursionlimit'', ctx=Load()), args=[Constant(value=3000)],
    keywords=[])), If(test=UnaryOp(op=Not(), operand=Name(id=''start_dir'', ctx=Load())),
    body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()), attr=''info'',
    ctx=Load()), args=[Constant(value=''No valid start path provided. Using current
    working directory.'')], keywords=[])), Assign(targets=[Name(id=''start_dir'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''os'', ctx=Load()), attr=''getcwd'',
    ctx=Load()), args=[], keywords=[]))], orelse=[]), Assign(targets=[Name(id=''start_dir'',
    ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''path'', ctx=Load()), attr=''abspath'', ctx=Load()), args=[Name(id=''start_dir'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''output_dir'', ctx=Store())],
    value=Call(func=Name(id=''get_output_dir'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load())], keywords=[])), Assign(targets=[Name(id=''questions'', ctx=Store())],
    value=Call(func=Name(id=''get_questions'', ctx=Load()), args=[Name(id=''questions_pathname'',
    ctx=Load())], keywords=[])), If(test=Name(id=''single_process'', ctx=Load()),
    body=[Assign(targets=[Name(id=''model_config'', ctx=Store())], value=IfExp(test=Name(id=''use_llm'',
    ctx=Load()), body=Call(func=Name(id=''get_model'', ctx=Load()), args=[Name(id=''model_config_pathname'',
    ctx=Load())], keywords=[]), orelse=Tuple(elts=[Constant(value=None), Constant(value=''''),
    Constant(value=0)], ctx=Load())))], orelse=[]), For(target=Name(id=''pythonfile_path'',
    ctx=Store()), iter=Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()),
    args=[Name(id=''start_dir'', ctx=Load())], keywords=[]), attr=''rglob'', ctx=Load()),
    args=[Constant(value=''[!_]*.py'')], keywords=[]), body=[If(test=Call(func=Attribute(value=Name(id=''pythonfile_path'',
    ctx=Load()), attr=''is_dir'', ctx=Load()), args=[], keywords=[]), body=[Continue()],
    orelse=[]), If(test=Name(id=''single_process'', ctx=Load()), body=[Expr(value=Call(func=Name(id=''process_single_file'',
    ctx=Load()), args=[Name(id=''pythonfile_path'', ctx=Load()), Name(id=''start_dir'',
    ctx=Load()), Name(id=''model_config_pathname'', ctx=Load()), Name(id=''questions'',
    ctx=Load()), Name(id=''use_llm'', ctx=Load()), Name(id=''output_dir'', ctx=Load()),
    Name(id=''model_config'', ctx=Load()), Name(id=''single_process'', ctx=Load())],
    keywords=[])), Continue()], orelse=[]), Assign(targets=[Name(id=''proc'', ctx=Store())],
    value=Call(func=Name(id=''Process'', ctx=Load()), args=[], keywords=[keyword(arg=''target'',
    value=Name(id=''process_single_file'', ctx=Load())), keyword(arg=''args'', value=Tuple(elts=[Name(id=''pythonfile_path'',
    ctx=Load()), Name(id=''start_dir'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load()),
    Name(id=''output_dir'', ctx=Load())], ctx=Load()))])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
    ctx=Load()), attr=''start'', ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
    ctx=Load()), attr=''join'', ctx=Load()), args=[], keywords=[]))], orelse=[]),
    Assign(targets=[Name(id=''datasets'', ctx=Store())], value=Call(func=Name(id=''combine_json_files'',
    ctx=Load()), args=[Name(id=''output_dir'', ctx=Load())], keywords=[])), Return(value=Name(id=''datasets'',
    ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''Dict'', ctx=Load()),
    slice=Tuple(elts=[Name(id=''str'', ctx=Load()), Subscript(value=Name(id=''List'',
    ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())),
    FunctionDef(name=''main'', args=arguments(posonlyargs=[], args=[], kwonlyargs=[],
    kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Command-line
    entry point for processing Python files and generating datasets.\n    '')), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Constant(value='' ''), attr=''join'',
    ctx=Load()), args=[Subscript(value=Attribute(value=Name(id=''sys'', ctx=Load()),
    attr=''argv'', ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())],
    keywords=[])), Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''output_dir'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''questions_pathname'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''model_config_pathname'', ctx=Store())], value=Constant(value='''')),
    Assign(targets=[Name(id=''use_llm'', ctx=Store())], value=Constant(value=False)),
    Assign(targets=[Name(id=''quiet'', ctx=Store())], value=Constant(value=False)),
    Assign(targets=[Name(id=''single_process'', ctx=Store())], value=Constant(value=False)),
    If(test=Compare(left=Constant(value=''--start_dir''), ops=[In()], comparators=[Name(id=''arg_string'',
    ctx=Load())]), body=[Assign(targets=[Name(id=''start_dir'', ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--start_dir '')],
    keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--start_dir
    ''), FormattedValue(value=Name(id=''start_dir'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--output_dir''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''output_dir'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--output_dir
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--output_dir
    ''), FormattedValue(value=Name(id=''output_dir'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--model_config_pathname''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''model_config_pathname'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--model_config_pathname
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--model_config_pathname
    ''), FormattedValue(value=Name(id=''model_config_pathname'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--questions_pathname''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''questions_pathname'',
    ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''split'', ctx=Load()), args=[Constant(value=''--questions_pathname
    '')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr=''split'', ctx=Load()),
    args=[Constant(value='' '')], keywords=[]), slice=Constant(value=0), ctx=Load())),
    Assign(targets=[Name(id=''arg_string'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''--questions_pathname
    ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()), conversion=-1)]),
    Constant(value='''')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--use_llm''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''use_llm'',
    ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''--use_llm''), Constant(value='''')],
    keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--quiet''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''quiet'',
    ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''--quiet''), Constant(value='''')],
    keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value=''--single_process''),
    ops=[In()], comparators=[Name(id=''arg_string'', ctx=Load())]), body=[Assign(targets=[Name(id=''single_process'',
    ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id=''arg_string'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''arg_string'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''--single_process''), Constant(value='''')],
    keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''py2dataset'', ctx=Load()),
    args=[Name(id=''start_dir'', ctx=Load()), Name(id=''output_dir'', ctx=Load()),
    Name(id=''questions_pathname'', ctx=Load()), Name(id=''model_config_pathname'',
    ctx=Load()), Name(id=''use_llm'', ctx=Load()), Name(id=''quiet'', ctx=Load()),
    Name(id=''single_process'', ctx=Load())], keywords=[]))], decorator_list=[]),
    If(test=Compare(left=Name(id=''__name__'', ctx=Load()), ops=[Eq()], comparators=[Constant(value=''__main__'')]),
    body=[Expr(value=Call(func=Name(id=''main'', ctx=Load()), args=[], keywords=[]))],
    orelse=[])], type_ignores=[])'
  file_dependencies:
  - save_py2dataset_output
  - os
  - typing
  - get_py2dataset_params
  - pathlib
  - multiprocessing
  - get_python_datasets
  - logging
  - sys
  - get_python_file_details
  file_functions:
  - process_single_file
  - py2dataset
  - main
  file_classes: []
  file_summary: '{dependencies: [save_py2dataset_output, os, typing, get_py2dataset_params,
    pathlib, multiprocessing, get_python_datasets, logging, sys, get_python_file_details],
    function_defs: [{process_single_file: {inputs: [pythonfile_path, start_dir, model_config_pathname,
    questions, use_llm, output_dir, model_config, single_process], calls: [logging.info,
    pythonfile_path.relative_to, ''.''.join, get_model, get_python_file_details, isinstance,
    get_python_datasets, save_python_data], call_inputs: {logging.info: [f''Processing:
    {pythonfile_path}''], pythonfile_path.relative_to: [start_dir], ''.''.join: [(part
    for part in relative_path.parts)], get_model: [model_config_pathname], get_python_file_details:
    [pythonfile_path], isinstance: [file_details, tuple], get_python_datasets: [pythonfile_path,
    file_details, base_name, questions, model_config], save_python_data: [file_details,
    instruct_list, relative_path, output_dir]}, returns: [None, None]}}, {py2dataset:
    {inputs: [start_dir, output_dir, questions_pathname, model_config_pathname, use_llm,
    quiet, single_process], calls: [logging.getLogger().setLevel, logging.getLogger,
    sys.setrecursionlimit, logging.info, os.getcwd, os.path.abspath, get_output_dir,
    get_questions, get_model, Path(start_dir).rglob, Path, pythonfile_path.is_dir,
    process_single_file, Process, proc.start, proc.join, combine_json_files], call_inputs:
    {logging.getLogger().setLevel: [logging.INFO], logging.getLogger: [], sys.setrecursionlimit:
    [3000], logging.info: [''No valid start path provided. Using current working directory.''],
    os.getcwd: [], os.path.abspath: [start_dir], get_output_dir: [output_dir], get_questions:
    [questions_pathname], get_model: [model_config_pathname], Path(start_dir).rglob:
    [''[!_]*.py''], Path: [start_dir], pythonfile_path.is_dir: [], process_single_file:
    [pythonfile_path, start_dir, model_config_pathname, questions, use_llm, output_dir,
    model_config, single_process], Process: [], proc.start: [], proc.join: [], combine_json_files:
    [output_dir]}, returns: [datasets]}}, {main: {inputs: [], calls: ['' ''.join,
    arg_string.split(''--start_dir '')[1].split, arg_string.split, arg_string.replace,
    arg_string.split(''--output_dir '')[1].split, arg_string.split(''--model_config_pathname
    '')[1].split, arg_string.split(''--questions_pathname '')[1].split, py2dataset],
    call_inputs: {'' ''.join: [sys.argv[1:]], arg_string.split(''--start_dir '')[1].split:
    ['' ''], arg_string.split: [''--questions_pathname ''], arg_string.replace: [''--single_process'',
    ''''], arg_string.split(''--output_dir '')[1].split: ['' ''], arg_string.split(''--model_config_pathname
    '')[1].split: ['' ''], arg_string.split(''--questions_pathname '')[1].split: [''
    ''], py2dataset: [start_dir, output_dir, questions_pathname, model_config_pathname,
    use_llm, quiet, single_process]}, returns: []}}], class_defs: []}'
  file_code_simplified: "\"\"\"\"\"\"\nimport os\nimport sys\nimport logging\nfrom\
    \ pathlib import Path\nfrom typing import Dict, List\nfrom multiprocessing import\
    \ Process\nfrom get_python_file_details import get_python_file_details\nfrom get_python_datasets\
    \ import get_python_datasets\nfrom get_py2dataset_params import get_questions,\
    \ get_model, get_output_dir\nfrom save_py2dataset_output import combine_json_files,\
    \ save_python_data\n\n\ndef process_single_file(pythonfile_path: str, start_dir:\
    \ str,\n    model_config_pathname: str, questions: Dict, use_llm: bool, output_dir:\n\
    \    str, model_config: Dict=None, single_process: bool=False) ->None:\n    \"\
    \"\"\"\"\"\n    logging.info(f'Processing: {pythonfile_path}')\n    relative_path\
    \ = pythonfile_path.relative_to(start_dir)\n    base_name = '.'.join(part for\
    \ part in relative_path.parts)\n    if not single_process:\n        model_config\
    \ = get_model(model_config_pathname) if use_llm else (None,\n            '', 0)\n\
    \    file_details = get_python_file_details(pythonfile_path)\n    if file_details\
    \ is None or isinstance(file_details, tuple):\n        return\n    instruct_list\
    \ = get_python_datasets(pythonfile_path, file_details,\n        base_name, questions,\
    \ model_config)\n    if instruct_list is None:\n        return\n    save_python_data(file_details,\
    \ instruct_list, relative_path, output_dir)\n\n\ndef py2dataset(start_dir: str='',\
    \ output_dir: str='', questions_pathname:\n    str='', model_config_pathname:\
    \ str='', use_llm: bool=False, quiet: bool\n    =False, single_process: bool=False)\
    \ ->Dict[str, List[Dict]]:\n    \"\"\"\"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n\
    \    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\n\
    \    if not start_dir:\n        logging.info(\n            'No valid start path\
    \ provided. Using current working directory.')\n        start_dir = os.getcwd()\n\
    \    start_dir = os.path.abspath(start_dir)\n    output_dir = get_output_dir(output_dir)\n\
    \    questions = get_questions(questions_pathname)\n    if single_process:\n \
    \       model_config = get_model(model_config_pathname) if use_llm else (None,\n\
    \            '', 0)\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n\
    \        if pythonfile_path.is_dir():\n            continue\n        if single_process:\n\
    \            process_single_file(pythonfile_path, start_dir,\n               \
    \ model_config_pathname, questions, use_llm, output_dir,\n                model_config,\
    \ single_process)\n            continue\n        proc = Process(target=process_single_file,\
    \ args=(pythonfile_path,\n            start_dir, model_config_pathname, questions,\
    \ use_llm, output_dir))\n        proc.start()\n        proc.join()\n    datasets\
    \ = combine_json_files(output_dir)\n    return datasets\n\n\ndef main():\n   \
    \ \"\"\"\"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n    start_dir = ''\n\
    \    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname =\
    \ ''\n    use_llm = False\n    quiet = False\n    single_process = False\n   \
    \ if '--start_dir' in arg_string:\n        start_dir = arg_string.split('--start_dir\
    \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--start_dir {start_dir}',\
    \ '')\n    if '--output_dir' in arg_string:\n        output_dir = arg_string.split('--output_dir\
    \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--output_dir\
    \ {output_dir}', '')\n    if '--model_config_pathname' in arg_string:\n      \
    \  model_config_pathname = arg_string.split('--model_config_pathname ')[1\n  \
    \          ].split(' ')[0]\n        arg_string = arg_string.replace(\n       \
    \     f'--model_config_pathname {model_config_pathname}', '')\n    if '--questions_pathname'\
    \ in arg_string:\n        questions_pathname = arg_string.split('--questions_pathname\
    \ ')[1\n            ].split(' ')[0]\n        arg_string = arg_string.replace(\n\
    \            f'--questions_pathname {questions_pathname}', '')\n    if '--use_llm'\
    \ in arg_string:\n        use_llm = True\n        arg_string = arg_string.replace('--use_llm',\
    \ '')\n    if '--quiet' in arg_string:\n        quiet = True\n        arg_string\
    \ = arg_string.replace('--quiet', '')\n    if '--single_process' in arg_string:\n\
    \        single_process = True\n        arg_string = arg_string.replace('--single_process',\
    \ '')\n    py2dataset(start_dir, output_dir, questions_pathname,\n        model_config_pathname,\
    \ use_llm, quiet, single_process)\n\n\nif __name__ == '__main__':\n    main()"
  entire_code_graph:
    nodes:
    - process_single_file
    - py2dataset
    - main
    - logging.info
    - pythonfile_path.relative_to
    - '''.''.join'
    - get_model
    - get_python_file_details
    - isinstance
    - get_python_datasets
    - save_python_data
    - logging.getLogger().setLevel
    - logging.getLogger
    - sys.setrecursionlimit
    - os.getcwd
    - os.path.abspath
    - get_output_dir
    - get_questions
    - Path(start_dir).rglob
    - Path
    - pythonfile_path.is_dir
    - Process
    - proc.start
    - proc.join
    - combine_json_files
    - ''' ''.join'
    - arg_string.split('--start_dir ')[1].split
    - arg_string.split
    - arg_string.replace
    - arg_string.split('--output_dir ')[1].split
    - arg_string.split('--model_config_pathname ')[1].split
    - arg_string.split('--questions_pathname ')[1].split
    edges:
    - source: process_single_file
      target: logging.info
      target_inputs:
      - 'f''Processing: {pythonfile_path}'''
    - source: process_single_file
      target: pythonfile_path.relative_to
      target_inputs:
      - start_dir
    - source: process_single_file
      target: '''.''.join'
      target_inputs:
      - (part for part in relative_path.parts)
    - source: process_single_file
      target: get_model
      target_inputs:
      - model_config_pathname
    - source: process_single_file
      target: get_python_file_details
      target_inputs:
      - pythonfile_path
    - source: process_single_file
      target: isinstance
      target_inputs:
      - file_details
      - tuple
    - source: process_single_file
      target: get_python_datasets
      target_inputs:
      - pythonfile_path
      - file_details
      - base_name
      - questions
      - model_config
    - source: process_single_file
      target: save_python_data
      target_inputs:
      - file_details
      - instruct_list
      - relative_path
      - output_dir
    - source: py2dataset
      target: logging.getLogger().setLevel
      target_inputs:
      - logging.INFO
    - source: py2dataset
      target: logging.getLogger
      target_inputs: []
    - source: py2dataset
      target: sys.setrecursionlimit
      target_inputs:
      - '3000'
    - source: py2dataset
      target: logging.info
      target_inputs:
      - '''No valid start path provided. Using current working directory.'''
    - source: py2dataset
      target: os.getcwd
      target_inputs: []
    - source: py2dataset
      target: os.path.abspath
      target_inputs:
      - start_dir
    - source: py2dataset
      target: get_output_dir
      target_inputs:
      - output_dir
    - source: py2dataset
      target: get_questions
      target_inputs:
      - questions_pathname
    - source: py2dataset
      target: get_model
      target_inputs:
      - model_config_pathname
    - source: py2dataset
      target: Path(start_dir).rglob
      target_inputs:
      - '''[!_]*.py'''
    - source: py2dataset
      target: Path
      target_inputs:
      - start_dir
    - source: py2dataset
      target: pythonfile_path.is_dir
      target_inputs: []
    - source: py2dataset
      target: process_single_file
      target_inputs:
      - pythonfile_path
      - start_dir
      - model_config_pathname
      - questions
      - use_llm
      - output_dir
      - model_config
      - single_process
      target_returns:
      - None
    - source: py2dataset
      target: Process
      target_inputs: []
    - source: py2dataset
      target: proc.start
      target_inputs: []
    - source: py2dataset
      target: proc.join
      target_inputs: []
    - source: py2dataset
      target: combine_json_files
      target_inputs:
      - output_dir
    - source: main
      target: ''' ''.join'
      target_inputs:
      - sys.argv[1:]
    - source: main
      target: arg_string.split('--start_dir ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split
      target_inputs:
      - '''--questions_pathname '''
    - source: main
      target: arg_string.replace
      target_inputs:
      - '''--single_process'''
      - ''''''
    - source: main
      target: arg_string.split('--output_dir ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split('--model_config_pathname ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: arg_string.split('--questions_pathname ')[1].split
      target_inputs:
      - ''' '''
    - source: main
      target: py2dataset
      target_inputs:
      - start_dir
      - output_dir
      - questions_pathname
      - model_config_pathname
      - use_llm
      - quiet
      - single_process
      target_returns:
      - datasets
functions:
  process_single_file:
    function_name: process_single_file
    function_code: "def process_single_file(pythonfile_path: str, start_dir: str,\
      \ model_config_pathname: str, questions: Dict, use_llm: bool, output_dir: str,\
      \ model_config: Dict=None, single_process: bool=False) -> None:\n    \"\"\"\n\
      \    Process a single Python file to generate question-answer pairs and instructions.\n\
      \    Args:\n        pythonfile_path (str): Path to the Python file.\n      \
      \  start_dir (str): Starting directory to search for Python files.\n       \
      \ model_config_pathname (str): Path to the model configuration file.\n     \
      \   questions (Dict): Questions dictionary to answer about the Python file.\n\
      \        use_llm (bool): If True, use a Large Language Model for generating\
      \ JSON answers.\n        output_dir (str): Directory to write the output files.\n\
      \        model_config (Dict): Model configuration dictionary for the LLM.\n\
      \        single_process (bool, optional): Set True to use single process. Defaults\
      \ to False.\n    Returns:\n        none\n    \"\"\"\n    logging.info(f'Processing:\
      \ {pythonfile_path}')\n    relative_path = pythonfile_path.relative_to(start_dir)\n\
      \    base_name = '.'.join((part for part in relative_path.parts))\n    if not\
      \ single_process:\n        model_config = get_model(model_config_pathname) if\
      \ use_llm else (None, '', 0)\n    file_details = get_python_file_details(pythonfile_path)\n\
      \    if file_details is None or isinstance(file_details, tuple):\n        return\n\
      \    instruct_list = get_python_datasets(pythonfile_path, file_details, base_name,\
      \ questions, model_config)\n    if instruct_list is None:\n        return\n\
      \    save_python_data(file_details, instruct_list, relative_path, output_dir)"
    function_ast: 'FunctionDef(name=''process_single_file'', args=arguments(posonlyargs=[],
      args=[arg(arg=''pythonfile_path'', annotation=Name(id=''str'', ctx=Load())),
      arg(arg=''start_dir'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''model_config_pathname'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''questions'', annotation=Name(id=''Dict'',
      ctx=Load())), arg(arg=''use_llm'', annotation=Name(id=''bool'', ctx=Load())),
      arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''model_config'',
      annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''single_process'', annotation=Name(id=''bool'',
      ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None),
      Constant(value=False)]), body=[Expr(value=Constant(value=''\n    Process a single
      Python file to generate question-answer pairs and instructions.\n    Args:\n        pythonfile_path
      (str): Path to the Python file.\n        start_dir (str): Starting directory
      to search for Python files.\n        model_config_pathname (str): Path to the
      model configuration file.\n        questions (Dict): Questions dictionary to
      answer about the Python file.\n        use_llm (bool): If True, use a Large
      Language Model for generating JSON answers.\n        output_dir (str): Directory
      to write the output files.\n        model_config (Dict): Model configuration
      dictionary for the LLM.\n        single_process (bool, optional): Set True to
      use single process. Defaults to False.\n    Returns:\n        none\n    '')),
      Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()), attr=''info'',
      ctx=Load()), args=[JoinedStr(values=[Constant(value=''Processing: ''), FormattedValue(value=Name(id=''pythonfile_path'',
      ctx=Load()), conversion=-1)])], keywords=[])), Assign(targets=[Name(id=''relative_path'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''pythonfile_path'',
      ctx=Load()), attr=''relative_to'', ctx=Load()), args=[Name(id=''start_dir'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''base_name'', ctx=Store())],
      value=Call(func=Attribute(value=Constant(value=''.''), attr=''join'', ctx=Load()),
      args=[GeneratorExp(elt=Name(id=''part'', ctx=Load()), generators=[comprehension(target=Name(id=''part'',
      ctx=Store()), iter=Attribute(value=Name(id=''relative_path'', ctx=Load()), attr=''parts'',
      ctx=Load()), ifs=[], is_async=0)])], keywords=[])), If(test=UnaryOp(op=Not(),
      operand=Name(id=''single_process'', ctx=Load())), body=[Assign(targets=[Name(id=''model_config'',
      ctx=Store())], value=IfExp(test=Name(id=''use_llm'', ctx=Load()), body=Call(func=Name(id=''get_model'',
      ctx=Load()), args=[Name(id=''model_config_pathname'', ctx=Load())], keywords=[]),
      orelse=Tuple(elts=[Constant(value=None), Constant(value=''''), Constant(value=0)],
      ctx=Load())))], orelse=[]), Assign(targets=[Name(id=''file_details'', ctx=Store())],
      value=Call(func=Name(id=''get_python_file_details'', ctx=Load()), args=[Name(id=''pythonfile_path'',
      ctx=Load())], keywords=[])), If(test=BoolOp(op=Or(), values=[Compare(left=Name(id=''file_details'',
      ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), Call(func=Name(id=''isinstance'',
      ctx=Load()), args=[Name(id=''file_details'', ctx=Load()), Name(id=''tuple'',
      ctx=Load())], keywords=[])]), body=[Return()], orelse=[]), Assign(targets=[Name(id=''instruct_list'',
      ctx=Store())], value=Call(func=Name(id=''get_python_datasets'', ctx=Load()),
      args=[Name(id=''pythonfile_path'', ctx=Load()), Name(id=''file_details'', ctx=Load()),
      Name(id=''base_name'', ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''model_config'',
      ctx=Load())], keywords=[])), If(test=Compare(left=Name(id=''instruct_list'',
      ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Return()],
      orelse=[]), Expr(value=Call(func=Name(id=''save_python_data'', ctx=Load()),
      args=[Name(id=''file_details'', ctx=Load()), Name(id=''instruct_list'', ctx=Load()),
      Name(id=''relative_path'', ctx=Load()), Name(id=''output_dir'', ctx=Load())],
      keywords=[]))], decorator_list=[], returns=Constant(value=None))'
    function_docstring: "\n    Process a single Python file to generate question-answer\
      \ pairs and instructions.\n    Args:\n        pythonfile_path (str): Path to\
      \ the Python file.\n        start_dir (str): Starting directory to search for\
      \ Python files.\n        model_config_pathname (str): Path to the model configuration\
      \ file.\n        questions (Dict): Questions dictionary to answer about the\
      \ Python file.\n        use_llm (bool): If True, use a Large Language Model\
      \ for generating JSON answers.\n        output_dir (str): Directory to write\
      \ the output files.\n        model_config (Dict): Model configuration dictionary\
      \ for the LLM.\n        single_process (bool, optional): Set True to use single\
      \ process. Defaults to False.\n    Returns:\n        none\n    "
    function_inputs:
    - pythonfile_path
    - start_dir
    - model_config_pathname
    - questions
    - use_llm
    - output_dir
    - model_config
    - single_process
    function_defaults:
    - None
    - 'False'
    function_returns:
    - None
    - None
    function_calls:
    - logging.info
    - pythonfile_path.relative_to
    - '''.''.join'
    - get_model
    - get_python_file_details
    - isinstance
    - get_python_datasets
    - save_python_data
    function_call_inputs:
      logging.info:
      - 'f''Processing: {pythonfile_path}'''
      pythonfile_path.relative_to:
      - start_dir
      '''.''.join':
      - (part for part in relative_path.parts)
      get_model:
      - model_config_pathname
      get_python_file_details:
      - pythonfile_path
      isinstance:
      - file_details
      - tuple
      get_python_datasets:
      - pythonfile_path
      - file_details
      - base_name
      - questions
      - model_config
      save_python_data:
      - file_details
      - instruct_list
      - relative_path
      - output_dir
    function_variables:
    - model_config
    - base_name
    - file_details
    - instruct_list
    - relative_path
    function_decorators: []
    function_annotations: []
    function_properties: []
  py2dataset:
    function_name: py2dataset
    function_code: "def py2dataset(start_dir: str='', output_dir: str='', questions_pathname:\
      \ str='', model_config_pathname: str='', use_llm: bool=False, quiet: bool=False,\
      \ single_process: bool=False) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Process\
      \ Python files to generate question-answer pairs and instructions.\n    Args:\n\
      \        start_dir (str, optional): Starting directory for Python files.\n \
      \       Defaults to current working directory.\n        output_dir (str, optional):\
      \ Directory to write the output files.\n        questions_pathname (str, optional):\
      \ Path to the questions file.\n        model_config_pathname (str, optional):\
      \ Path to the model\n        configuration file.\n        use_llm (bool, optional):\
      \ If True, use a Large Language Model\n        for generating JSON answers.\
      \ Defaults to False.\n        quiet (bool, optional): Limit logging output.\
      \ Defaults to False.\n        single_process(bool, optional): If True, only\
      \ a single process \n        will be used to process Python files. Defaults\
      \ to False. Set to True to\n        instantiate LLM once before processing all\
      \ files.\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n\
      \    \"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n\
      \    else:\n        logging.getLogger().setLevel(logging.INFO)\n    sys.setrecursionlimit(3000)\n\
      \    if not start_dir:\n        logging.info('No valid start path provided.\
      \ Using current working directory.')\n        start_dir = os.getcwd()\n    start_dir\
      \ = os.path.abspath(start_dir)\n    output_dir = get_output_dir(output_dir)\n\
      \    questions = get_questions(questions_pathname)\n    if single_process:\n\
      \        model_config = get_model(model_config_pathname) if use_llm else (None,\
      \ '', 0)\n    for pythonfile_path in Path(start_dir).rglob('[!_]*.py'):\n  \
      \      if pythonfile_path.is_dir():\n            continue\n        if single_process:\n\
      \            process_single_file(pythonfile_path, start_dir, model_config_pathname,\
      \ questions, use_llm, output_dir, model_config, single_process)\n          \
      \  continue\n        proc = Process(target=process_single_file, args=(pythonfile_path,\
      \ start_dir, model_config_pathname, questions, use_llm, output_dir))\n     \
      \   proc.start()\n        proc.join()\n    datasets = combine_json_files(output_dir)\n\
      \    return datasets"
    function_ast: 'FunctionDef(name=''py2dataset'', args=arguments(posonlyargs=[],
      args=[arg(arg=''start_dir'', annotation=Name(id=''str'', ctx=Load())), arg(arg=''output_dir'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''questions_pathname'', annotation=Name(id=''str'',
      ctx=Load())), arg(arg=''model_config_pathname'', annotation=Name(id=''str'',
      ctx=Load())), arg(arg=''use_llm'', annotation=Name(id=''bool'', ctx=Load())),
      arg(arg=''quiet'', annotation=Name(id=''bool'', ctx=Load())), arg(arg=''single_process'',
      annotation=Name(id=''bool'', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=''''),
      Constant(value=''''), Constant(value=''''), Constant(value=''''), Constant(value=False),
      Constant(value=False), Constant(value=False)]), body=[Expr(value=Constant(value=''\n    Process
      Python files to generate question-answer pairs and instructions.\n    Args:\n        start_dir
      (str, optional): Starting directory for Python files.\n        Defaults to current
      working directory.\n        output_dir (str, optional): Directory to write the
      output files.\n        questions_pathname (str, optional): Path to the questions
      file.\n        model_config_pathname (str, optional): Path to the model\n        configuration
      file.\n        use_llm (bool, optional): If True, use a Large Language Model\n        for
      generating JSON answers. Defaults to False.\n        quiet (bool, optional):
      Limit logging output. Defaults to False.\n        single_process(bool, optional):
      If True, only a single process \n        will be used to process Python files.
      Defaults to False. Set to True to\n        instantiate LLM once before processing
      all files.\n    Returns:\n        Dict[str, List[Dict]]: Datasets dictionary.\n    '')),
      If(test=Name(id=''quiet'', ctx=Load()), body=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
      ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''WARNING'',
      ctx=Load())], keywords=[]))], orelse=[Expr(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''getLogger'', ctx=Load()), args=[], keywords=[]), attr=''setLevel'',
      ctx=Load()), args=[Attribute(value=Name(id=''logging'', ctx=Load()), attr=''INFO'',
      ctx=Load())], keywords=[]))]), Expr(value=Call(func=Attribute(value=Name(id=''sys'',
      ctx=Load()), attr=''setrecursionlimit'', ctx=Load()), args=[Constant(value=3000)],
      keywords=[])), If(test=UnaryOp(op=Not(), operand=Name(id=''start_dir'', ctx=Load())),
      body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()),
      attr=''info'', ctx=Load()), args=[Constant(value=''No valid start path provided.
      Using current working directory.'')], keywords=[])), Assign(targets=[Name(id=''start_dir'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''os'', ctx=Load()),
      attr=''getcwd'', ctx=Load()), args=[], keywords=[]))], orelse=[]), Assign(targets=[Name(id=''start_dir'',
      ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''path'', ctx=Load()), attr=''abspath'', ctx=Load()), args=[Name(id=''start_dir'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''output_dir'', ctx=Store())],
      value=Call(func=Name(id=''get_output_dir'', ctx=Load()), args=[Name(id=''output_dir'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''questions'', ctx=Store())],
      value=Call(func=Name(id=''get_questions'', ctx=Load()), args=[Name(id=''questions_pathname'',
      ctx=Load())], keywords=[])), If(test=Name(id=''single_process'', ctx=Load()),
      body=[Assign(targets=[Name(id=''model_config'', ctx=Store())], value=IfExp(test=Name(id=''use_llm'',
      ctx=Load()), body=Call(func=Name(id=''get_model'', ctx=Load()), args=[Name(id=''model_config_pathname'',
      ctx=Load())], keywords=[]), orelse=Tuple(elts=[Constant(value=None), Constant(value=''''),
      Constant(value=0)], ctx=Load())))], orelse=[]), For(target=Name(id=''pythonfile_path'',
      ctx=Store()), iter=Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()),
      args=[Name(id=''start_dir'', ctx=Load())], keywords=[]), attr=''rglob'', ctx=Load()),
      args=[Constant(value=''[!_]*.py'')], keywords=[]), body=[If(test=Call(func=Attribute(value=Name(id=''pythonfile_path'',
      ctx=Load()), attr=''is_dir'', ctx=Load()), args=[], keywords=[]), body=[Continue()],
      orelse=[]), If(test=Name(id=''single_process'', ctx=Load()), body=[Expr(value=Call(func=Name(id=''process_single_file'',
      ctx=Load()), args=[Name(id=''pythonfile_path'', ctx=Load()), Name(id=''start_dir'',
      ctx=Load()), Name(id=''model_config_pathname'', ctx=Load()), Name(id=''questions'',
      ctx=Load()), Name(id=''use_llm'', ctx=Load()), Name(id=''output_dir'', ctx=Load()),
      Name(id=''model_config'', ctx=Load()), Name(id=''single_process'', ctx=Load())],
      keywords=[])), Continue()], orelse=[]), Assign(targets=[Name(id=''proc'', ctx=Store())],
      value=Call(func=Name(id=''Process'', ctx=Load()), args=[], keywords=[keyword(arg=''target'',
      value=Name(id=''process_single_file'', ctx=Load())), keyword(arg=''args'', value=Tuple(elts=[Name(id=''pythonfile_path'',
      ctx=Load()), Name(id=''start_dir'', ctx=Load()), Name(id=''model_config_pathname'',
      ctx=Load()), Name(id=''questions'', ctx=Load()), Name(id=''use_llm'', ctx=Load()),
      Name(id=''output_dir'', ctx=Load())], ctx=Load()))])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
      ctx=Load()), attr=''start'', ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''proc'',
      ctx=Load()), attr=''join'', ctx=Load()), args=[], keywords=[]))], orelse=[]),
      Assign(targets=[Name(id=''datasets'', ctx=Store())], value=Call(func=Name(id=''combine_json_files'',
      ctx=Load()), args=[Name(id=''output_dir'', ctx=Load())], keywords=[])), Return(value=Name(id=''datasets'',
      ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''Dict'',
      ctx=Load()), slice=Tuple(elts=[Name(id=''str'', ctx=Load()), Subscript(value=Name(id=''List'',
      ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())], ctx=Load()),
      ctx=Load()))'
    function_docstring: "\n    Process Python files to generate question-answer pairs\
      \ and instructions.\n    Args:\n        start_dir (str, optional): Starting\
      \ directory for Python files.\n        Defaults to current working directory.\n\
      \        output_dir (str, optional): Directory to write the output files.\n\
      \        questions_pathname (str, optional): Path to the questions file.\n \
      \       model_config_pathname (str, optional): Path to the model\n        configuration\
      \ file.\n        use_llm (bool, optional): If True, use a Large Language Model\n\
      \        for generating JSON answers. Defaults to False.\n        quiet (bool,\
      \ optional): Limit logging output. Defaults to False.\n        single_process(bool,\
      \ optional): If True, only a single process \n        will be used to process\
      \ Python files. Defaults to False. Set to True to\n        instantiate LLM once\
      \ before processing all files.\n    Returns:\n        Dict[str, List[Dict]]:\
      \ Datasets dictionary.\n    "
    function_inputs:
    - start_dir
    - output_dir
    - questions_pathname
    - model_config_pathname
    - use_llm
    - quiet
    - single_process
    function_defaults:
    - ''''''
    - ''''''
    - ''''''
    - ''''''
    - 'False'
    - 'False'
    - 'False'
    function_returns:
    - datasets
    function_calls:
    - logging.getLogger().setLevel
    - logging.getLogger
    - sys.setrecursionlimit
    - logging.info
    - os.getcwd
    - os.path.abspath
    - get_output_dir
    - get_questions
    - get_model
    - Path(start_dir).rglob
    - Path
    - pythonfile_path.is_dir
    - process_single_file
    - Process
    - proc.start
    - proc.join
    - combine_json_files
    function_call_inputs:
      logging.getLogger().setLevel:
      - logging.INFO
      logging.getLogger: []
      sys.setrecursionlimit:
      - '3000'
      logging.info:
      - '''No valid start path provided. Using current working directory.'''
      os.getcwd: []
      os.path.abspath:
      - start_dir
      get_output_dir:
      - output_dir
      get_questions:
      - questions_pathname
      get_model:
      - model_config_pathname
      Path(start_dir).rglob:
      - '''[!_]*.py'''
      Path:
      - start_dir
      pythonfile_path.is_dir: []
      process_single_file:
      - pythonfile_path
      - start_dir
      - model_config_pathname
      - questions
      - use_llm
      - output_dir
      - model_config
      - single_process
      Process: []
      proc.start: []
      proc.join: []
      combine_json_files:
      - output_dir
    function_variables:
    - model_config
    - proc
    - start_dir
    - datasets
    - questions
    - output_dir
    function_decorators: []
    function_annotations: []
    function_properties: []
  main:
    function_name: main
    function_code: "def main():\n    \"\"\"\n    Command-line entry point for processing\
      \ Python files and generating datasets.\n    \"\"\"\n    arg_string = ' '.join(sys.argv[1:])\n\
      \    start_dir = ''\n    output_dir = ''\n    questions_pathname = ''\n    model_config_pathname\
      \ = ''\n    use_llm = False\n    quiet = False\n    single_process = False\n\
      \    if '--start_dir' in arg_string:\n        start_dir = arg_string.split('--start_dir\
      \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--start_dir\
      \ {start_dir}', '')\n    if '--output_dir' in arg_string:\n        output_dir\
      \ = arg_string.split('--output_dir ')[1].split(' ')[0]\n        arg_string =\
      \ arg_string.replace(f'--output_dir {output_dir}', '')\n    if '--model_config_pathname'\
      \ in arg_string:\n        model_config_pathname = arg_string.split('--model_config_pathname\
      \ ')[1].split(' ')[0]\n        arg_string = arg_string.replace(f'--model_config_pathname\
      \ {model_config_pathname}', '')\n    if '--questions_pathname' in arg_string:\n\
      \        questions_pathname = arg_string.split('--questions_pathname ')[1].split('\
      \ ')[0]\n        arg_string = arg_string.replace(f'--questions_pathname {questions_pathname}',\
      \ '')\n    if '--use_llm' in arg_string:\n        use_llm = True\n        arg_string\
      \ = arg_string.replace('--use_llm', '')\n    if '--quiet' in arg_string:\n \
      \       quiet = True\n        arg_string = arg_string.replace('--quiet', '')\n\
      \    if '--single_process' in arg_string:\n        single_process = True\n \
      \       arg_string = arg_string.replace('--single_process', '')\n    py2dataset(start_dir,\
      \ output_dir, questions_pathname, model_config_pathname, use_llm, quiet, single_process)"
    function_ast: FunctionDef(name='main', args=arguments(posonlyargs=[], args=[],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\n    Command-line
      entry point for processing Python files and generating datasets.\n    ')), Assign(targets=[Name(id='arg_string',
      ctx=Store())], value=Call(func=Attribute(value=Constant(value=' '), attr='join',
      ctx=Load()), args=[Subscript(value=Attribute(value=Name(id='sys', ctx=Load()),
      attr='argv', ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())],
      keywords=[])), Assign(targets=[Name(id='start_dir', ctx=Store())], value=Constant(value='')),
      Assign(targets=[Name(id='output_dir', ctx=Store())], value=Constant(value='')),
      Assign(targets=[Name(id='questions_pathname', ctx=Store())], value=Constant(value='')),
      Assign(targets=[Name(id='model_config_pathname', ctx=Store())], value=Constant(value='')),
      Assign(targets=[Name(id='use_llm', ctx=Store())], value=Constant(value=False)),
      Assign(targets=[Name(id='quiet', ctx=Store())], value=Constant(value=False)),
      Assign(targets=[Name(id='single_process', ctx=Store())], value=Constant(value=False)),
      If(test=Compare(left=Constant(value='--start_dir'), ops=[In()], comparators=[Name(id='arg_string',
      ctx=Load())]), body=[Assign(targets=[Name(id='start_dir', ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='split', ctx=Load()), args=[Constant(value='--start_dir ')],
      keywords=[]), slice=Constant(value=1), ctx=Load()), attr='split', ctx=Load()),
      args=[Constant(value=' ')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id='arg_string', ctx=Store())], value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='replace', ctx=Load()), args=[JoinedStr(values=[Constant(value='--start_dir
      '), FormattedValue(value=Name(id='start_dir', ctx=Load()), conversion=-1)]),
      Constant(value='')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value='--output_dir'),
      ops=[In()], comparators=[Name(id='arg_string', ctx=Load())]), body=[Assign(targets=[Name(id='output_dir',
      ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='split', ctx=Load()), args=[Constant(value='--output_dir ')],
      keywords=[]), slice=Constant(value=1), ctx=Load()), attr='split', ctx=Load()),
      args=[Constant(value=' ')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id='arg_string', ctx=Store())], value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='replace', ctx=Load()), args=[JoinedStr(values=[Constant(value='--output_dir
      '), FormattedValue(value=Name(id='output_dir', ctx=Load()), conversion=-1)]),
      Constant(value='')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value='--model_config_pathname'),
      ops=[In()], comparators=[Name(id='arg_string', ctx=Load())]), body=[Assign(targets=[Name(id='model_config_pathname',
      ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='split', ctx=Load()), args=[Constant(value='--model_config_pathname
      ')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr='split', ctx=Load()),
      args=[Constant(value=' ')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id='arg_string', ctx=Store())], value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='replace', ctx=Load()), args=[JoinedStr(values=[Constant(value='--model_config_pathname
      '), FormattedValue(value=Name(id='model_config_pathname', ctx=Load()), conversion=-1)]),
      Constant(value='')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value='--questions_pathname'),
      ops=[In()], comparators=[Name(id='arg_string', ctx=Load())]), body=[Assign(targets=[Name(id='questions_pathname',
      ctx=Store())], value=Subscript(value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='split', ctx=Load()), args=[Constant(value='--questions_pathname
      ')], keywords=[]), slice=Constant(value=1), ctx=Load()), attr='split', ctx=Load()),
      args=[Constant(value=' ')], keywords=[]), slice=Constant(value=0), ctx=Load())),
      Assign(targets=[Name(id='arg_string', ctx=Store())], value=Call(func=Attribute(value=Name(id='arg_string',
      ctx=Load()), attr='replace', ctx=Load()), args=[JoinedStr(values=[Constant(value='--questions_pathname
      '), FormattedValue(value=Name(id='questions_pathname', ctx=Load()), conversion=-1)]),
      Constant(value='')], keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value='--use_llm'),
      ops=[In()], comparators=[Name(id='arg_string', ctx=Load())]), body=[Assign(targets=[Name(id='use_llm',
      ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id='arg_string',
      ctx=Store())], value=Call(func=Attribute(value=Name(id='arg_string', ctx=Load()),
      attr='replace', ctx=Load()), args=[Constant(value='--use_llm'), Constant(value='')],
      keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value='--quiet'),
      ops=[In()], comparators=[Name(id='arg_string', ctx=Load())]), body=[Assign(targets=[Name(id='quiet',
      ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id='arg_string',
      ctx=Store())], value=Call(func=Attribute(value=Name(id='arg_string', ctx=Load()),
      attr='replace', ctx=Load()), args=[Constant(value='--quiet'), Constant(value='')],
      keywords=[]))], orelse=[]), If(test=Compare(left=Constant(value='--single_process'),
      ops=[In()], comparators=[Name(id='arg_string', ctx=Load())]), body=[Assign(targets=[Name(id='single_process',
      ctx=Store())], value=Constant(value=True)), Assign(targets=[Name(id='arg_string',
      ctx=Store())], value=Call(func=Attribute(value=Name(id='arg_string', ctx=Load()),
      attr='replace', ctx=Load()), args=[Constant(value='--single_process'), Constant(value='')],
      keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id='py2dataset', ctx=Load()),
      args=[Name(id='start_dir', ctx=Load()), Name(id='output_dir', ctx=Load()), Name(id='questions_pathname',
      ctx=Load()), Name(id='model_config_pathname', ctx=Load()), Name(id='use_llm',
      ctx=Load()), Name(id='quiet', ctx=Load()), Name(id='single_process', ctx=Load())],
      keywords=[]))], decorator_list=[])
    function_docstring: "\n    Command-line entry point for processing Python files\
      \ and generating datasets.\n    "
    function_inputs: []
    function_defaults: []
    function_returns: []
    function_calls:
    - ''' ''.join'
    - arg_string.split('--start_dir ')[1].split
    - arg_string.split
    - arg_string.replace
    - arg_string.split('--output_dir ')[1].split
    - arg_string.split('--model_config_pathname ')[1].split
    - arg_string.split('--questions_pathname ')[1].split
    - py2dataset
    function_call_inputs:
      ''' ''.join':
      - sys.argv[1:]
      arg_string.split('--start_dir ')[1].split:
      - ''' '''
      arg_string.split:
      - '''--questions_pathname '''
      arg_string.replace:
      - '''--single_process'''
      - ''''''
      arg_string.split('--output_dir ')[1].split:
      - ''' '''
      arg_string.split('--model_config_pathname ')[1].split:
      - ''' '''
      arg_string.split('--questions_pathname ')[1].split:
      - ''' '''
      py2dataset:
      - start_dir
      - output_dir
      - questions_pathname
      - model_config_pathname
      - use_llm
      - quiet
      - single_process
    function_variables:
    - arg_string
    - model_config_pathname
    - start_dir
    - quiet
    - single_process
    - output_dir
    - questions_pathname
    - use_llm
    function_decorators: []
    function_annotations: []
    function_properties: []
classes: {}
