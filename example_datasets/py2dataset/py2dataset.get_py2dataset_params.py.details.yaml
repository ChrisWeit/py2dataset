file_info:
  file_code: "\"\"\"\nObtain data parameter and model from the py2dataset functions.\n\
    Requirements:\n[req01] The `get_default_questions` function shall:\n        a.\
    \ Return a list of default questions.\n        b. Ensure each question in the\
    \ list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text,\
    \ and type.\n[req02] The `get_default_model_config` function shall:\n        a.\
    \ Return a dictionary representing the default model configuration.\n[req03] The\
    \ `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n\
    \        b. Return the absolute path of the provided output_dir if it exists or\
    \ can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir\
    \ argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n\
    \        a. Accept an optional questions_pathname argument.\n        b. Validate\
    \ the question file provided by the questions_pathname.\n        c. Return the\
    \ questions from the provided questions_pathname if valid.\n        d. Return\
    \ default questions if the questions_pathname is not provided or invalid.\n[req05]\
    \ The `instantiate_model` function shall:\n        a. Accept a model_config dictionary\
    \ as an argument.\n        b. Import the specified module and class from the model_config.\n\
    \        c. Instantiate and return the model using the provided configuration.\n\
    [req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname\
    \ argument.\n        b. Validate the model config file provided by the model_config_pathname.\n\
    \        c. Return an instantiated model and a prompt template based on the provided\
    \ configuration.\n        d. Return an instantiated model and a prompt template\
    \ based on the default model configuration if the model_config_pathname is not\
    \ provided or invalid.\n[req07] The `write_questions_file` function shall:\n \
    \       a. Accept an optional output_dir argument.\n        b. Write the default\
    \ questions to the QUESTIONS_FILE in the specified directory.\n        c. Write\
    \ the default questions to the QUESTIONS_FILE in the current working directory\
    \ if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file`\
    \ function shall:\n        a. Accept an optional output_dir argument.\n      \
    \  b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified\
    \ directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE\
    \ in the current working directory if the output_dir argument is not provided\
    \ or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport yaml\nimport\
    \ importlib\nfrom typing import Dict, List \nfrom pathlib import Path\nfrom transformers\
    \ import AutoTokenizer\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\
    \nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\n\
    OUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\
    \"Return default question list\n    Args:\n        None\n    Returns:\n      \
    \  List[Dict]: The default question list\n    \"\"\"\n    questions = [\n    \
    \    {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies\
    \ of Python file: '{filename}'?\",\n            \"type\": \"file\"\n        },\n\
    \        {\n            \"id\": \"entire_code_graph\",\n            \"text\":\
    \ \"Call code graph of Python file: '{filename}'?\",\n            \"type\": \"\
    file\"\n        },\n        {\n            \"id\": \"file_functions\",\n     \
    \       \"text\": \"Functions defined in Python file: '{filename}'?\",\n     \
    \       \"type\": \"file\"\n        },      \n        {\n            \"id\": \"\
    file_classes\",\n            \"text\": \"Classes defined in Python file: '{filename}'?\"\
    ,\n            \"type\": \"file\"\n        },\n        {\n            \"id\":\
    \ \"function_inputs\",\n            \"text\": \"Inputs to function: '{function_name}'\
    \ in Python file: '{filename}'?\",\n            \"type\": \"function\"\n     \
    \   },\n        {\n            \"id\": \"function_docstring\",\n            \"\
    text\": \"Docstring of function: '{function_name}' in Python file: '{filename}'?\"\
    ,\n            \"type\": \"function\"\n        },\n        {\n            \"id\"\
    : \"function_calls\",\n            \"text\": \"Calls made in function: '{function_name}'\
    \ in Python file: '{filename}'?\",\n            \"type\": \"function\"\n     \
    \   },\n        {\n            \"id\": \"function_variables\",\n            \"\
    text\": \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\"\
    ,\n            \"type\": \"function\"\n        }, \n        {\n            \"\
    id\": \"function_returns\",\n            \"text\": \"Returned items from function:\
    \ '{function_name}' in Python file: '{filename}'?\",\n            \"type\": \"\
    function\"\n        },\n        {\n            \"id\": \"class_methods\",\n  \
    \          \"text\": \"Methods defined in class: '{class_name}' in Python file:\
    \ '{filename}'?\",\n            \"type\": \"class\"\n        },\n        {\n \
    \           \"id\": \"class_docstring\",\n            \"text\": \"Docstring of\
    \ class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\"\
    : \"class\"\n        },\n        {\n            \"id\": \"class_attributes\",\n\
    \            \"text\": \"Attributes of class: '{class_name}' in Python file: '{filename}'?\"\
    ,\n            \"type\": \"class\"\n        },\n        {\n            \"id\"\
    : \"class_variables\",\n            \"text\": \"Variables defined in class: '{class_name}'\
    \ in Python file: '{filename}'?\",\n            \"type\": \"class\"\n        },\n\
    \        {\n            \"id\": \"class_inheritance\",\n            \"text\":\
    \ \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\",\n  \
    \          \"type\": \"class\"\n        },\n        {\n            \"id\": \"\
    method_inputs\",\n            \"text\": \"Inputs to method: '{method_name}' in\
    \ class: '{class_name}' in Python file: '{filename}'?\",\n            \"type\"\
    : \"method\"\n        },\n        {\n            \"id\": \"method_docstring\"\
    ,\n            \"text\": \"Docstring of method: '{method_name}' in class: '{class_name}'\
    \ in Python file: '{filename}'?\",\n            \"type\": \"method\"\n       \
    \ },\n        {\n            \"id\": \"method_calls\",\n            \"text\":\
    \ \"Calls made in method: '{method_name}' in class: '{class_name}' in Python file:\
    \ '{filename}'?\",\n            \"type\": \"method\"\n        },\n        {\n\
    \            \"id\": \"method_returns\",\n            \"text\": \"Returns from\
    \ method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\"\
    ,\n            \"type\": \"method\"\n        },\n        {   \n            \"\
    id\": \"file_purpose\",\n            \"text\": \"1) DESCRIBE the purpose and processing\
    \ summary of Python file: '{filename}'; 2) PROVIDE an itemized and detailed description\
    \ of each applicable function, class, and method; 3) EXPLAIN what each input,\
    \ output, and variable does in the code.\",\n            \"type\": \"file\"\n\
    \        } \n    ]\n    return questions\n\n\ndef get_default_model_config() ->\
    \ Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n\
    \    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n\
    \    model_config = {\n        \"prompt_template\": \"\\n### Instruction:\\nGiven\
    \ this context:\\n'{context}'\\nPlease analyze this code you created provide a\
    \ comprehensive response without duplicating the input code, include enough detail\
    \ for me to implement the same logic, and include your reasoning step by step:\
    \ {query}\\n### Response:\",\n        \"inference_model\": {\n            \"model_import_path\"\
    : \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\"\
    : \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\"\
    : \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",  \n                \"model_type\"\
    : \"llama\",\n                \"local_files_only\": False,\n                ##\
    \ MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads,\
    \ 64GB RAM)\n                #avx2 and gpu_layers are not compatible \n      \
    \          #\"lib\": \"avx2\",\n                \"threads\": 28,\n           \
    \     \"batch_size\": 128,\n                \"context_length\": 14000,\n     \
    \           \"max_new_tokens\": 8092,\n                \"gpu_layers\": 100,\n\
    \                \"reset\": True\n                }\n            }\n        }\n\
    \    return model_config\n\n\ndef get_output_dir(output_dir: str='') -> str:\n\
    \    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir\
    \ (str): The directory to write the output to.\n    Returns:\n        str: The\
    \ absolute path of the provided output_dir if it exists or can be created.\n \
    \   \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir,\
    \ exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n\
    \    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n\
    \    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname\
    \ (str): The pathname of the questions file\n    Returns:\n        List[Dict]:\
    \ The list of questions\n    \"\"\"\n    try: # get questions from provided or\
    \ default configuration file\n        if not questions_pathname:\n           \
    \ questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with\
    \ open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n\
    \        logging.info(f'Using questions from file: {questions_pathname}')\n  \
    \  except: # get default questions if can't read questions_pathname file \n  \
    \      logging.info(f'Questions file not valid: {questions_pathname} Using default\
    \ questions')\n        questions = get_default_questions()\n    return questions\n\
    \n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports\
    \ and instantiates a model based on the provided configuration.\n    Args:\n \
    \       model_config (dict): model configuration dictionary.\n    Returns:\n \
    \       object: An instance of the specified model class, or None if error.\n\
    \    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.',\
    \ 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n\
    \        model_params = model_config['model_params']\n        model_path = model_params['model_path']\n\
    \        inference_function_name = model_config['model_inference_function']\n\
    \        if inference_function_name != \"\": \n            inference_function\
    \ = getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'),\
    \ **model_params)\n        else: \n            model = ModelClass(model_params.pop('model_path'),\
    \ **model_params)\n        return model\n    except ImportError or AttributeError\
    \ or Exception as e:\n        logging.info(f\"Failed to instantiate the model.\
    \ Error: {e}\")    \n        return None, None\n\n\ndef get_model(model_config_pathname:\
    \ str) -> tuple[object, str]:\n    \"\"\"\n    Returns an instantiated model and\
    \ prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname\
    \ (str): The pathname of the model config file\n    Returns:\n        Tuple[object,\
    \ str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n  \
    \      if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(),\
    \ MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n\
    \            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using\
    \ model config from file: {model_config_pathname}')\n    except:\n        logging.info(f'Model\
    \ config file not valid: {model_config_pathname} Using default model config')\n\
    \        model_config = get_default_model_config()\n    model_config['model']\
    \ = instantiate_model(model_config['inference_model'])\n    return model_config\n\
    \n\ndef write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes\
    \ the default questions to a file in JSON format.\n    Args:\n        output_dir\
    \ (str): The directory to write the questions file to.\n    Returns:\n       \
    \ None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir =\
    \ output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n  \
    \  with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n       \
    \ json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir:\
    \ str='') -> None:\n    \"\"\"\n    Writes the default model config to a file\
    \ in YAML format.\n    Args:\n        output_dir (str): The directory to write\
    \ the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config\
    \ = get_default_model_config()\n    output_dir = output_dir if output_dir and\
    \ Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir,\
    \ MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)\n"
  file_ast: 'Module(body=[Expr(value=Constant(value=''\nObtain data parameter and
    model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions`
    function shall:\n        a. Return a list of default questions.\n        b. Ensure
    each question in the list is a dictionary.\n        c. Ensure each dictionary
    has the keys: id, text, and type.\n[req02] The `get_default_model_config` function
    shall:\n        a. Return a dictionary representing the default model configuration.\n[req03]
    The `get_output_dir` function shall:\n        a. Accept an optional output_dir
    argument.\n        b. Return the absolute path of the provided output_dir if it
    exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided
    output_dir argument is not provided or invalid.\n[req04] The `get_questions` function
    shall:\n        a. Accept an optional questions_pathname argument.\n        b.
    Validate the question file provided by the questions_pathname.\n        c. Return
    the questions from the provided questions_pathname if valid.\n        d. Return
    default questions if the questions_pathname is not provided or invalid.\n[req05]
    The `instantiate_model` function shall:\n        a. Accept a model_config dictionary
    as an argument.\n        b. Import the specified module and class from the model_config.\n        c.
    Instantiate and return the model using the provided configuration.\n[req06] The
    `get_model` function shall:\n        a. Accept an optional model_config_pathname
    argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c.
    Return an instantiated model and a prompt template based on the provided configuration.\n        d.
    Return an instantiated model and a prompt template based on the default model
    configuration if the model_config_pathname is not provided or invalid.\n[req07]
    The `write_questions_file` function shall:\n        a. Accept an optional output_dir
    argument.\n        b. Write the default questions to the QUESTIONS_FILE in the
    specified directory.\n        c. Write the default questions to the QUESTIONS_FILE
    in the current working directory if the output_dir argument is not provided or
    invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept
    an optional output_dir argument.\n        b. Write the default model configuration
    to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default
    model configuration to the MODEL_CONFIG_FILE in the current working directory
    if the output_dir argument is not provided or invalid.\n'')), Import(names=[alias(name=''os'')]),
    Import(names=[alias(name=''json'')]), Import(names=[alias(name=''logging'')]),
    Import(names=[alias(name=''yaml'')]), Import(names=[alias(name=''importlib'')]),
    ImportFrom(module=''typing'', names=[alias(name=''Dict''), alias(name=''List'')],
    level=0), ImportFrom(module=''pathlib'', names=[alias(name=''Path'')], level=0),
    ImportFrom(module=''transformers'', names=[alias(name=''AutoTokenizer'')], level=0),
    Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()), attr=''basicConfig'',
    ctx=Load()), args=[], keywords=[keyword(arg=''level'', value=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''INFO'', ctx=Load()))])), Assign(targets=[Name(id=''QUESTIONS_FILE'',
    ctx=Store())], value=Constant(value=''py2dataset_questions.json'')), Assign(targets=[Name(id=''MODEL_CONFIG_FILE'',
    ctx=Store())], value=Constant(value=''py2dataset_model_config.yaml'')), Assign(targets=[Name(id=''OUTPUT_DIR'',
    ctx=Store())], value=Constant(value=''datasets'')), FunctionDef(name=''get_default_questions'',
    args=arguments(posonlyargs=[], args=[], kwonlyargs=[], kw_defaults=[], defaults=[]),
    body=[Expr(value=Constant(value=''Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]:
    The default question list\n    '')), Assign(targets=[Name(id=''questions'', ctx=Store())],
    value=List(elts=[Dict(keys=[Constant(value=''id''), Constant(value=''text''),
    Constant(value=''type'')], values=[Constant(value=''file_dependencies''), Constant(value="Dependencies
    of Python file: ''{filename}''?"), Constant(value=''file'')]), Dict(keys=[Constant(value=''id''),
    Constant(value=''text''), Constant(value=''type'')], values=[Constant(value=''entire_code_graph''),
    Constant(value="Call code graph of Python file: ''{filename}''?"), Constant(value=''file'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''file_functions''), Constant(value="Functions defined
    in Python file: ''{filename}''?"), Constant(value=''file'')]), Dict(keys=[Constant(value=''id''),
    Constant(value=''text''), Constant(value=''type'')], values=[Constant(value=''file_classes''),
    Constant(value="Classes defined in Python file: ''{filename}''?"), Constant(value=''file'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''function_inputs''), Constant(value="Inputs to function:
    ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''function_docstring''), Constant(value="Docstring of function:
    ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''function_calls''), Constant(value="Calls made in function:
    ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''function_variables''), Constant(value="Variables defined
    in function: ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''function_returns''), Constant(value="Returned items from
    function: ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''class_methods''), Constant(value="Methods defined in
    class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''class_docstring''), Constant(value="Docstring of class:
    ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''class_attributes''), Constant(value="Attributes of class:
    ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''class_variables''), Constant(value="Variables defined
    in class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''class_inheritance''), Constant(value="Inheritance of
    class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''method_inputs''), Constant(value="Inputs to method: ''{method_name}''
    in class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''method'')]),
    Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
    values=[Constant(value=''method_docstring''), Constant(value="Docstring of method:
    ''{method_name}'' in class: ''{class_name}'' in Python file: ''{filename}''?"),
    Constant(value=''method'')]), Dict(keys=[Constant(value=''id''), Constant(value=''text''),
    Constant(value=''type'')], values=[Constant(value=''method_calls''), Constant(value="Calls
    made in method: ''{method_name}'' in class: ''{class_name}'' in Python file: ''{filename}''?"),
    Constant(value=''method'')]), Dict(keys=[Constant(value=''id''), Constant(value=''text''),
    Constant(value=''type'')], values=[Constant(value=''method_returns''), Constant(value="Returns
    from method: ''{method_name}'' in class: ''{class_name}'' in Python file: ''{filename}''?"),
    Constant(value=''method'')]), Dict(keys=[Constant(value=''id''), Constant(value=''text''),
    Constant(value=''type'')], values=[Constant(value=''file_purpose''), Constant(value="1)
    DESCRIBE the purpose and processing summary of Python file: ''{filename}''; 2)
    PROVIDE an itemized and detailed description of each applicable function, class,
    and method; 3) EXPLAIN what each input, output, and variable does in the code."),
    Constant(value=''file'')])], ctx=Load())), Return(value=Name(id=''questions'',
    ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''List'', ctx=Load()),
    slice=Name(id=''Dict'', ctx=Load()), ctx=Load())), FunctionDef(name=''get_default_model_config'',
    args=arguments(posonlyargs=[], args=[], kwonlyargs=[], kw_defaults=[], defaults=[]),
    body=[Expr(value=Constant(value=''Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict:
    The default model config dictionary\n    '')), Assign(targets=[Name(id=''model_config'',
    ctx=Store())], value=Dict(keys=[Constant(value=''prompt_template''), Constant(value=''inference_model'')],
    values=[Constant(value="\n### Instruction:\nGiven this context:\n''{context}''\nPlease
    analyze this code you created provide a comprehensive response without duplicating
    the input code, include enough detail for me to implement the same logic, and
    include your reasoning step by step: {query}\n### Response:"), Dict(keys=[Constant(value=''model_import_path''),
    Constant(value=''model_inference_function''), Constant(value=''model_params'')],
    values=[Constant(value=''ctransformers.AutoModelForCausalLM''), Constant(value=''from_pretrained''),
    Dict(keys=[Constant(value=''model_path''), Constant(value=''model_type''), Constant(value=''local_files_only''),
    Constant(value=''threads''), Constant(value=''batch_size''), Constant(value=''context_length''),
    Constant(value=''max_new_tokens''), Constant(value=''gpu_layers''), Constant(value=''reset'')],
    values=[Constant(value=''TheBloke/WizardCoder-Python-13B-V1.0-GGUF''), Constant(value=''llama''),
    Constant(value=False), Constant(value=28), Constant(value=128), Constant(value=14000),
    Constant(value=8092), Constant(value=100), Constant(value=True)])])])), Return(value=Name(id=''model_config'',
    ctx=Load()))], decorator_list=[], returns=Name(id=''Dict'', ctx=Load())), FunctionDef(name=''get_output_dir'',
    args=arguments(posonlyargs=[], args=[arg(arg=''output_dir'', annotation=Name(id=''str'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value='''')]),
    body=[Expr(value=Constant(value=''Returns the appropriate output directory.\n    Args:\n        output_dir
    (str): The directory to write the output to.\n    Returns:\n        str: The absolute
    path of the provided output_dir if it exists or can be created.\n    '')), Assign(targets=[Name(id=''output_dir'',
    ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''path'', ctx=Load()), attr=''abspath'', ctx=Load()), args=[BoolOp(op=Or(),
    values=[Name(id=''output_dir'', ctx=Load()), Name(id=''OUTPUT_DIR'', ctx=Load())])],
    keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''os'', ctx=Load()),
    attr=''makedirs'', ctx=Load()), args=[Name(id=''output_dir'', ctx=Load())], keywords=[keyword(arg=''exist_ok'',
    value=Constant(value=True))])), Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Using
    output directory: ''), FormattedValue(value=Name(id=''output_dir'', ctx=Load()),
    conversion=-1)])], keywords=[])), Return(value=Name(id=''output_dir'', ctx=Load()))],
    decorator_list=[], returns=Name(id=''str'', ctx=Load())), FunctionDef(name=''get_questions'',
    args=arguments(posonlyargs=[], args=[arg(arg=''questions_pathname'', annotation=Name(id=''str'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Get
    questions from file or default\n    Args:\n        questions_pathname (str): The
    pathname of the questions file\n    Returns:\n        List[Dict]: The list of
    questions\n    '')), Try(body=[If(test=UnaryOp(op=Not(), operand=Name(id=''questions_pathname'',
    ctx=Load())), body=[Assign(targets=[Name(id=''questions_pathname'', ctx=Store())],
    value=Call(func=Attribute(value=Attribute(value=Name(id=''os'', ctx=Load()), attr=''path'',
    ctx=Load()), attr=''join'', ctx=Load()), args=[Call(func=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]), Name(id=''QUESTIONS_FILE'',
    ctx=Load())], keywords=[]))], orelse=[]), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
    ctx=Load()), args=[Name(id=''questions_pathname'', ctx=Load()), Constant(value=''r'')],
    keywords=[]), optional_vars=Name(id=''f'', ctx=Store()))], body=[Assign(targets=[Name(id=''questions'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''json'', ctx=Load()),
    attr=''load'', ctx=Load()), args=[Name(id=''f'', ctx=Load())], keywords=[]))]),
    Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()), attr=''info'',
    ctx=Load()), args=[JoinedStr(values=[Constant(value=''Using questions from file:
    ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()), conversion=-1)])],
    keywords=[]))], handlers=[ExceptHandler(body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Questions
    file not valid: ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()),
    conversion=-1), Constant(value='' Using default questions'')])], keywords=[])),
    Assign(targets=[Name(id=''questions'', ctx=Store())], value=Call(func=Name(id=''get_default_questions'',
    ctx=Load()), args=[], keywords=[]))])], orelse=[], finalbody=[]), Return(value=Name(id=''questions'',
    ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''List'', ctx=Load()),
    slice=Name(id=''Dict'', ctx=Load()), ctx=Load())), FunctionDef(name=''instantiate_model'',
    args=arguments(posonlyargs=[], args=[arg(arg=''model_config'', annotation=Name(id=''Dict'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Imports
    and instantiates a model based on the provided configuration.\n    Args:\n        model_config
    (dict): model configuration dictionary.\n    Returns:\n        object: An instance
    of the specified model class, or None if error.\n    '')), Try(body=[Assign(targets=[Tuple(elts=[Name(id=''module_name'',
    ctx=Store()), Name(id=''class_name'', ctx=Store())], ctx=Store())], value=Call(func=Attribute(value=Subscript(value=Name(id=''model_config'',
    ctx=Load()), slice=Constant(value=''model_import_path''), ctx=Load()), attr=''rsplit'',
    ctx=Load()), args=[Constant(value=''.''), Constant(value=1)], keywords=[])), Assign(targets=[Name(id=''ModelClass'',
    ctx=Store())], value=Call(func=Name(id=''getattr'', ctx=Load()), args=[Call(func=Attribute(value=Name(id=''importlib'',
    ctx=Load()), attr=''import_module'', ctx=Load()), args=[Name(id=''module_name'',
    ctx=Load())], keywords=[]), Name(id=''class_name'', ctx=Load())], keywords=[])),
    Assign(targets=[Name(id=''model_params'', ctx=Store())], value=Subscript(value=Name(id=''model_config'',
    ctx=Load()), slice=Constant(value=''model_params''), ctx=Load())), Assign(targets=[Name(id=''model_path'',
    ctx=Store())], value=Subscript(value=Name(id=''model_params'', ctx=Load()), slice=Constant(value=''model_path''),
    ctx=Load())), Assign(targets=[Name(id=''inference_function_name'', ctx=Store())],
    value=Subscript(value=Name(id=''model_config'', ctx=Load()), slice=Constant(value=''model_inference_function''),
    ctx=Load())), If(test=Compare(left=Name(id=''inference_function_name'', ctx=Load()),
    ops=[NotEq()], comparators=[Constant(value='''')]), body=[Assign(targets=[Name(id=''inference_function'',
    ctx=Store())], value=Call(func=Name(id=''getattr'', ctx=Load()), args=[Name(id=''ModelClass'',
    ctx=Load()), Name(id=''inference_function_name'', ctx=Load())], keywords=[])),
    Assign(targets=[Name(id=''model'', ctx=Store())], value=Call(func=Name(id=''inference_function'',
    ctx=Load()), args=[Call(func=Attribute(value=Name(id=''model_params'', ctx=Load()),
    attr=''pop'', ctx=Load()), args=[Constant(value=''model_path'')], keywords=[])],
    keywords=[keyword(value=Name(id=''model_params'', ctx=Load()))]))], orelse=[Assign(targets=[Name(id=''model'',
    ctx=Store())], value=Call(func=Name(id=''ModelClass'', ctx=Load()), args=[Call(func=Attribute(value=Name(id=''model_params'',
    ctx=Load()), attr=''pop'', ctx=Load()), args=[Constant(value=''model_path'')],
    keywords=[])], keywords=[keyword(value=Name(id=''model_params'', ctx=Load()))]))]),
    Return(value=Name(id=''model'', ctx=Load()))], handlers=[ExceptHandler(type=BoolOp(op=Or(),
    values=[Name(id=''ImportError'', ctx=Load()), Name(id=''AttributeError'', ctx=Load()),
    Name(id=''Exception'', ctx=Load())]), name=''e'', body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Failed
    to instantiate the model. Error: ''), FormattedValue(value=Name(id=''e'', ctx=Load()),
    conversion=-1)])], keywords=[])), Return(value=Tuple(elts=[Constant(value=None),
    Constant(value=None)], ctx=Load()))])], orelse=[], finalbody=[])], decorator_list=[],
    returns=Name(id=''object'', ctx=Load())), FunctionDef(name=''get_model'', args=arguments(posonlyargs=[],
    args=[arg(arg=''model_config_pathname'', annotation=Name(id=''str'', ctx=Load()))],
    kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Returns
    an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname
    (str): The pathname of the model config file\n    Returns:\n        Tuple[object,
    str]: The instantiated model and prompt template \n    '')), Try(body=[If(test=UnaryOp(op=Not(),
    operand=Name(id=''model_config_pathname'', ctx=Load())), body=[Assign(targets=[Name(id=''model_config_pathname'',
    ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''path'', ctx=Load()), attr=''join'', ctx=Load()), args=[Call(func=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]), Name(id=''MODEL_CONFIG_FILE'',
    ctx=Load())], keywords=[]))], orelse=[]), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
    ctx=Load()), args=[Name(id=''model_config_pathname'', ctx=Load()), Constant(value=''r'')],
    keywords=[]), optional_vars=Name(id=''config_file'', ctx=Store()))], body=[Assign(targets=[Name(id=''model_config'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''yaml'', ctx=Load()),
    attr=''safe_load'', ctx=Load()), args=[Name(id=''config_file'', ctx=Load())],
    keywords=[]))]), Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()),
    attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Using model
    config from file: ''), FormattedValue(value=Name(id=''model_config_pathname'',
    ctx=Load()), conversion=-1)])], keywords=[]))], handlers=[ExceptHandler(body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Model
    config file not valid: ''), FormattedValue(value=Name(id=''model_config_pathname'',
    ctx=Load()), conversion=-1), Constant(value='' Using default model config'')])],
    keywords=[])), Assign(targets=[Name(id=''model_config'', ctx=Store())], value=Call(func=Name(id=''get_default_model_config'',
    ctx=Load()), args=[], keywords=[]))])], orelse=[], finalbody=[]), Assign(targets=[Subscript(value=Name(id=''model_config'',
    ctx=Load()), slice=Constant(value=''model''), ctx=Store())], value=Call(func=Name(id=''instantiate_model'',
    ctx=Load()), args=[Subscript(value=Name(id=''model_config'', ctx=Load()), slice=Constant(value=''inference_model''),
    ctx=Load())], keywords=[])), Return(value=Name(id=''model_config'', ctx=Load()))],
    decorator_list=[], returns=Subscript(value=Name(id=''tuple'', ctx=Load()), slice=Tuple(elts=[Name(id=''object'',
    ctx=Load()), Name(id=''str'', ctx=Load())], ctx=Load()), ctx=Load())), FunctionDef(name=''write_questions_file'',
    args=arguments(posonlyargs=[], args=[arg(arg=''output_dir'', annotation=Name(id=''str'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value='''')]),
    body=[Expr(value=Constant(value=''\n    Writes the default questions to a file
    in JSON format.\n    Args:\n        output_dir (str): The directory to write the
    questions file to.\n    Returns:\n        None\n    '')), Assign(targets=[Name(id=''questions'',
    ctx=Store())], value=Call(func=Name(id=''get_default_questions'', ctx=Load()),
    args=[], keywords=[])), Assign(targets=[Name(id=''output_dir'', ctx=Store())],
    value=IfExp(test=BoolOp(op=And(), values=[Name(id=''output_dir'', ctx=Load()),
    Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load())], keywords=[]), attr=''is_dir'', ctx=Load()), args=[], keywords=[])]),
    body=Name(id=''output_dir'', ctx=Load()), orelse=Call(func=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]))), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
    ctx=Load()), args=[Call(func=Attribute(value=Attribute(value=Name(id=''os'', ctx=Load()),
    attr=''path'', ctx=Load()), attr=''join'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load()), Name(id=''QUESTIONS_FILE'', ctx=Load())], keywords=[]), Constant(value=''w'')],
    keywords=[]), optional_vars=Name(id=''file'', ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id=''json'',
    ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''questions'', ctx=Load()),
    Name(id=''file'', ctx=Load())], keywords=[keyword(arg=''indent'', value=Constant(value=4))]))])],
    decorator_list=[], returns=Constant(value=None)), FunctionDef(name=''write_model_config_file'',
    args=arguments(posonlyargs=[], args=[arg(arg=''output_dir'', annotation=Name(id=''str'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value='''')]),
    body=[Expr(value=Constant(value=''\n    Writes the default model config to a file
    in YAML format.\n    Args:\n        output_dir (str): The directory to write the
    model config file to.\n    Returns:\n        None\n    '')), Assign(targets=[Name(id=''model_config'',
    ctx=Store())], value=Call(func=Name(id=''get_default_model_config'', ctx=Load()),
    args=[], keywords=[])), Assign(targets=[Name(id=''output_dir'', ctx=Store())],
    value=IfExp(test=BoolOp(op=And(), values=[Name(id=''output_dir'', ctx=Load()),
    Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load())], keywords=[]), attr=''is_dir'', ctx=Load()), args=[], keywords=[])]),
    body=Name(id=''output_dir'', ctx=Load()), orelse=Call(func=Attribute(value=Name(id=''os'',
    ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]))), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
    ctx=Load()), args=[Call(func=Attribute(value=Attribute(value=Name(id=''os'', ctx=Load()),
    attr=''path'', ctx=Load()), attr=''join'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load()), Name(id=''MODEL_CONFIG_FILE'', ctx=Load())], keywords=[]), Constant(value=''w'')],
    keywords=[]), optional_vars=Name(id=''file'', ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id=''yaml'',
    ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''model_config'', ctx=Load()),
    Name(id=''file'', ctx=Load())], keywords=[]))])], decorator_list=[], returns=Constant(value=None))],
    type_ignores=[])'
  file_dependencies:
  - pathlib
  - yaml
  - json
  - typing
  - transformers
  - importlib
  - logging
  - os
  file_functions:
  - get_default_questions
  - get_default_model_config
  - get_output_dir
  - get_questions
  - instantiate_model
  - get_model
  - write_questions_file
  - write_model_config_file
  file_classes: []
  file_summary: '{dependencies: [pathlib, yaml, json, typing, transformers, importlib,
    logging, os], function_defs: [{get_default_questions: {inputs: [], calls: [],
    call_inputs: {}, returns: [questions]}}, {get_default_model_config: {inputs: [],
    calls: [], call_inputs: {}, returns: [model_config]}}, {get_output_dir: {inputs:
    [output_dir], calls: [os.path.abspath, os.makedirs, logging.info], call_inputs:
    {os.path.abspath: [output_dir or OUTPUT_DIR], os.makedirs: [output_dir], logging.info:
    [f''Using output directory: {output_dir}'']}, returns: [output_dir]}}, {get_questions:
    {inputs: [questions_pathname], calls: [os.path.join, os.getcwd, open, json.load,
    logging.info, get_default_questions], call_inputs: {os.path.join: [os.getcwd(),
    QUESTIONS_FILE], os.getcwd: [], open: [questions_pathname, ''r''], json.load:
    [f], logging.info: [f''Questions file not valid: {questions_pathname} Using default
    questions''], get_default_questions: []}, returns: [questions]}}, {instantiate_model:
    {inputs: [model_config], calls: [model_config[''model_import_path''].rsplit, getattr,
    importlib.import_module, inference_function, model_params.pop, ModelClass, logging.info],
    call_inputs: {model_config[''model_import_path''].rsplit: [''.'', 1], getattr:
    [ModelClass, inference_function_name], importlib.import_module: [module_name],
    inference_function: [model_params.pop(''model_path'')], model_params.pop: [''model_path''],
    ModelClass: [model_params.pop(''model_path'')], logging.info: [f''Failed to instantiate
    the model. Error: {e}'']}, returns: [model, (None, None)]}}, {get_model: {inputs:
    [model_config_pathname], calls: [os.path.join, os.getcwd, open, yaml.safe_load,
    logging.info, get_default_model_config, instantiate_model], call_inputs: {os.path.join:
    [os.getcwd(), MODEL_CONFIG_FILE], os.getcwd: [], open: [model_config_pathname,
    ''r''], yaml.safe_load: [config_file], logging.info: [f''Model config file not
    valid: {model_config_pathname} Using default model config''], get_default_model_config:
    [], instantiate_model: [model_config[''inference_model'']]}, returns: [model_config]}},
    {write_questions_file: {inputs: [output_dir], calls: [get_default_questions, Path(output_dir).is_dir,
    Path, os.getcwd, open, os.path.join, json.dump], call_inputs: {get_default_questions:
    [], Path(output_dir).is_dir: [], Path: [output_dir], os.getcwd: [], open: [os.path.join(output_dir,
    QUESTIONS_FILE), ''w''], os.path.join: [output_dir, QUESTIONS_FILE], json.dump:
    [questions, file]}, returns: []}}, {write_model_config_file: {inputs: [output_dir],
    calls: [get_default_model_config, Path(output_dir).is_dir, Path, os.getcwd, open,
    os.path.join, yaml.dump], call_inputs: {get_default_model_config: [], Path(output_dir).is_dir:
    [], Path: [output_dir], os.getcwd: [], open: [os.path.join(output_dir, MODEL_CONFIG_FILE),
    ''w''], os.path.join: [output_dir, MODEL_CONFIG_FILE], yaml.dump: [model_config,
    file]}, returns: []}}], class_defs: []}'
  file_code_simplified: "\"\"\"\"\"\"\nimport os\nimport json\nimport logging\nimport\
    \ yaml\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\n\
    from transformers import AutoTokenizer\nlogging.basicConfig(level=logging.INFO)\n\
    QUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\n\
    OUTPUT_DIR = 'datasets'\n\n\ndef get_default_questions() ->List[Dict]:\n    \"\
    \"\"\"\"\"\n    questions = [{'id': 'file_dependencies', 'text':\n        \"Dependencies\
    \ of Python file: '{filename}'?\", 'type': 'file'}, {\n        'id': 'entire_code_graph',\
    \ 'text':\n        \"Call code graph of Python file: '{filename}'?\", 'type':\
    \ 'file'}, {\n        'id': 'file_functions', 'text':\n        \"Functions defined\
    \ in Python file: '{filename}'?\", 'type': 'file'},\n        {'id': 'file_classes',\
    \ 'text':\n        \"Classes defined in Python file: '{filename}'?\", 'type':\
    \ 'file'}, {\n        'id': 'function_inputs', 'text':\n        \"Inputs to function:\
    \ '{function_name}' in Python file: '{filename}'?\",\n        'type': 'function'},\
    \ {'id': 'function_docstring', 'text':\n        \"Docstring of function: '{function_name}'\
    \ in Python file: '{filename}'?\"\n        , 'type': 'function'}, {'id': 'function_calls',\
    \ 'text':\n        \"Calls made in function: '{function_name}' in Python file:\
    \ '{filename}'?\"\n        , 'type': 'function'}, {'id': 'function_variables',\
    \ 'text':\n        \"Variables defined in function: '{function_name}' in Python\
    \ file: '{filename}'?\"\n        , 'type': 'function'}, {'id': 'function_returns',\
    \ 'text':\n        \"Returned items from function: '{function_name}' in Python\
    \ file: '{filename}'?\"\n        , 'type': 'function'}, {'id': 'class_methods',\
    \ 'text':\n        \"Methods defined in class: '{class_name}' in Python file:\
    \ '{filename}'?\"\n        , 'type': 'class'}, {'id': 'class_docstring', 'text':\n\
    \        \"Docstring of class: '{class_name}' in Python file: '{filename}'?\"\
    ,\n        'type': 'class'}, {'id': 'class_attributes', 'text':\n        \"Attributes\
    \ of class: '{class_name}' in Python file: '{filename}'?\",\n        'type': 'class'},\
    \ {'id': 'class_variables', 'text':\n        \"Variables defined in class: '{class_name}'\
    \ in Python file: '{filename}'?\"\n        , 'type': 'class'}, {'id': 'class_inheritance',\
    \ 'text':\n        \"Inheritance of class: '{class_name}' in Python file: '{filename}'?\"\
    ,\n        'type': 'class'}, {'id': 'method_inputs', 'text':\n        \"Inputs\
    \ to method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\"\
    \n        , 'type': 'method'}, {'id': 'method_docstring', 'text':\n        \"\
    Docstring of method: '{method_name}' in class: '{class_name}' in Python file:\
    \ '{filename}'?\"\n        , 'type': 'method'}, {'id': 'method_calls', 'text':\n\
    \        \"Calls made in method: '{method_name}' in class: '{class_name}' in Python\
    \ file: '{filename}'?\"\n        , 'type': 'method'}, {'id': 'method_returns',\
    \ 'text':\n        \"Returns from method: '{method_name}' in class: '{class_name}'\
    \ in Python file: '{filename}'?\"\n        , 'type': 'method'}, {'id': 'file_purpose',\
    \ 'text':\n        \"1) DESCRIBE the purpose and processing summary of Python\
    \ file: '{filename}'; 2) PROVIDE an itemized and detailed description of each\
    \ applicable function, class, and method; 3) EXPLAIN what each input, output,\
    \ and variable does in the code.\"\n        , 'type': 'file'}]\n    return questions\n\
    \n\ndef get_default_model_config() ->Dict:\n    \"\"\"\"\"\"\n    model_config\
    \ = {'prompt_template':\n        \"\"\"\n### Instruction:\nGiven this context:\n\
    '{context}'\nPlease analyze this code you created provide a comprehensive response\
    \ without duplicating the input code, include enough detail for me to implement\
    \ the same logic, and include your reasoning step by step: {query}\n### Response:\"\
    \"\"\n        , 'inference_model': {'model_import_path':\n        'ctransformers.AutoModelForCausalLM',\
    \ 'model_inference_function':\n        'from_pretrained', 'model_params': {'model_path':\n\
    \        'TheBloke/WizardCoder-Python-13B-V1.0-GGUF', 'model_type': 'llama',\n\
    \        'local_files_only': False, 'threads': 28, 'batch_size': 128,\n      \
    \  'context_length': 14000, 'max_new_tokens': 8092, 'gpu_layers': 100,\n     \
    \   'reset': True}}}\n    return model_config\n\n\ndef get_output_dir(output_dir:\
    \ str='') ->str:\n    \"\"\"\"\"\"\n    output_dir = os.path.abspath(output_dir\
    \ or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using\
    \ output directory: {output_dir}')\n    return output_dir\n\n\ndef get_questions(questions_pathname:\
    \ str) ->List[Dict]:\n    \"\"\"\"\"\"\n    try:\n        if not questions_pathname:\n\
    \            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n\
    \        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n\
    \        logging.info(f'Using questions from file: {questions_pathname}')\n  \
    \  except:\n        logging.info(\n            f'Questions file not valid: {questions_pathname}\
    \ Using default questions'\n            )\n        questions = get_default_questions()\n\
    \    return questions\n\n\ndef instantiate_model(model_config: Dict) ->object:\n\
    \    \"\"\"\"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.',\n\
    \            1)\n        ModelClass = getattr(importlib.import_module(module_name),\
    \ class_name)\n        model_params = model_config['model_params']\n        model_path\
    \ = model_params['model_path']\n        inference_function_name = model_config['model_inference_function']\n\
    \        if inference_function_name != '':\n            inference_function = getattr(ModelClass,\
    \ inference_function_name)\n            model = inference_function(model_params.pop('model_path'),\
    \ **\n                model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'),\
    \ **model_params)\n        return model\n    except (ImportError or AttributeError\
    \ or Exception) as e:\n        logging.info(f'Failed to instantiate the model.\
    \ Error: {e}')\n        return None, None\n\n\ndef get_model(model_config_pathname:\
    \ str) ->tuple[object, str]:\n    \"\"\"\"\"\"\n    try:\n        if not model_config_pathname:\n\
    \            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE\n\
    \                )\n        with open(model_config_pathname, 'r') as config_file:\n\
    \            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using\
    \ model config from file: {model_config_pathname}')\n    except:\n        logging.info(\n\
    \            f'Model config file not valid: {model_config_pathname} Using default\
    \ model config'\n            )\n        model_config = get_default_model_config()\n\
    \    model_config['model'] = instantiate_model(model_config['inference_model'])\n\
    \    return model_config\n\n\ndef write_questions_file(output_dir: str='') ->None:\n\
    \    \"\"\"\"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir\
    \ if output_dir and Path(output_dir).is_dir(\n        ) else os.getcwd()\n   \
    \ with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions,\
    \ file, indent=4)\n\n\ndef write_model_config_file(output_dir: str='') ->None:\n\
    \    \"\"\"\"\"\"\n    model_config = get_default_model_config()\n    output_dir\
    \ = output_dir if output_dir and Path(output_dir).is_dir(\n        ) else os.getcwd()\n\
    \    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n  \
    \      yaml.dump(model_config, file)"
  entire_code_graph:
    nodes:
    - get_default_questions
    - get_default_model_config
    - get_output_dir
    - get_questions
    - instantiate_model
    - get_model
    - write_questions_file
    - write_model_config_file
    - os.path.abspath
    - os.makedirs
    - logging.info
    - os.path.join
    - os.getcwd
    - open
    - json.load
    - model_config['model_import_path'].rsplit
    - getattr
    - importlib.import_module
    - inference_function
    - model_params.pop
    - ModelClass
    - yaml.safe_load
    - Path(output_dir).is_dir
    - Path
    - json.dump
    - yaml.dump
    edges:
    - source: get_output_dir
      target: os.path.abspath
      target_inputs:
      - output_dir or OUTPUT_DIR
    - source: get_output_dir
      target: os.makedirs
      target_inputs:
      - output_dir
    - source: get_output_dir
      target: logging.info
      target_inputs:
      - 'f''Using output directory: {output_dir}'''
    - source: get_questions
      target: os.path.join
      target_inputs:
      - os.getcwd()
      - QUESTIONS_FILE
    - source: get_questions
      target: os.getcwd
      target_inputs: []
    - source: get_questions
      target: open
      target_inputs:
      - questions_pathname
      - '''r'''
    - source: get_questions
      target: json.load
      target_inputs:
      - f
    - source: get_questions
      target: logging.info
      target_inputs:
      - 'f''Questions file not valid: {questions_pathname} Using default questions'''
    - source: get_questions
      target: get_default_questions
      target_inputs: []
      target_returns:
      - questions
    - source: instantiate_model
      target: model_config['model_import_path'].rsplit
      target_inputs:
      - '''.'''
      - '1'
    - source: instantiate_model
      target: getattr
      target_inputs:
      - ModelClass
      - inference_function_name
    - source: instantiate_model
      target: importlib.import_module
      target_inputs:
      - module_name
    - source: instantiate_model
      target: inference_function
      target_inputs:
      - model_params.pop('model_path')
    - source: instantiate_model
      target: model_params.pop
      target_inputs:
      - '''model_path'''
    - source: instantiate_model
      target: ModelClass
      target_inputs:
      - model_params.pop('model_path')
    - source: instantiate_model
      target: logging.info
      target_inputs:
      - 'f''Failed to instantiate the model. Error: {e}'''
    - source: get_model
      target: os.path.join
      target_inputs:
      - os.getcwd()
      - MODEL_CONFIG_FILE
    - source: get_model
      target: os.getcwd
      target_inputs: []
    - source: get_model
      target: open
      target_inputs:
      - model_config_pathname
      - '''r'''
    - source: get_model
      target: yaml.safe_load
      target_inputs:
      - config_file
    - source: get_model
      target: logging.info
      target_inputs:
      - 'f''Model config file not valid: {model_config_pathname} Using default model
        config'''
    - source: get_model
      target: get_default_model_config
      target_inputs: []
      target_returns:
      - model_config
    - source: get_model
      target: instantiate_model
      target_inputs:
      - model_config['inference_model']
      target_returns:
      - (None, None)
      - model
    - source: write_questions_file
      target: get_default_questions
      target_inputs: []
      target_returns:
      - questions
    - source: write_questions_file
      target: Path(output_dir).is_dir
      target_inputs: []
    - source: write_questions_file
      target: Path
      target_inputs:
      - output_dir
    - source: write_questions_file
      target: os.getcwd
      target_inputs: []
    - source: write_questions_file
      target: open
      target_inputs:
      - os.path.join(output_dir, QUESTIONS_FILE)
      - '''w'''
    - source: write_questions_file
      target: os.path.join
      target_inputs:
      - output_dir
      - QUESTIONS_FILE
    - source: write_questions_file
      target: json.dump
      target_inputs:
      - questions
      - file
    - source: write_model_config_file
      target: get_default_model_config
      target_inputs: []
      target_returns:
      - model_config
    - source: write_model_config_file
      target: Path(output_dir).is_dir
      target_inputs: []
    - source: write_model_config_file
      target: Path
      target_inputs:
      - output_dir
    - source: write_model_config_file
      target: os.getcwd
      target_inputs: []
    - source: write_model_config_file
      target: open
      target_inputs:
      - os.path.join(output_dir, MODEL_CONFIG_FILE)
      - '''w'''
    - source: write_model_config_file
      target: os.path.join
      target_inputs:
      - output_dir
      - MODEL_CONFIG_FILE
    - source: write_model_config_file
      target: yaml.dump
      target_inputs:
      - model_config
      - file
functions:
  get_default_questions:
    function_name: get_default_questions
    function_code: "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default\
      \ question list\n    Args:\n        None\n    Returns:\n        List[Dict]:\
      \ The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies',\
      \ 'text': \"Dependencies of Python file: '{filename}'?\", 'type': 'file'}, {'id':\
      \ 'entire_code_graph', 'text': \"Call code graph of Python file: '{filename}'?\"\
      , 'type': 'file'}, {'id': 'file_functions', 'text': \"Functions defined in Python\
      \ file: '{filename}'?\", 'type': 'file'}, {'id': 'file_classes', 'text': \"\
      Classes defined in Python file: '{filename}'?\", 'type': 'file'}, {'id': 'function_inputs',\
      \ 'text': \"Inputs to function: '{function_name}' in Python file: '{filename}'?\"\
      , 'type': 'function'}, {'id': 'function_docstring', 'text': \"Docstring of function:\
      \ '{function_name}' in Python file: '{filename}'?\", 'type': 'function'}, {'id':\
      \ 'function_calls', 'text': \"Calls made in function: '{function_name}' in Python\
      \ file: '{filename}'?\", 'type': 'function'}, {'id': 'function_variables', 'text':\
      \ \"Variables defined in function: '{function_name}' in Python file: '{filename}'?\"\
      , 'type': 'function'}, {'id': 'function_returns', 'text': \"Returned items from\
      \ function: '{function_name}' in Python file: '{filename}'?\", 'type': 'function'},\
      \ {'id': 'class_methods', 'text': \"Methods defined in class: '{class_name}'\
      \ in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_docstring',\
      \ 'text': \"Docstring of class: '{class_name}' in Python file: '{filename}'?\"\
      , 'type': 'class'}, {'id': 'class_attributes', 'text': \"Attributes of class:\
      \ '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'class_variables',\
      \ 'text': \"Variables defined in class: '{class_name}' in Python file: '{filename}'?\"\
      , 'type': 'class'}, {'id': 'class_inheritance', 'text': \"Inheritance of class:\
      \ '{class_name}' in Python file: '{filename}'?\", 'type': 'class'}, {'id': 'method_inputs',\
      \ 'text': \"Inputs to method: '{method_name}' in class: '{class_name}' in Python\
      \ file: '{filename}'?\", 'type': 'method'}, {'id': 'method_docstring', 'text':\
      \ \"Docstring of method: '{method_name}' in class: '{class_name}' in Python\
      \ file: '{filename}'?\", 'type': 'method'}, {'id': 'method_calls', 'text': \"\
      Calls made in method: '{method_name}' in class: '{class_name}' in Python file:\
      \ '{filename}'?\", 'type': 'method'}, {'id': 'method_returns', 'text': \"Returns\
      \ from method: '{method_name}' in class: '{class_name}' in Python file: '{filename}'?\"\
      , 'type': 'method'}, {'id': 'file_purpose', 'text': \"1) DESCRIBE the purpose\
      \ and processing summary of Python file: '{filename}'; 2) PROVIDE an itemized\
      \ and detailed description of each applicable function, class, and method; 3)\
      \ EXPLAIN what each input, output, and variable does in the code.\", 'type':\
      \ 'file'}]\n    return questions"
    function_ast: 'FunctionDef(name=''get_default_questions'', args=arguments(posonlyargs=[],
      args=[], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''Return
      default question list\n    Args:\n        None\n    Returns:\n        List[Dict]:
      The default question list\n    '')), Assign(targets=[Name(id=''questions'',
      ctx=Store())], value=List(elts=[Dict(keys=[Constant(value=''id''), Constant(value=''text''),
      Constant(value=''type'')], values=[Constant(value=''file_dependencies''), Constant(value="Dependencies
      of Python file: ''{filename}''?"), Constant(value=''file'')]), Dict(keys=[Constant(value=''id''),
      Constant(value=''text''), Constant(value=''type'')], values=[Constant(value=''entire_code_graph''),
      Constant(value="Call code graph of Python file: ''{filename}''?"), Constant(value=''file'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''file_functions''), Constant(value="Functions defined
      in Python file: ''{filename}''?"), Constant(value=''file'')]), Dict(keys=[Constant(value=''id''),
      Constant(value=''text''), Constant(value=''type'')], values=[Constant(value=''file_classes''),
      Constant(value="Classes defined in Python file: ''{filename}''?"), Constant(value=''file'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''function_inputs''), Constant(value="Inputs to function:
      ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''function_docstring''), Constant(value="Docstring of
      function: ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''function_calls''), Constant(value="Calls made in function:
      ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''function_variables''), Constant(value="Variables defined
      in function: ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''function_returns''), Constant(value="Returned items
      from function: ''{function_name}'' in Python file: ''{filename}''?"), Constant(value=''function'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''class_methods''), Constant(value="Methods defined in
      class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''class_docstring''), Constant(value="Docstring of class:
      ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''class_attributes''), Constant(value="Attributes of
      class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''class_variables''), Constant(value="Variables defined
      in class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''class_inheritance''), Constant(value="Inheritance of
      class: ''{class_name}'' in Python file: ''{filename}''?"), Constant(value=''class'')]),
      Dict(keys=[Constant(value=''id''), Constant(value=''text''), Constant(value=''type'')],
      values=[Constant(value=''method_inputs''), Constant(value="Inputs to method:
      ''{method_name}'' in class: ''{class_name}'' in Python file: ''{filename}''?"),
      Constant(value=''method'')]), Dict(keys=[Constant(value=''id''), Constant(value=''text''),
      Constant(value=''type'')], values=[Constant(value=''method_docstring''), Constant(value="Docstring
      of method: ''{method_name}'' in class: ''{class_name}'' in Python file: ''{filename}''?"),
      Constant(value=''method'')]), Dict(keys=[Constant(value=''id''), Constant(value=''text''),
      Constant(value=''type'')], values=[Constant(value=''method_calls''), Constant(value="Calls
      made in method: ''{method_name}'' in class: ''{class_name}'' in Python file:
      ''{filename}''?"), Constant(value=''method'')]), Dict(keys=[Constant(value=''id''),
      Constant(value=''text''), Constant(value=''type'')], values=[Constant(value=''method_returns''),
      Constant(value="Returns from method: ''{method_name}'' in class: ''{class_name}''
      in Python file: ''{filename}''?"), Constant(value=''method'')]), Dict(keys=[Constant(value=''id''),
      Constant(value=''text''), Constant(value=''type'')], values=[Constant(value=''file_purpose''),
      Constant(value="1) DESCRIBE the purpose and processing summary of Python file:
      ''{filename}''; 2) PROVIDE an itemized and detailed description of each applicable
      function, class, and method; 3) EXPLAIN what each input, output, and variable
      does in the code."), Constant(value=''file'')])], ctx=Load())), Return(value=Name(id=''questions'',
      ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''List'',
      ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load()))'
    function_docstring: "Return default question list\n    Args:\n        None\n \
      \   Returns:\n        List[Dict]: The default question list\n    "
    function_inputs: []
    function_defaults: []
    function_returns:
    - questions
    function_calls: []
    function_call_inputs: {}
    function_variables:
    - questions
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_default_model_config:
    function_name: get_default_model_config
    function_code: "def get_default_model_config() -> Dict:\n    \"\"\"Return default\
      \ model config dict\n    Args:\n        None\n    Returns:\n        Dict: The\
      \ default model config dictionary\n    \"\"\"\n    model_config = {'prompt_template':\
      \ \"\\n### Instruction:\\nGiven this context:\\n'{context}'\\nPlease analyze\
      \ this code you created provide a comprehensive response without duplicating\
      \ the input code, include enough detail for me to implement the same logic,\
      \ and include your reasoning step by step: {query}\\n### Response:\", 'inference_model':\
      \ {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function':\
      \ 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF',\
      \ 'model_type': 'llama', 'local_files_only': False, 'threads': 28, 'batch_size':\
      \ 128, 'context_length': 14000, 'max_new_tokens': 8092, 'gpu_layers': 100, 'reset':\
      \ True}}}\n    return model_config"
    function_ast: 'FunctionDef(name=''get_default_model_config'', args=arguments(posonlyargs=[],
      args=[], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''Return
      default model config dict\n    Args:\n        None\n    Returns:\n        Dict:
      The default model config dictionary\n    '')), Assign(targets=[Name(id=''model_config'',
      ctx=Store())], value=Dict(keys=[Constant(value=''prompt_template''), Constant(value=''inference_model'')],
      values=[Constant(value="\n### Instruction:\nGiven this context:\n''{context}''\nPlease
      analyze this code you created provide a comprehensive response without duplicating
      the input code, include enough detail for me to implement the same logic, and
      include your reasoning step by step: {query}\n### Response:"), Dict(keys=[Constant(value=''model_import_path''),
      Constant(value=''model_inference_function''), Constant(value=''model_params'')],
      values=[Constant(value=''ctransformers.AutoModelForCausalLM''), Constant(value=''from_pretrained''),
      Dict(keys=[Constant(value=''model_path''), Constant(value=''model_type''), Constant(value=''local_files_only''),
      Constant(value=''threads''), Constant(value=''batch_size''), Constant(value=''context_length''),
      Constant(value=''max_new_tokens''), Constant(value=''gpu_layers''), Constant(value=''reset'')],
      values=[Constant(value=''TheBloke/WizardCoder-Python-13B-V1.0-GGUF''), Constant(value=''llama''),
      Constant(value=False), Constant(value=28), Constant(value=128), Constant(value=14000),
      Constant(value=8092), Constant(value=100), Constant(value=True)])])])), Return(value=Name(id=''model_config'',
      ctx=Load()))], decorator_list=[], returns=Name(id=''Dict'', ctx=Load()))'
    function_docstring: "Return default model config dict\n    Args:\n        None\n\
      \    Returns:\n        Dict: The default model config dictionary\n    "
    function_inputs: []
    function_defaults: []
    function_returns:
    - model_config
    function_calls: []
    function_call_inputs: {}
    function_variables:
    - model_config
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_output_dir:
    function_name: get_output_dir
    function_code: "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns\
      \ the appropriate output directory.\n    Args:\n        output_dir (str): The\
      \ directory to write the output to.\n    Returns:\n        str: The absolute\
      \ path of the provided output_dir if it exists or can be created.\n    \"\"\"\
      \n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir,\
      \ exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n\
      \    return output_dir"
    function_ast: 'FunctionDef(name=''get_output_dir'', args=arguments(posonlyargs=[],
      args=[arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[Constant(value='''')]), body=[Expr(value=Constant(value=''Returns
      the appropriate output directory.\n    Args:\n        output_dir (str): The
      directory to write the output to.\n    Returns:\n        str: The absolute path
      of the provided output_dir if it exists or can be created.\n    '')), Assign(targets=[Name(id=''output_dir'',
      ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''path'', ctx=Load()), attr=''abspath'', ctx=Load()), args=[BoolOp(op=Or(),
      values=[Name(id=''output_dir'', ctx=Load()), Name(id=''OUTPUT_DIR'', ctx=Load())])],
      keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''os'', ctx=Load()),
      attr=''makedirs'', ctx=Load()), args=[Name(id=''output_dir'', ctx=Load())],
      keywords=[keyword(arg=''exist_ok'', value=Constant(value=True))])), Expr(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Using
      output directory: ''), FormattedValue(value=Name(id=''output_dir'', ctx=Load()),
      conversion=-1)])], keywords=[])), Return(value=Name(id=''output_dir'', ctx=Load()))],
      decorator_list=[], returns=Name(id=''str'', ctx=Load()))'
    function_docstring: "Returns the appropriate output directory.\n    Args:\n  \
      \      output_dir (str): The directory to write the output to.\n    Returns:\n\
      \        str: The absolute path of the provided output_dir if it exists or can\
      \ be created.\n    "
    function_inputs:
    - output_dir
    function_defaults:
    - ''''''
    function_returns:
    - output_dir
    function_calls:
    - os.path.abspath
    - os.makedirs
    - logging.info
    function_call_inputs:
      os.path.abspath:
      - output_dir or OUTPUT_DIR
      os.makedirs:
      - output_dir
      logging.info:
      - 'f''Using output directory: {output_dir}'''
    function_variables:
    - output_dir
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_questions:
    function_name: get_questions
    function_code: "def get_questions(questions_pathname: str) -> List[Dict]:\n  \
      \  \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname\
      \ (str): The pathname of the questions file\n    Returns:\n        List[Dict]:\
      \ The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n\
      \            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n\
      \        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n\
      \        logging.info(f'Using questions from file: {questions_pathname}')\n\
      \    except:\n        logging.info(f'Questions file not valid: {questions_pathname}\
      \ Using default questions')\n        questions = get_default_questions()\n \
      \   return questions"
    function_ast: 'FunctionDef(name=''get_questions'', args=arguments(posonlyargs=[],
      args=[arg(arg=''questions_pathname'', annotation=Name(id=''str'', ctx=Load()))],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Get
      questions from file or default\n    Args:\n        questions_pathname (str):
      The pathname of the questions file\n    Returns:\n        List[Dict]: The list
      of questions\n    '')), Try(body=[If(test=UnaryOp(op=Not(), operand=Name(id=''questions_pathname'',
      ctx=Load())), body=[Assign(targets=[Name(id=''questions_pathname'', ctx=Store())],
      value=Call(func=Attribute(value=Attribute(value=Name(id=''os'', ctx=Load()),
      attr=''path'', ctx=Load()), attr=''join'', ctx=Load()), args=[Call(func=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]), Name(id=''QUESTIONS_FILE'',
      ctx=Load())], keywords=[]))], orelse=[]), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
      ctx=Load()), args=[Name(id=''questions_pathname'', ctx=Load()), Constant(value=''r'')],
      keywords=[]), optional_vars=Name(id=''f'', ctx=Store()))], body=[Assign(targets=[Name(id=''questions'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''json'', ctx=Load()),
      attr=''load'', ctx=Load()), args=[Name(id=''f'', ctx=Load())], keywords=[]))]),
      Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()), attr=''info'',
      ctx=Load()), args=[JoinedStr(values=[Constant(value=''Using questions from file:
      ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()), conversion=-1)])],
      keywords=[]))], handlers=[ExceptHandler(body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Questions
      file not valid: ''), FormattedValue(value=Name(id=''questions_pathname'', ctx=Load()),
      conversion=-1), Constant(value='' Using default questions'')])], keywords=[])),
      Assign(targets=[Name(id=''questions'', ctx=Store())], value=Call(func=Name(id=''get_default_questions'',
      ctx=Load()), args=[], keywords=[]))])], orelse=[], finalbody=[]), Return(value=Name(id=''questions'',
      ctx=Load()))], decorator_list=[], returns=Subscript(value=Name(id=''List'',
      ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load()))'
    function_docstring: "\n    Get questions from file or default\n    Args:\n   \
      \     questions_pathname (str): The pathname of the questions file\n    Returns:\n\
      \        List[Dict]: The list of questions\n    "
    function_inputs:
    - questions_pathname
    function_defaults: []
    function_returns:
    - questions
    function_calls:
    - os.path.join
    - os.getcwd
    - open
    - json.load
    - logging.info
    - get_default_questions
    function_call_inputs:
      os.path.join:
      - os.getcwd()
      - QUESTIONS_FILE
      os.getcwd: []
      open:
      - questions_pathname
      - '''r'''
      json.load:
      - f
      logging.info:
      - 'f''Questions file not valid: {questions_pathname} Using default questions'''
      get_default_questions: []
    function_variables:
    - questions
    - questions_pathname
    function_decorators: []
    function_annotations: []
    function_properties: []
  instantiate_model:
    function_name: instantiate_model
    function_code: "def instantiate_model(model_config: Dict) -> object:\n    \"\"\
      \"\n    Imports and instantiates a model based on the provided configuration.\n\
      \    Args:\n        model_config (dict): model configuration dictionary.\n \
      \   Returns:\n        object: An instance of the specified model class, or None\
      \ if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.',\
      \ 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n\
      \        model_params = model_config['model_params']\n        model_path = model_params['model_path']\n\
      \        inference_function_name = model_config['model_inference_function']\n\
      \        if inference_function_name != '':\n            inference_function =\
      \ getattr(ModelClass, inference_function_name)\n            model = inference_function(model_params.pop('model_path'),\
      \ **model_params)\n        else:\n            model = ModelClass(model_params.pop('model_path'),\
      \ **model_params)\n        return model\n    except ImportError or AttributeError\
      \ or Exception as e:\n        logging.info(f'Failed to instantiate the model.\
      \ Error: {e}')\n        return (None, None)"
    function_ast: 'FunctionDef(name=''instantiate_model'', args=arguments(posonlyargs=[],
      args=[arg(arg=''model_config'', annotation=Name(id=''Dict'', ctx=Load()))],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Imports
      and instantiates a model based on the provided configuration.\n    Args:\n        model_config
      (dict): model configuration dictionary.\n    Returns:\n        object: An instance
      of the specified model class, or None if error.\n    '')), Try(body=[Assign(targets=[Tuple(elts=[Name(id=''module_name'',
      ctx=Store()), Name(id=''class_name'', ctx=Store())], ctx=Store())], value=Call(func=Attribute(value=Subscript(value=Name(id=''model_config'',
      ctx=Load()), slice=Constant(value=''model_import_path''), ctx=Load()), attr=''rsplit'',
      ctx=Load()), args=[Constant(value=''.''), Constant(value=1)], keywords=[])),
      Assign(targets=[Name(id=''ModelClass'', ctx=Store())], value=Call(func=Name(id=''getattr'',
      ctx=Load()), args=[Call(func=Attribute(value=Name(id=''importlib'', ctx=Load()),
      attr=''import_module'', ctx=Load()), args=[Name(id=''module_name'', ctx=Load())],
      keywords=[]), Name(id=''class_name'', ctx=Load())], keywords=[])), Assign(targets=[Name(id=''model_params'',
      ctx=Store())], value=Subscript(value=Name(id=''model_config'', ctx=Load()),
      slice=Constant(value=''model_params''), ctx=Load())), Assign(targets=[Name(id=''model_path'',
      ctx=Store())], value=Subscript(value=Name(id=''model_params'', ctx=Load()),
      slice=Constant(value=''model_path''), ctx=Load())), Assign(targets=[Name(id=''inference_function_name'',
      ctx=Store())], value=Subscript(value=Name(id=''model_config'', ctx=Load()),
      slice=Constant(value=''model_inference_function''), ctx=Load())), If(test=Compare(left=Name(id=''inference_function_name'',
      ctx=Load()), ops=[NotEq()], comparators=[Constant(value='''')]), body=[Assign(targets=[Name(id=''inference_function'',
      ctx=Store())], value=Call(func=Name(id=''getattr'', ctx=Load()), args=[Name(id=''ModelClass'',
      ctx=Load()), Name(id=''inference_function_name'', ctx=Load())], keywords=[])),
      Assign(targets=[Name(id=''model'', ctx=Store())], value=Call(func=Name(id=''inference_function'',
      ctx=Load()), args=[Call(func=Attribute(value=Name(id=''model_params'', ctx=Load()),
      attr=''pop'', ctx=Load()), args=[Constant(value=''model_path'')], keywords=[])],
      keywords=[keyword(value=Name(id=''model_params'', ctx=Load()))]))], orelse=[Assign(targets=[Name(id=''model'',
      ctx=Store())], value=Call(func=Name(id=''ModelClass'', ctx=Load()), args=[Call(func=Attribute(value=Name(id=''model_params'',
      ctx=Load()), attr=''pop'', ctx=Load()), args=[Constant(value=''model_path'')],
      keywords=[])], keywords=[keyword(value=Name(id=''model_params'', ctx=Load()))]))]),
      Return(value=Name(id=''model'', ctx=Load()))], handlers=[ExceptHandler(type=BoolOp(op=Or(),
      values=[Name(id=''ImportError'', ctx=Load()), Name(id=''AttributeError'', ctx=Load()),
      Name(id=''Exception'', ctx=Load())]), name=''e'', body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Failed
      to instantiate the model. Error: ''), FormattedValue(value=Name(id=''e'', ctx=Load()),
      conversion=-1)])], keywords=[])), Return(value=Tuple(elts=[Constant(value=None),
      Constant(value=None)], ctx=Load()))])], orelse=[], finalbody=[])], decorator_list=[],
      returns=Name(id=''object'', ctx=Load()))'
    function_docstring: "\n    Imports and instantiates a model based on the provided\
      \ configuration.\n    Args:\n        model_config (dict): model configuration\
      \ dictionary.\n    Returns:\n        object: An instance of the specified model\
      \ class, or None if error.\n    "
    function_inputs:
    - model_config
    function_defaults: []
    function_returns:
    - model
    - (None, None)
    function_calls:
    - model_config['model_import_path'].rsplit
    - getattr
    - importlib.import_module
    - inference_function
    - model_params.pop
    - ModelClass
    - logging.info
    function_call_inputs:
      model_config['model_import_path'].rsplit:
      - '''.'''
      - '1'
      getattr:
      - ModelClass
      - inference_function_name
      importlib.import_module:
      - module_name
      inference_function:
      - model_params.pop('model_path')
      model_params.pop:
      - '''model_path'''
      ModelClass:
      - model_params.pop('model_path')
      logging.info:
      - 'f''Failed to instantiate the model. Error: {e}'''
    function_variables:
    - ModelClass
    - inference_function
    - inference_function_name
    - model_params
    - model_path
    - model
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_model:
    function_name: get_model
    function_code: "def get_model(model_config_pathname: str) -> tuple[object, str]:\n\
      \    \"\"\"\n    Returns an instantiated model and prompt template based on\
      \ the model configuration.\n    Agrs:\n        model_config_pathname (str):\
      \ The pathname of the model config file\n    Returns:\n        Tuple[object,\
      \ str]: The instantiated model and prompt template \n    \"\"\"\n    try:\n\
      \        if not model_config_pathname:\n            model_config_pathname =\
      \ os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname,\
      \ 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n\
      \        logging.info(f'Using model config from file: {model_config_pathname}')\n\
      \    except:\n        logging.info(f'Model config file not valid: {model_config_pathname}\
      \ Using default model config')\n        model_config = get_default_model_config()\n\
      \    model_config['model'] = instantiate_model(model_config['inference_model'])\n\
      \    return model_config"
    function_ast: 'FunctionDef(name=''get_model'', args=arguments(posonlyargs=[],
      args=[arg(arg=''model_config_pathname'', annotation=Name(id=''str'', ctx=Load()))],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Returns
      an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname
      (str): The pathname of the model config file\n    Returns:\n        Tuple[object,
      str]: The instantiated model and prompt template \n    '')), Try(body=[If(test=UnaryOp(op=Not(),
      operand=Name(id=''model_config_pathname'', ctx=Load())), body=[Assign(targets=[Name(id=''model_config_pathname'',
      ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''path'', ctx=Load()), attr=''join'', ctx=Load()), args=[Call(func=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]), Name(id=''MODEL_CONFIG_FILE'',
      ctx=Load())], keywords=[]))], orelse=[]), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
      ctx=Load()), args=[Name(id=''model_config_pathname'', ctx=Load()), Constant(value=''r'')],
      keywords=[]), optional_vars=Name(id=''config_file'', ctx=Store()))], body=[Assign(targets=[Name(id=''model_config'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''yaml'', ctx=Load()),
      attr=''safe_load'', ctx=Load()), args=[Name(id=''config_file'', ctx=Load())],
      keywords=[]))]), Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()),
      attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Using model
      config from file: ''), FormattedValue(value=Name(id=''model_config_pathname'',
      ctx=Load()), conversion=-1)])], keywords=[]))], handlers=[ExceptHandler(body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Model
      config file not valid: ''), FormattedValue(value=Name(id=''model_config_pathname'',
      ctx=Load()), conversion=-1), Constant(value='' Using default model config'')])],
      keywords=[])), Assign(targets=[Name(id=''model_config'', ctx=Store())], value=Call(func=Name(id=''get_default_model_config'',
      ctx=Load()), args=[], keywords=[]))])], orelse=[], finalbody=[]), Assign(targets=[Subscript(value=Name(id=''model_config'',
      ctx=Load()), slice=Constant(value=''model''), ctx=Store())], value=Call(func=Name(id=''instantiate_model'',
      ctx=Load()), args=[Subscript(value=Name(id=''model_config'', ctx=Load()), slice=Constant(value=''inference_model''),
      ctx=Load())], keywords=[])), Return(value=Name(id=''model_config'', ctx=Load()))],
      decorator_list=[], returns=Subscript(value=Name(id=''tuple'', ctx=Load()), slice=Tuple(elts=[Name(id=''object'',
      ctx=Load()), Name(id=''str'', ctx=Load())], ctx=Load()), ctx=Load()))'
    function_docstring: "\n    Returns an instantiated model and prompt template based\
      \ on the model configuration.\n    Agrs:\n        model_config_pathname (str):\
      \ The pathname of the model config file\n    Returns:\n        Tuple[object,\
      \ str]: The instantiated model and prompt template \n    "
    function_inputs:
    - model_config_pathname
    function_defaults: []
    function_returns:
    - model_config
    function_calls:
    - os.path.join
    - os.getcwd
    - open
    - yaml.safe_load
    - logging.info
    - get_default_model_config
    - instantiate_model
    function_call_inputs:
      os.path.join:
      - os.getcwd()
      - MODEL_CONFIG_FILE
      os.getcwd: []
      open:
      - model_config_pathname
      - '''r'''
      yaml.safe_load:
      - config_file
      logging.info:
      - 'f''Model config file not valid: {model_config_pathname} Using default model
        config'''
      get_default_model_config: []
      instantiate_model:
      - model_config['inference_model']
    function_variables:
    - model_config
    - model_config_pathname
    function_decorators: []
    function_annotations: []
    function_properties: []
  write_questions_file:
    function_name: write_questions_file
    function_code: "def write_questions_file(output_dir: str='') -> None:\n    \"\"\
      \"\n    Writes the default questions to a file in JSON format.\n    Args:\n\
      \        output_dir (str): The directory to write the questions file to.\n \
      \   Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n\
      \    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else\
      \ os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w')\
      \ as file:\n        json.dump(questions, file, indent=4)"
    function_ast: 'FunctionDef(name=''write_questions_file'', args=arguments(posonlyargs=[],
      args=[arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[Constant(value='''')]), body=[Expr(value=Constant(value=''\n    Writes
      the default questions to a file in JSON format.\n    Args:\n        output_dir
      (str): The directory to write the questions file to.\n    Returns:\n        None\n    '')),
      Assign(targets=[Name(id=''questions'', ctx=Store())], value=Call(func=Name(id=''get_default_questions'',
      ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id=''output_dir'',
      ctx=Store())], value=IfExp(test=BoolOp(op=And(), values=[Name(id=''output_dir'',
      ctx=Load()), Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()),
      args=[Name(id=''output_dir'', ctx=Load())], keywords=[]), attr=''is_dir'', ctx=Load()),
      args=[], keywords=[])]), body=Name(id=''output_dir'', ctx=Load()), orelse=Call(func=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]))), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
      ctx=Load()), args=[Call(func=Attribute(value=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''path'', ctx=Load()), attr=''join'', ctx=Load()), args=[Name(id=''output_dir'',
      ctx=Load()), Name(id=''QUESTIONS_FILE'', ctx=Load())], keywords=[]), Constant(value=''w'')],
      keywords=[]), optional_vars=Name(id=''file'', ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id=''json'',
      ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''questions'', ctx=Load()),
      Name(id=''file'', ctx=Load())], keywords=[keyword(arg=''indent'', value=Constant(value=4))]))])],
      decorator_list=[], returns=Constant(value=None))'
    function_docstring: "\n    Writes the default questions to a file in JSON format.\n\
      \    Args:\n        output_dir (str): The directory to write the questions file\
      \ to.\n    Returns:\n        None\n    "
    function_inputs:
    - output_dir
    function_defaults:
    - ''''''
    function_returns: []
    function_calls:
    - get_default_questions
    - Path(output_dir).is_dir
    - Path
    - os.getcwd
    - open
    - os.path.join
    - json.dump
    function_call_inputs:
      get_default_questions: []
      Path(output_dir).is_dir: []
      Path:
      - output_dir
      os.getcwd: []
      open:
      - os.path.join(output_dir, QUESTIONS_FILE)
      - '''w'''
      os.path.join:
      - output_dir
      - QUESTIONS_FILE
      json.dump:
      - questions
      - file
    function_variables:
    - output_dir
    - questions
    function_decorators: []
    function_annotations: []
    function_properties: []
  write_model_config_file:
    function_name: write_model_config_file
    function_code: "def write_model_config_file(output_dir: str='') -> None:\n   \
      \ \"\"\"\n    Writes the default model config to a file in YAML format.\n  \
      \  Args:\n        output_dir (str): The directory to write the model config\
      \ file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n\
      \    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else\
      \ os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w')\
      \ as file:\n        yaml.dump(model_config, file)"
    function_ast: 'FunctionDef(name=''write_model_config_file'', args=arguments(posonlyargs=[],
      args=[arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[Constant(value='''')]), body=[Expr(value=Constant(value=''\n    Writes
      the default model config to a file in YAML format.\n    Args:\n        output_dir
      (str): The directory to write the model config file to.\n    Returns:\n        None\n    '')),
      Assign(targets=[Name(id=''model_config'', ctx=Store())], value=Call(func=Name(id=''get_default_model_config'',
      ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id=''output_dir'',
      ctx=Store())], value=IfExp(test=BoolOp(op=And(), values=[Name(id=''output_dir'',
      ctx=Load()), Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()),
      args=[Name(id=''output_dir'', ctx=Load())], keywords=[]), attr=''is_dir'', ctx=Load()),
      args=[], keywords=[])]), body=Name(id=''output_dir'', ctx=Load()), orelse=Call(func=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''getcwd'', ctx=Load()), args=[], keywords=[]))), With(items=[withitem(context_expr=Call(func=Name(id=''open'',
      ctx=Load()), args=[Call(func=Attribute(value=Attribute(value=Name(id=''os'',
      ctx=Load()), attr=''path'', ctx=Load()), attr=''join'', ctx=Load()), args=[Name(id=''output_dir'',
      ctx=Load()), Name(id=''MODEL_CONFIG_FILE'', ctx=Load())], keywords=[]), Constant(value=''w'')],
      keywords=[]), optional_vars=Name(id=''file'', ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id=''yaml'',
      ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''model_config'', ctx=Load()),
      Name(id=''file'', ctx=Load())], keywords=[]))])], decorator_list=[], returns=Constant(value=None))'
    function_docstring: "\n    Writes the default model config to a file in YAML format.\n\
      \    Args:\n        output_dir (str): The directory to write the model config\
      \ file to.\n    Returns:\n        None\n    "
    function_inputs:
    - output_dir
    function_defaults:
    - ''''''
    function_returns: []
    function_calls:
    - get_default_model_config
    - Path(output_dir).is_dir
    - Path
    - os.getcwd
    - open
    - os.path.join
    - yaml.dump
    function_call_inputs:
      get_default_model_config: []
      Path(output_dir).is_dir: []
      Path:
      - output_dir
      os.getcwd: []
      open:
      - os.path.join(output_dir, MODEL_CONFIG_FILE)
      - '''w'''
      os.path.join:
      - output_dir
      - MODEL_CONFIG_FILE
      yaml.dump:
      - model_config
      - file
    function_variables:
    - model_config
    - output_dir
    function_decorators: []
    function_annotations: []
    function_properties: []
classes: {}
