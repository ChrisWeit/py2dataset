file_info:
  file_code: "\"\"\"\nUtility functions for reading the input and saving the output\
    \ of the py2dataset script.\nRequirements:\n[req01] The `read_file` function shall:\n\
    \        a. Accept a file path as an argument.\n        b. Read and return the\
    \ contents of a JSON or YAML file as a dictionary.\n[req02] The `write_file` function\
    \ shall:\n        a. Accept a dictionary and a file path as arguments.\n     \
    \   b. Write the dictionary to a file in either JSON or YAML format.\n[req03]\
    \ The `convert_json_to_html` function shall:\n        a. Convert JSON files within\
    \ a given directory to HTML format.\n        b. Save each converted file with\
    \ a .html extension.\n        c. Preserve spacing and tabs for the 'input' field.\n\
    [req04] The `combine_json_files` function shall:\n        a. Accept a directory\
    \ path as an argument.\n        b. Merge all JSON files in the directory.\n  \
    \      c. Remove duplicates from the combined JSON files.\n        d. Write the\
    \ combined data to 'instruct.json' files.\n        e. Convert the merged JSON\
    \ files to HTML format.\n        f. Return the 'instruct_list' datasets.\n[req05]\
    \ The `create_code_graph` function shall:\n        a. Accept details of a Python\
    \ file, a base name, and an output directory as arguments.\n        b. Generate\
    \ code graphs based on the provided file details.\n        c. Save the graphs\
    \ as PNG images in the specified output directory.\n[req06] The `save_python_data`\
    \ function shall:\n        a. Accept details of a Python file, a base name, and\
    \ an output directory as arguments.\n        b. Save the details of the Python\
    \ file as a YAML file.\n        c. Save the instruction data as JSON files.\n\
    \        d. Generate and save code graphs.\n\"\"\"\nimport json\nimport logging\n\
    from html import escape\nfrom pathlib import Path\nfrom typing import Dict, List\n\
    import matplotlib.pyplot as plt\nimport networkx as nx\nimport yaml\n\ndef read_file(file_path:\
    \ Path) -> Dict:\n    \"\"\"\n    Reads a JSON or YAML file and returns its contents\
    \ as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n\
    \    Returns:\n        The contents of the file as a dictionary.\n    \"\"\"\n\
    \    file_type = file_path.suffix[1:]\n    with file_path.open() as f:\n     \
    \   if file_type == 'json':\n            return json.load(f)\n        if file_type\
    \ == 'yaml':\n            return yaml.load(f, Loader=yaml.SafeLoader)\n      \
    \  return {}\n\ndef write_file(data: Dict, file_path: Path) -> None:\n    \"\"\
    \"\n    Writes a dictionary to a JSON or YAML file. \n    Args:\n        data\
    \ (Dict): The data to write to the file.\n        file_path (Path): The path to\
    \ the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n\
    \    with file_path.open('w') as f:\n        if file_type == 'json':\n       \
    \     json.dump(data, f, indent=4)\n        elif file_type == 'yaml':\n      \
    \      yaml.SafeDumper.ignore_aliases = lambda *args: True\n            yaml.dump(data,\
    \ f, Dumper=yaml.SafeDumper, sort_keys=False)\n\n\ndef convert_json_to_html(directory:\
    \ str) -> None:\n    \"\"\"\n    Convert JSON files within a given directory to\
    \ HTML format.\n    Args:\n        directory (str): The directory where the JSON\
    \ files are located.\n    Returns:\n        None    \n    \"\"\"\n    def preserve_spacing(text:\
    \ str, tab_width: int = 4) -> str:\n        \"\"\"Preserve spaces and tabs in\
    \ the provided text.\"\"\"\n        return text.replace(\" \", \"&nbsp;\").replace(\"\
    \\t\", \"&nbsp;\" * tab_width)\n\n    for json_file in Path(directory).rglob('*.json'):\n\
    \        dataset = read_file(json_file)\n        if not dataset:\n           \
    \ continue\n\n        html_content = \"\"\"\n        <html>\n        <head>\n\
    \            <style>\n                table {border-collapse: collapse; width:\
    \ 100%; table-layout: fixed;}\n                th, td {\n                    border:\
    \ 1px solid black;\n                    padding: 8px;\n                    text-align:\
    \ left;\n                    white-space: pre-line;\n                    vertical-align:\
    \ top;\n                    word-wrap: break-word;\n                }\n      \
    \      </style>\n        </head>\n        <body>\n            <table>\n      \
    \          <thead>\n                    <tr>\n        \"\"\"\n        column_count\
    \ = len(dataset[0].keys())\n        column_width = 100 / column_count  # Calculate\
    \ the width for each column based on the number of columns\n        for key in\
    \ dataset[0].keys():\n            html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\
    \n        html_content += \"\"\"\n                    </tr>\n                </thead>\n\
    \                <tbody>\n        \"\"\"\n        for entry in dataset:\n    \
    \        html_content += \"<tr>\"\n            for key in entry:\n           \
    \     # Convert \\n to HTML line breaks\n                value = escape(str(entry[key]))\n\
    \                value = preserve_spacing(value)\n                value = value.replace('\\\
    n', '<br/>')\n                html_content += f\"<td>{value}</td>\"\n        \
    \    html_content += \"</tr>\"\n\n        html_content += \"\"\"\n           \
    \     </tbody>\n            </table>\n        </body>\n        </html>\n     \
    \   \"\"\"\n        html_file_path = json_file.with_suffix('.html')\n        try:\n\
    \            with open(html_file_path, 'w', encoding='utf-8') as file:\n     \
    \           file.write(html_content)\n        except Exception:\n            logging.info(f'Failed\
    \ saving: {html_file_path}')\n\n\ndef combine_json_files(directory: str) -> Dict[str,\
    \ List[Dict]]:\n    \"\"\"\n    Combine all JSON files in the output directory\
    \ into 'instruct.json', and \n    then remove duplicates.\n    Args:\n       \
    \ directory (str): The directory where the output files are located.\n    Returns:\n\
    \        A dictionary containing the 'instruct_list' datasets.\n    \"\"\"\n\n\
    \    def remove_duplicate_dataset_entries(dataset: List[Dict], key1: str, key2:\
    \ str) -> List[Dict]:\n        \"\"\"\n        Remove duplicate entries from the\
    \ provided dataset based on the provided keys.\n        Args:\n            dataset\
    \ (List[Dict]): The dataset to remove duplicates from.\n            key1 (str):\
    \ The first key to check for duplicates.\n            key2 (str): The second key\
    \ to check for duplicates.\n        Returns:\n            A dataset without duplicate\
    \ entries.\n        \"\"\"\n        seen = set()\n        result = []\n      \
    \  for item in dataset:\n            if (item[key1], item[key2]) not in seen:\n\
    \                seen.add((item[key1], item[key2]))\n                result.append(item)\n\
    \        return result\n\n    instruct_data = []\n    for file_name in ['instruct.json']:\n\
    \        file_path = Path(directory) / file_name\n        combined_data = []\n\
    \        for json_file in Path(directory).rglob(f'*.{file_name}'):\n         \
    \   json_file_data = read_file(json_file)\n            combined_data.extend(json_file_data)\n\
    \            combined_data = remove_duplicate_dataset_entries(combined_data, 'instruction',\
    \ 'output')\n            instruct_data = combined_data.copy()\n            # gen\
    \ training datasets that contains purpose and graph data formatted for each item:\n\
    \            purpose_data = [item for item in combined_data if item['instruction'].startswith('1)\
    \ DESCRIBE the purpose')]\n            graph_data = [item for item in combined_data\
    \ if item['instruction'].startswith('Call code graph')]\n            code_output\
    \ = []\n            graph_output = []\n            for item in purpose_data:\n\
    \                instruction = 'Define a Python code file that is described as\
    \ follows:\\n'+ item['output']\n                code_output.append({'instruction':\
    \ instruction, 'output': item['input']})\n            for item in graph_data:\n\
    \                instruction = 'Define the call code graph for this Python file:\\\
    n' + item['input']\n                graph_output.append({'instruction': instruction,\
    \ 'output': item['output']})\n            code_graph_output = code_output + graph_output\n\
    \            write_file(code_graph_output, Path(directory) / 'training.json')\n\
    \n        write_file(combined_data, file_path)\n\n    # Save html file for each\
    \ json file in the output directory\n    convert_json_to_html(directory)\n   \
    \ return {'instruct_list': instruct_data}\n\n\ndef create_code_graph(file_details:\
    \ Dict, base_name: str, output_subdir: Path) -> None:\n    \"\"\"\n    Generate\
    \ graphs from the file_details and save them as PNG images.\n    Args:\n     \
    \   file_details (dict): The details extracted from the Python file.\n       \
    \ base_name (str): The base name of the output files.\n        output_subdir (Path):\
    \ The subdirectory where the output files will be saved.\n    Returns:\n     \
    \   None\n    \"\"\"\n    graph_type = 'entire_code_graph'\n    output_file =\
    \ output_subdir / f'{base_name}.{graph_type}.png'\n\n    # Create graphs, add\
    \ nodes, and add edges\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n\
    \    for edge in file_details['file_info'][graph_type]['edges']:\n        source,\
    \ target = edge['source'], edge['target']\n        if source in G.nodes and target\
    \ in G.nodes:\n            G.add_edge(source, target, **{k: v for k, v in edge.items()\
    \ if k in ['target_inputs', 'target_returns']})\n    # Draw graphs\n    plt.figure(figsize=(20,\
    \ 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True, font_weight='bold',\
    \ font_size = 8, node_shape='s', node_size=500, width=1, arrowsize=12)\n    edge_labels\
    \ = {}\n    for edge in G.edges(data=True):\n        label = []\n        if 'target_inputs'\
    \ in edge[2] and edge[2]['target_inputs']:\n            label.append(f\"Inputs:\
    \ {', '.join(edge[2]['target_inputs'])}\")\n        if 'target_returns' in edge[2]\
    \ and edge[2]['target_returns']:\n            label.append(f\"\\nReturns: {',\
    \ '.join(edge[2]['target_returns'])}\")\n        edge_labels[(edge[0], edge[1])]\
    \ = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels,\
    \ font_size=6)\n    plt.savefig(output_file) # Save the figure\n    plt.close()\
    \  # Close the figure\n\n\ndef save_python_data(file_details: dict, instruct_list:\
    \ list, relative_path: Path, output_dir: str) -> None:\n    \"\"\"\n    Save Python\
    \ file details as a YAML file, the instruction data as a JSON file, and code graphs.\n\
    \    Args:\n        file_details (dict): The details extracted from the Python\
    \ file.\n        instruct_list (list): The instruction data extracted from the\
    \ Python file.\n        relative_path (Path): The relative path to the Python\
    \ file.\n        output_dir (str): The directory where the output files will be\
    \ saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir = Path(output_dir)\
    \ / relative_path.parts[0]\n    output_subdir.mkdir(parents=True, exist_ok=True)\n\
    \    base_name = '.'.join(part for part in relative_path.parts)\n\n    # write\
    \ instrunct.json files\n    file_names = [f'{base_name}.instruct.json', f'{base_name}.details.yaml']\n\
    \    contents = [instruct_list, file_details]\n\n    for file_name, content in\
    \ zip(file_names, contents):\n        write_file(content, output_subdir / file_name)\n\
    \n    try:\n        create_code_graph(file_details, base_name, output_subdir)\n\
    \    except Exception as e:\n        logging.info(f'Error creating graph for {base_name}:\
    \ {e}')\n"
  file_ast: 'Module(body=[Expr(value=Constant(value="\nUtility functions for reading
    the input and saving the output of the py2dataset script.\nRequirements:\n[req01]
    The `read_file` function shall:\n        a. Accept a file path as an argument.\n        b.
    Read and return the contents of a JSON or YAML file as a dictionary.\n[req02]
    The `write_file` function shall:\n        a. Accept a dictionary and a file path
    as arguments.\n        b. Write the dictionary to a file in either JSON or YAML
    format.\n[req03] The `convert_json_to_html` function shall:\n        a. Convert
    JSON files within a given directory to HTML format.\n        b. Save each converted
    file with a .html extension.\n        c. Preserve spacing and tabs for the ''input''
    field.\n[req04] The `combine_json_files` function shall:\n        a. Accept a
    directory path as an argument.\n        b. Merge all JSON files in the directory.\n        c.
    Remove duplicates from the combined JSON files.\n        d. Write the combined
    data to ''instruct.json'' files.\n        e. Convert the merged JSON files to
    HTML format.\n        f. Return the ''instruct_list'' datasets.\n[req05] The `create_code_graph`
    function shall:\n        a. Accept details of a Python file, a base name, and
    an output directory as arguments.\n        b. Generate code graphs based on the
    provided file details.\n        c. Save the graphs as PNG images in the specified
    output directory.\n[req06] The `save_python_data` function shall:\n        a.
    Accept details of a Python file, a base name, and an output directory as arguments.\n        b.
    Save the details of the Python file as a YAML file.\n        c. Save the instruction
    data as JSON files.\n        d. Generate and save code graphs.\n")), Import(names=[alias(name=''json'')]),
    Import(names=[alias(name=''logging'')]), ImportFrom(module=''html'', names=[alias(name=''escape'')],
    level=0), ImportFrom(module=''pathlib'', names=[alias(name=''Path'')], level=0),
    ImportFrom(module=''typing'', names=[alias(name=''Dict''), alias(name=''List'')],
    level=0), Import(names=[alias(name=''matplotlib.pyplot'', asname=''plt'')]), Import(names=[alias(name=''networkx'',
    asname=''nx'')]), Import(names=[alias(name=''yaml'')]), FunctionDef(name=''read_file'',
    args=arguments(posonlyargs=[], args=[arg(arg=''file_path'', annotation=Name(id=''Path'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Reads
    a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n        file_path
    (Path): The path to the file.\n    Returns:\n        The contents of the file
    as a dictionary.\n    '')), Assign(targets=[Name(id=''file_type'', ctx=Store())],
    value=Subscript(value=Attribute(value=Name(id=''file_path'', ctx=Load()), attr=''suffix'',
    ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())), With(items=[withitem(context_expr=Call(func=Attribute(value=Name(id=''file_path'',
    ctx=Load()), attr=''open'', ctx=Load()), args=[], keywords=[]), optional_vars=Name(id=''f'',
    ctx=Store()))], body=[If(test=Compare(left=Name(id=''file_type'', ctx=Load()),
    ops=[Eq()], comparators=[Constant(value=''json'')]), body=[Return(value=Call(func=Attribute(value=Name(id=''json'',
    ctx=Load()), attr=''load'', ctx=Load()), args=[Name(id=''f'', ctx=Load())], keywords=[]))],
    orelse=[]), If(test=Compare(left=Name(id=''file_type'', ctx=Load()), ops=[Eq()],
    comparators=[Constant(value=''yaml'')]), body=[Return(value=Call(func=Attribute(value=Name(id=''yaml'',
    ctx=Load()), attr=''load'', ctx=Load()), args=[Name(id=''f'', ctx=Load())], keywords=[keyword(arg=''Loader'',
    value=Attribute(value=Name(id=''yaml'', ctx=Load()), attr=''SafeLoader'', ctx=Load()))]))],
    orelse=[]), Return(value=Dict(keys=[], values=[]))])], decorator_list=[], returns=Name(id=''Dict'',
    ctx=Load())), FunctionDef(name=''write_file'', args=arguments(posonlyargs=[],
    args=[arg(arg=''data'', annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''file_path'',
    annotation=Name(id=''Path'', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]),
    body=[Expr(value=Constant(value=''\n    Writes a dictionary to a JSON or YAML
    file. \n    Args:\n        data (Dict): The data to write to the file.\n        file_path
    (Path): The path to the file.\n    Returns:\n        None\n    '')), Assign(targets=[Name(id=''file_type'',
    ctx=Store())], value=Subscript(value=Attribute(value=Name(id=''file_path'', ctx=Load()),
    attr=''suffix'', ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())),
    With(items=[withitem(context_expr=Call(func=Attribute(value=Name(id=''file_path'',
    ctx=Load()), attr=''open'', ctx=Load()), args=[Constant(value=''w'')], keywords=[]),
    optional_vars=Name(id=''f'', ctx=Store()))], body=[If(test=Compare(left=Name(id=''file_type'',
    ctx=Load()), ops=[Eq()], comparators=[Constant(value=''json'')]), body=[Expr(value=Call(func=Attribute(value=Name(id=''json'',
    ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''data'', ctx=Load()),
    Name(id=''f'', ctx=Load())], keywords=[keyword(arg=''indent'', value=Constant(value=4))]))],
    orelse=[If(test=Compare(left=Name(id=''file_type'', ctx=Load()), ops=[Eq()], comparators=[Constant(value=''yaml'')]),
    body=[Assign(targets=[Attribute(value=Attribute(value=Name(id=''yaml'', ctx=Load()),
    attr=''SafeDumper'', ctx=Load()), attr=''ignore_aliases'', ctx=Store())], value=Lambda(args=arguments(posonlyargs=[],
    args=[], vararg=arg(arg=''args''), kwonlyargs=[], kw_defaults=[], defaults=[]),
    body=Constant(value=True))), Expr(value=Call(func=Attribute(value=Name(id=''yaml'',
    ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''data'', ctx=Load()),
    Name(id=''f'', ctx=Load())], keywords=[keyword(arg=''Dumper'', value=Attribute(value=Name(id=''yaml'',
    ctx=Load()), attr=''SafeDumper'', ctx=Load())), keyword(arg=''sort_keys'', value=Constant(value=False))]))],
    orelse=[])])])], decorator_list=[], returns=Constant(value=None)), FunctionDef(name=''convert_json_to_html'',
    args=arguments(posonlyargs=[], args=[arg(arg=''directory'', annotation=Name(id=''str'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Convert
    JSON files within a given directory to HTML format.\n    Args:\n        directory
    (str): The directory where the JSON files are located.\n    Returns:\n        None    \n    '')),
    FunctionDef(name=''preserve_spacing'', args=arguments(posonlyargs=[], args=[arg(arg=''text'',
    annotation=Name(id=''str'', ctx=Load())), arg(arg=''tab_width'', annotation=Name(id=''int'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=4)]), body=[Expr(value=Constant(value=''Preserve
    spaces and tabs in the provided text.'')), Return(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''text'',
    ctx=Load()), attr=''replace'', ctx=Load()), args=[Constant(value='' ''), Constant(value=''&nbsp;'')],
    keywords=[]), attr=''replace'', ctx=Load()), args=[Constant(value=''\t''), BinOp(left=Constant(value=''&nbsp;''),
    op=Mult(), right=Name(id=''tab_width'', ctx=Load()))], keywords=[]))], decorator_list=[],
    returns=Name(id=''str'', ctx=Load())), For(target=Name(id=''json_file'', ctx=Store()),
    iter=Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''directory'',
    ctx=Load())], keywords=[]), attr=''rglob'', ctx=Load()), args=[Constant(value=''*.json'')],
    keywords=[]), body=[Assign(targets=[Name(id=''dataset'', ctx=Store())], value=Call(func=Name(id=''read_file'',
    ctx=Load()), args=[Name(id=''json_file'', ctx=Load())], keywords=[])), If(test=UnaryOp(op=Not(),
    operand=Name(id=''dataset'', ctx=Load())), body=[Continue()], orelse=[]), Assign(targets=[Name(id=''html_content'',
    ctx=Store())], value=Constant(value=''\n        <html>\n        <head>\n            <style>\n                table
    {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th,
    td {\n                    border: 1px solid black;\n                    padding:
    8px;\n                    text-align: left;\n                    white-space:
    pre-line;\n                    vertical-align: top;\n                    word-wrap:
    break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        '')),
    Assign(targets=[Name(id=''column_count'', ctx=Store())], value=Call(func=Name(id=''len'',
    ctx=Load()), args=[Call(func=Attribute(value=Subscript(value=Name(id=''dataset'',
    ctx=Load()), slice=Constant(value=0), ctx=Load()), attr=''keys'', ctx=Load()),
    args=[], keywords=[])], keywords=[])), Assign(targets=[Name(id=''column_width'',
    ctx=Store())], value=BinOp(left=Constant(value=100), op=Div(), right=Name(id=''column_count'',
    ctx=Load()))), For(target=Name(id=''key'', ctx=Store()), iter=Call(func=Attribute(value=Subscript(value=Name(id=''dataset'',
    ctx=Load()), slice=Constant(value=0), ctx=Load()), attr=''keys'', ctx=Load()),
    args=[], keywords=[]), body=[AugAssign(target=Name(id=''html_content'', ctx=Store()),
    op=Add(), value=JoinedStr(values=[Constant(value="<th style=''width: "), FormattedValue(value=Name(id=''column_width'',
    ctx=Load()), conversion=-1), Constant(value="%;''>"), FormattedValue(value=Name(id=''key'',
    ctx=Load()), conversion=-1), Constant(value=''</th>'')]))], orelse=[]), AugAssign(target=Name(id=''html_content'',
    ctx=Store()), op=Add(), value=Constant(value=''\n                    </tr>\n                </thead>\n                <tbody>\n        '')),
    For(target=Name(id=''entry'', ctx=Store()), iter=Name(id=''dataset'', ctx=Load()),
    body=[AugAssign(target=Name(id=''html_content'', ctx=Store()), op=Add(), value=Constant(value=''<tr>'')),
    For(target=Name(id=''key'', ctx=Store()), iter=Name(id=''entry'', ctx=Load()),
    body=[Assign(targets=[Name(id=''value'', ctx=Store())], value=Call(func=Name(id=''escape'',
    ctx=Load()), args=[Call(func=Name(id=''str'', ctx=Load()), args=[Subscript(value=Name(id=''entry'',
    ctx=Load()), slice=Name(id=''key'', ctx=Load()), ctx=Load())], keywords=[])],
    keywords=[])), Assign(targets=[Name(id=''value'', ctx=Store())], value=Call(func=Name(id=''preserve_spacing'',
    ctx=Load()), args=[Name(id=''value'', ctx=Load())], keywords=[])), Assign(targets=[Name(id=''value'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''value'', ctx=Load()),
    attr=''replace'', ctx=Load()), args=[Constant(value=''\n''), Constant(value=''<br/>'')],
    keywords=[])), AugAssign(target=Name(id=''html_content'', ctx=Store()), op=Add(),
    value=JoinedStr(values=[Constant(value=''<td>''), FormattedValue(value=Name(id=''value'',
    ctx=Load()), conversion=-1), Constant(value=''</td>'')]))], orelse=[]), AugAssign(target=Name(id=''html_content'',
    ctx=Store()), op=Add(), value=Constant(value=''</tr>''))], orelse=[]), AugAssign(target=Name(id=''html_content'',
    ctx=Store()), op=Add(), value=Constant(value=''\n                </tbody>\n            </table>\n        </body>\n        </html>\n        '')),
    Assign(targets=[Name(id=''html_file_path'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''json_file'',
    ctx=Load()), attr=''with_suffix'', ctx=Load()), args=[Constant(value=''.html'')],
    keywords=[])), Try(body=[With(items=[withitem(context_expr=Call(func=Name(id=''open'',
    ctx=Load()), args=[Name(id=''html_file_path'', ctx=Load()), Constant(value=''w'')],
    keywords=[keyword(arg=''encoding'', value=Constant(value=''utf-8''))]), optional_vars=Name(id=''file'',
    ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id=''file'', ctx=Load()),
    attr=''write'', ctx=Load()), args=[Name(id=''html_content'', ctx=Load())], keywords=[]))])],
    handlers=[ExceptHandler(type=Name(id=''Exception'', ctx=Load()), body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Failed
    saving: ''), FormattedValue(value=Name(id=''html_file_path'', ctx=Load()), conversion=-1)])],
    keywords=[]))])], orelse=[], finalbody=[])], orelse=[])], decorator_list=[], returns=Constant(value=None)),
    FunctionDef(name=''combine_json_files'', args=arguments(posonlyargs=[], args=[arg(arg=''directory'',
    annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]),
    body=[Expr(value=Constant(value="\n    Combine all JSON files in the output directory
    into ''instruct.json'', and \n    then remove duplicates.\n    Args:\n        directory
    (str): The directory where the output files are located.\n    Returns:\n        A
    dictionary containing the ''instruct_list'' datasets.\n    ")), FunctionDef(name=''remove_duplicate_dataset_entries'',
    args=arguments(posonlyargs=[], args=[arg(arg=''dataset'', annotation=Subscript(value=Name(id=''List'',
    ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())), arg(arg=''key1'',
    annotation=Name(id=''str'', ctx=Load())), arg(arg=''key2'', annotation=Name(id=''str'',
    ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n        Remove
    duplicate entries from the provided dataset based on the provided keys.\n        Args:\n            dataset
    (List[Dict]): The dataset to remove duplicates from.\n            key1 (str):
    The first key to check for duplicates.\n            key2 (str): The second key
    to check for duplicates.\n        Returns:\n            A dataset without duplicate
    entries.\n        '')), Assign(targets=[Name(id=''seen'', ctx=Store())], value=Call(func=Name(id=''set'',
    ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id=''result'', ctx=Store())],
    value=List(elts=[], ctx=Load())), For(target=Name(id=''item'', ctx=Store()), iter=Name(id=''dataset'',
    ctx=Load()), body=[If(test=Compare(left=Tuple(elts=[Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Name(id=''key1'', ctx=Load()), ctx=Load()), Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Name(id=''key2'', ctx=Load()), ctx=Load())], ctx=Load()), ops=[NotIn()],
    comparators=[Name(id=''seen'', ctx=Load())]), body=[Expr(value=Call(func=Attribute(value=Name(id=''seen'',
    ctx=Load()), attr=''add'', ctx=Load()), args=[Tuple(elts=[Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Name(id=''key1'', ctx=Load()), ctx=Load()), Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Name(id=''key2'', ctx=Load()), ctx=Load())], ctx=Load())],
    keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''result'', ctx=Load()),
    attr=''append'', ctx=Load()), args=[Name(id=''item'', ctx=Load())], keywords=[]))],
    orelse=[])], orelse=[]), Return(value=Name(id=''result'', ctx=Load()))], decorator_list=[],
    returns=Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
    ctx=Load()), ctx=Load())), Assign(targets=[Name(id=''instruct_data'', ctx=Store())],
    value=List(elts=[], ctx=Load())), For(target=Name(id=''file_name'', ctx=Store()),
    iter=List(elts=[Constant(value=''instruct.json'')], ctx=Load()), body=[Assign(targets=[Name(id=''file_path'',
    ctx=Store())], value=BinOp(left=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''directory'',
    ctx=Load())], keywords=[]), op=Div(), right=Name(id=''file_name'', ctx=Load()))),
    Assign(targets=[Name(id=''combined_data'', ctx=Store())], value=List(elts=[],
    ctx=Load())), For(target=Name(id=''json_file'', ctx=Store()), iter=Call(func=Attribute(value=Call(func=Name(id=''Path'',
    ctx=Load()), args=[Name(id=''directory'', ctx=Load())], keywords=[]), attr=''rglob'',
    ctx=Load()), args=[JoinedStr(values=[Constant(value=''*.''), FormattedValue(value=Name(id=''file_name'',
    ctx=Load()), conversion=-1)])], keywords=[]), body=[Assign(targets=[Name(id=''json_file_data'',
    ctx=Store())], value=Call(func=Name(id=''read_file'', ctx=Load()), args=[Name(id=''json_file'',
    ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''combined_data'',
    ctx=Load()), attr=''extend'', ctx=Load()), args=[Name(id=''json_file_data'', ctx=Load())],
    keywords=[])), Assign(targets=[Name(id=''combined_data'', ctx=Store())], value=Call(func=Name(id=''remove_duplicate_dataset_entries'',
    ctx=Load()), args=[Name(id=''combined_data'', ctx=Load()), Constant(value=''instruction''),
    Constant(value=''output'')], keywords=[])), Assign(targets=[Name(id=''instruct_data'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''combined_data'', ctx=Load()),
    attr=''copy'', ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id=''purpose_data'',
    ctx=Store())], value=ListComp(elt=Name(id=''item'', ctx=Load()), generators=[comprehension(target=Name(id=''item'',
    ctx=Store()), iter=Name(id=''combined_data'', ctx=Load()), ifs=[Call(func=Attribute(value=Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Constant(value=''instruction''), ctx=Load()), attr=''startswith'',
    ctx=Load()), args=[Constant(value=''1) DESCRIBE the purpose'')], keywords=[])],
    is_async=0)])), Assign(targets=[Name(id=''graph_data'', ctx=Store())], value=ListComp(elt=Name(id=''item'',
    ctx=Load()), generators=[comprehension(target=Name(id=''item'', ctx=Store()),
    iter=Name(id=''combined_data'', ctx=Load()), ifs=[Call(func=Attribute(value=Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Constant(value=''instruction''), ctx=Load()), attr=''startswith'',
    ctx=Load()), args=[Constant(value=''Call code graph'')], keywords=[])], is_async=0)])),
    Assign(targets=[Name(id=''code_output'', ctx=Store())], value=List(elts=[], ctx=Load())),
    Assign(targets=[Name(id=''graph_output'', ctx=Store())], value=List(elts=[], ctx=Load())),
    For(target=Name(id=''item'', ctx=Store()), iter=Name(id=''purpose_data'', ctx=Load()),
    body=[Assign(targets=[Name(id=''instruction'', ctx=Store())], value=BinOp(left=Constant(value=''Define
    a Python code file that is described as follows:\n''), op=Add(), right=Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Constant(value=''output''), ctx=Load()))), Expr(value=Call(func=Attribute(value=Name(id=''code_output'',
    ctx=Load()), attr=''append'', ctx=Load()), args=[Dict(keys=[Constant(value=''instruction''),
    Constant(value=''output'')], values=[Name(id=''instruction'', ctx=Load()), Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Constant(value=''input''), ctx=Load())])], keywords=[]))],
    orelse=[]), For(target=Name(id=''item'', ctx=Store()), iter=Name(id=''graph_data'',
    ctx=Load()), body=[Assign(targets=[Name(id=''instruction'', ctx=Store())], value=BinOp(left=Constant(value=''Define
    the call code graph for this Python file:\n''), op=Add(), right=Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Constant(value=''input''), ctx=Load()))), Expr(value=Call(func=Attribute(value=Name(id=''graph_output'',
    ctx=Load()), attr=''append'', ctx=Load()), args=[Dict(keys=[Constant(value=''instruction''),
    Constant(value=''output'')], values=[Name(id=''instruction'', ctx=Load()), Subscript(value=Name(id=''item'',
    ctx=Load()), slice=Constant(value=''output''), ctx=Load())])], keywords=[]))],
    orelse=[]), Assign(targets=[Name(id=''code_graph_output'', ctx=Store())], value=BinOp(left=Name(id=''code_output'',
    ctx=Load()), op=Add(), right=Name(id=''graph_output'', ctx=Load()))), Expr(value=Call(func=Name(id=''write_file'',
    ctx=Load()), args=[Name(id=''code_graph_output'', ctx=Load()), BinOp(left=Call(func=Name(id=''Path'',
    ctx=Load()), args=[Name(id=''directory'', ctx=Load())], keywords=[]), op=Div(),
    right=Constant(value=''training.json''))], keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''write_file'',
    ctx=Load()), args=[Name(id=''combined_data'', ctx=Load()), Name(id=''file_path'',
    ctx=Load())], keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''convert_json_to_html'',
    ctx=Load()), args=[Name(id=''directory'', ctx=Load())], keywords=[])), Return(value=Dict(keys=[Constant(value=''instruct_list'')],
    values=[Name(id=''instruct_data'', ctx=Load())]))], decorator_list=[], returns=Subscript(value=Name(id=''Dict'',
    ctx=Load()), slice=Tuple(elts=[Name(id=''str'', ctx=Load()), Subscript(value=Name(id=''List'',
    ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())),
    FunctionDef(name=''create_code_graph'', args=arguments(posonlyargs=[], args=[arg(arg=''file_details'',
    annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''base_name'', annotation=Name(id=''str'',
    ctx=Load())), arg(arg=''output_subdir'', annotation=Name(id=''Path'', ctx=Load()))],
    kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Generate
    graphs from the file_details and save them as PNG images.\n    Args:\n        file_details
    (dict): The details extracted from the Python file.\n        base_name (str):
    The base name of the output files.\n        output_subdir (Path): The subdirectory
    where the output files will be saved.\n    Returns:\n        None\n    '')), Assign(targets=[Name(id=''graph_type'',
    ctx=Store())], value=Constant(value=''entire_code_graph'')), Assign(targets=[Name(id=''output_file'',
    ctx=Store())], value=BinOp(left=Name(id=''output_subdir'', ctx=Load()), op=Div(),
    right=JoinedStr(values=[FormattedValue(value=Name(id=''base_name'', ctx=Load()),
    conversion=-1), Constant(value=''.''), FormattedValue(value=Name(id=''graph_type'',
    ctx=Load()), conversion=-1), Constant(value=''.png'')]))), Assign(targets=[Name(id=''G'',
    ctx=Store())], value=Call(func=Attribute(value=Name(id=''nx'', ctx=Load()), attr=''DiGraph'',
    ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''G'',
    ctx=Load()), attr=''add_nodes_from'', ctx=Load()), args=[Subscript(value=Subscript(value=Subscript(value=Name(id=''file_details'',
    ctx=Load()), slice=Constant(value=''file_info''), ctx=Load()), slice=Name(id=''graph_type'',
    ctx=Load()), ctx=Load()), slice=Constant(value=''nodes''), ctx=Load())], keywords=[])),
    For(target=Name(id=''edge'', ctx=Store()), iter=Subscript(value=Subscript(value=Subscript(value=Name(id=''file_details'',
    ctx=Load()), slice=Constant(value=''file_info''), ctx=Load()), slice=Name(id=''graph_type'',
    ctx=Load()), ctx=Load()), slice=Constant(value=''edges''), ctx=Load()), body=[Assign(targets=[Tuple(elts=[Name(id=''source'',
    ctx=Store()), Name(id=''target'', ctx=Store())], ctx=Store())], value=Tuple(elts=[Subscript(value=Name(id=''edge'',
    ctx=Load()), slice=Constant(value=''source''), ctx=Load()), Subscript(value=Name(id=''edge'',
    ctx=Load()), slice=Constant(value=''target''), ctx=Load())], ctx=Load())), If(test=BoolOp(op=And(),
    values=[Compare(left=Name(id=''source'', ctx=Load()), ops=[In()], comparators=[Attribute(value=Name(id=''G'',
    ctx=Load()), attr=''nodes'', ctx=Load())]), Compare(left=Name(id=''target'', ctx=Load()),
    ops=[In()], comparators=[Attribute(value=Name(id=''G'', ctx=Load()), attr=''nodes'',
    ctx=Load())])]), body=[Expr(value=Call(func=Attribute(value=Name(id=''G'', ctx=Load()),
    attr=''add_edge'', ctx=Load()), args=[Name(id=''source'', ctx=Load()), Name(id=''target'',
    ctx=Load())], keywords=[keyword(value=DictComp(key=Name(id=''k'', ctx=Load()),
    value=Name(id=''v'', ctx=Load()), generators=[comprehension(target=Tuple(elts=[Name(id=''k'',
    ctx=Store()), Name(id=''v'', ctx=Store())], ctx=Store()), iter=Call(func=Attribute(value=Name(id=''edge'',
    ctx=Load()), attr=''items'', ctx=Load()), args=[], keywords=[]), ifs=[Compare(left=Name(id=''k'',
    ctx=Load()), ops=[In()], comparators=[List(elts=[Constant(value=''target_inputs''),
    Constant(value=''target_returns'')], ctx=Load())])], is_async=0)]))]))], orelse=[])],
    orelse=[]), Expr(value=Call(func=Attribute(value=Name(id=''plt'', ctx=Load()),
    attr=''figure'', ctx=Load()), args=[], keywords=[keyword(arg=''figsize'', value=Tuple(elts=[Constant(value=20),
    Constant(value=20)], ctx=Load()))])), Assign(targets=[Name(id=''pos'', ctx=Store())],
    value=Call(func=Attribute(value=Name(id=''nx'', ctx=Load()), attr=''spring_layout'',
    ctx=Load()), args=[Name(id=''G'', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''nx'',
    ctx=Load()), attr=''draw'', ctx=Load()), args=[Name(id=''G'', ctx=Load()), Name(id=''pos'',
    ctx=Load())], keywords=[keyword(arg=''with_labels'', value=Constant(value=True)),
    keyword(arg=''font_weight'', value=Constant(value=''bold'')), keyword(arg=''font_size'',
    value=Constant(value=8)), keyword(arg=''node_shape'', value=Constant(value=''s'')),
    keyword(arg=''node_size'', value=Constant(value=500)), keyword(arg=''width'',
    value=Constant(value=1)), keyword(arg=''arrowsize'', value=Constant(value=12))])),
    Assign(targets=[Name(id=''edge_labels'', ctx=Store())], value=Dict(keys=[], values=[])),
    For(target=Name(id=''edge'', ctx=Store()), iter=Call(func=Attribute(value=Name(id=''G'',
    ctx=Load()), attr=''edges'', ctx=Load()), args=[], keywords=[keyword(arg=''data'',
    value=Constant(value=True))]), body=[Assign(targets=[Name(id=''label'', ctx=Store())],
    value=List(elts=[], ctx=Load())), If(test=BoolOp(op=And(), values=[Compare(left=Constant(value=''target_inputs''),
    ops=[In()], comparators=[Subscript(value=Name(id=''edge'', ctx=Load()), slice=Constant(value=2),
    ctx=Load())]), Subscript(value=Subscript(value=Name(id=''edge'', ctx=Load()),
    slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_inputs''),
    ctx=Load())]), body=[Expr(value=Call(func=Attribute(value=Name(id=''label'', ctx=Load()),
    attr=''append'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Inputs:
    ''), FormattedValue(value=Call(func=Attribute(value=Constant(value='', ''), attr=''join'',
    ctx=Load()), args=[Subscript(value=Subscript(value=Name(id=''edge'', ctx=Load()),
    slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_inputs''),
    ctx=Load())], keywords=[]), conversion=-1)])], keywords=[]))], orelse=[]), If(test=BoolOp(op=And(),
    values=[Compare(left=Constant(value=''target_returns''), ops=[In()], comparators=[Subscript(value=Name(id=''edge'',
    ctx=Load()), slice=Constant(value=2), ctx=Load())]), Subscript(value=Subscript(value=Name(id=''edge'',
    ctx=Load()), slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_returns''),
    ctx=Load())]), body=[Expr(value=Call(func=Attribute(value=Name(id=''label'', ctx=Load()),
    attr=''append'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''\nReturns:
    ''), FormattedValue(value=Call(func=Attribute(value=Constant(value='', ''), attr=''join'',
    ctx=Load()), args=[Subscript(value=Subscript(value=Name(id=''edge'', ctx=Load()),
    slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_returns''),
    ctx=Load())], keywords=[]), conversion=-1)])], keywords=[]))], orelse=[]), Assign(targets=[Subscript(value=Name(id=''edge_labels'',
    ctx=Load()), slice=Tuple(elts=[Subscript(value=Name(id=''edge'', ctx=Load()),
    slice=Constant(value=0), ctx=Load()), Subscript(value=Name(id=''edge'', ctx=Load()),
    slice=Constant(value=1), ctx=Load())], ctx=Load()), ctx=Store())], value=Call(func=Attribute(value=Constant(value=''\n''),
    attr=''join'', ctx=Load()), args=[Name(id=''label'', ctx=Load())], keywords=[]))],
    orelse=[]), Expr(value=Call(func=Attribute(value=Name(id=''nx'', ctx=Load()),
    attr=''draw_networkx_edge_labels'', ctx=Load()), args=[Name(id=''G'', ctx=Load()),
    Name(id=''pos'', ctx=Load())], keywords=[keyword(arg=''edge_labels'', value=Name(id=''edge_labels'',
    ctx=Load())), keyword(arg=''font_size'', value=Constant(value=6))])), Expr(value=Call(func=Attribute(value=Name(id=''plt'',
    ctx=Load()), attr=''savefig'', ctx=Load()), args=[Name(id=''output_file'', ctx=Load())],
    keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''plt'', ctx=Load()),
    attr=''close'', ctx=Load()), args=[], keywords=[]))], decorator_list=[], returns=Constant(value=None)),
    FunctionDef(name=''save_python_data'', args=arguments(posonlyargs=[], args=[arg(arg=''file_details'',
    annotation=Name(id=''dict'', ctx=Load())), arg(arg=''instruct_list'', annotation=Name(id=''list'',
    ctx=Load())), arg(arg=''relative_path'', annotation=Name(id=''Path'', ctx=Load())),
    arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[],
    kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Save Python
    file details as a YAML file, the instruction data as a JSON file, and code graphs.\n    Args:\n        file_details
    (dict): The details extracted from the Python file.\n        instruct_list (list):
    The instruction data extracted from the Python file.\n        relative_path (Path):
    The relative path to the Python file.\n        output_dir (str): The directory
    where the output files will be saved.\n    Returns:\n        None\n    '')), Assign(targets=[Name(id=''output_subdir'',
    ctx=Store())], value=BinOp(left=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''output_dir'',
    ctx=Load())], keywords=[]), op=Div(), right=Subscript(value=Attribute(value=Name(id=''relative_path'',
    ctx=Load()), attr=''parts'', ctx=Load()), slice=Constant(value=0), ctx=Load()))),
    Expr(value=Call(func=Attribute(value=Name(id=''output_subdir'', ctx=Load()), attr=''mkdir'',
    ctx=Load()), args=[], keywords=[keyword(arg=''parents'', value=Constant(value=True)),
    keyword(arg=''exist_ok'', value=Constant(value=True))])), Assign(targets=[Name(id=''base_name'',
    ctx=Store())], value=Call(func=Attribute(value=Constant(value=''.''), attr=''join'',
    ctx=Load()), args=[GeneratorExp(elt=Name(id=''part'', ctx=Load()), generators=[comprehension(target=Name(id=''part'',
    ctx=Store()), iter=Attribute(value=Name(id=''relative_path'', ctx=Load()), attr=''parts'',
    ctx=Load()), ifs=[], is_async=0)])], keywords=[])), Assign(targets=[Name(id=''file_names'',
    ctx=Store())], value=List(elts=[JoinedStr(values=[FormattedValue(value=Name(id=''base_name'',
    ctx=Load()), conversion=-1), Constant(value=''.instruct.json'')]), JoinedStr(values=[FormattedValue(value=Name(id=''base_name'',
    ctx=Load()), conversion=-1), Constant(value=''.details.yaml'')])], ctx=Load())),
    Assign(targets=[Name(id=''contents'', ctx=Store())], value=List(elts=[Name(id=''instruct_list'',
    ctx=Load()), Name(id=''file_details'', ctx=Load())], ctx=Load())), For(target=Tuple(elts=[Name(id=''file_name'',
    ctx=Store()), Name(id=''content'', ctx=Store())], ctx=Store()), iter=Call(func=Name(id=''zip'',
    ctx=Load()), args=[Name(id=''file_names'', ctx=Load()), Name(id=''contents'',
    ctx=Load())], keywords=[]), body=[Expr(value=Call(func=Name(id=''write_file'',
    ctx=Load()), args=[Name(id=''content'', ctx=Load()), BinOp(left=Name(id=''output_subdir'',
    ctx=Load()), op=Div(), right=Name(id=''file_name'', ctx=Load()))], keywords=[]))],
    orelse=[]), Try(body=[Expr(value=Call(func=Name(id=''create_code_graph'', ctx=Load()),
    args=[Name(id=''file_details'', ctx=Load()), Name(id=''base_name'', ctx=Load()),
    Name(id=''output_subdir'', ctx=Load())], keywords=[]))], handlers=[ExceptHandler(type=Name(id=''Exception'',
    ctx=Load()), name=''e'', body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
    ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Error
    creating graph for ''), FormattedValue(value=Name(id=''base_name'', ctx=Load()),
    conversion=-1), Constant(value='': ''), FormattedValue(value=Name(id=''e'', ctx=Load()),
    conversion=-1)])], keywords=[]))])], orelse=[], finalbody=[])], decorator_list=[],
    returns=Constant(value=None))], type_ignores=[])'
  file_dependencies:
  - pathlib
  - networkx
  - logging
  - matplotlib.pyplot
  - typing
  - json
  - yaml
  - html
  file_functions:
  - read_file
  - write_file
  - convert_json_to_html
  - preserve_spacing
  - combine_json_files
  - remove_duplicate_dataset_entries
  - create_code_graph
  - save_python_data
  file_classes: []
  file_summary: '{dependencies: [pathlib, networkx, logging, matplotlib.pyplot, typing,
    json, yaml, html], function_defs: [{read_file: {inputs: [file_path], calls: [file_path.open,
    json.load, yaml.load], call_inputs: {file_path.open: [], json.load: [f], yaml.load:
    [f]}, returns: [{}, json.load(f), yaml.load(f, Loader=yaml.SafeLoader)]}}, {write_file:
    {inputs: [data, file_path], calls: [file_path.open, json.dump, yaml.dump], call_inputs:
    {file_path.open: [''w''], json.dump: [data, f], yaml.dump: [data, f]}, returns:
    []}}, {convert_json_to_html: {inputs: [directory], calls: [text.replace('' '',
    ''&nbsp;'').replace, text.replace, Path(directory).rglob, Path, read_file, len,
    dataset[0].keys, escape, str, preserve_spacing, value.replace, json_file.with_suffix,
    open, file.write, logging.info], call_inputs: {text.replace('' '', ''&nbsp;'').replace:
    [''\\t'', ''&nbsp;'' * tab_width], text.replace: ['' '', ''&nbsp;''], Path(directory).rglob:
    [''*.json''], Path: [directory], read_file: [json_file], len: [dataset[0].keys()],
    dataset[0].keys: [], escape: [str(entry[key])], str: [entry[key]], preserve_spacing:
    [value], value.replace: [''\\n'', ''<br/>''], json_file.with_suffix: [''.html''],
    open: [html_file_path, ''w''], file.write: [html_content], logging.info: [f''Failed
    saving: {html_file_path}'']}, returns: [text.replace('' '', ''&nbsp;'').replace(''\\t'',
    ''&nbsp;'' * tab_width)]}}, {preserve_spacing: {inputs: [text, tab_width], calls:
    [text.replace('' '', ''&nbsp;'').replace, text.replace], call_inputs: {text.replace(''
    '', ''&nbsp;'').replace: [''\\t'', ''&nbsp;'' * tab_width], text.replace: [''
    '', ''&nbsp;'']}, returns: [text.replace('' '', ''&nbsp;'').replace(''\\t'', ''&nbsp;''
    * tab_width)]}}, {combine_json_files: {inputs: [directory], calls: [set, seen.add,
    result.append, Path, Path(directory).rglob, read_file, combined_data.extend, remove_duplicate_dataset_entries,
    combined_data.copy, item[''instruction''].startswith, code_output.append, graph_output.append,
    write_file, convert_json_to_html], call_inputs: {set: [], seen.add: [(item[key1],
    item[key2])], result.append: [item], Path: [directory], Path(directory).rglob:
    [f''*.{file_name}''], read_file: [json_file], combined_data.extend: [json_file_data],
    remove_duplicate_dataset_entries: [combined_data, ''instruction'', ''output''],
    combined_data.copy: [], item[''instruction''].startswith: [''Call code graph''],
    code_output.append: [{''instruction'': instruction, ''output'': item[''input'']}],
    graph_output.append: [{''instruction'': instruction, ''output'': item[''output'']}],
    write_file: [combined_data, file_path], convert_json_to_html: [directory]}, returns:
    [{''instruct_list'': instruct_data}, result]}}, {remove_duplicate_dataset_entries:
    {inputs: [dataset, key1, key2], calls: [set, seen.add, result.append], call_inputs:
    {set: [], seen.add: [(item[key1], item[key2])], result.append: [item]}, returns:
    [result]}}, {create_code_graph: {inputs: [file_details, base_name, output_subdir],
    calls: [nx.DiGraph, G.add_nodes_from, G.add_edge, edge.items, plt.figure, nx.spring_layout,
    nx.draw, G.edges, label.append, '', ''.join, ''\\n''.join, nx.draw_networkx_edge_labels,
    plt.savefig, plt.close], call_inputs: {nx.DiGraph: [], G.add_nodes_from: [file_details[''file_info''][graph_type][''nodes'']],
    G.add_edge: [source, target], edge.items: [], plt.figure: [], nx.spring_layout:
    [G], nx.draw: [G, pos], G.edges: [], label.append: [f\\\nReturns: {'', ''.join(edge[2][''target_returns''])}\],
    '', ''.join: [edge[2][''target_returns'']], ''\\n''.join: [label], nx.draw_networkx_edge_labels:
    [G, pos], plt.savefig: [output_file], plt.close: []}, returns: []}}, {save_python_data:
    {inputs: [file_details, instruct_list, relative_path, output_dir], calls: [Path,
    output_subdir.mkdir, ''.''.join, zip, write_file, create_code_graph, logging.info],
    call_inputs: {Path: [output_dir], output_subdir.mkdir: [], ''.''.join: [(part
    for part in relative_path.parts)], zip: [file_names, contents], write_file: [content,
    output_subdir / file_name], create_code_graph: [file_details, base_name, output_subdir],
    logging.info: [f''Error creating graph for {base_name}: {e}'']}, returns: []}}],
    class_defs: []}'
  file_code_simplified: "\"\"\"\"\"\"\nimport json\nimport logging\nfrom html import\
    \ escape\nfrom pathlib import Path\nfrom typing import Dict, List\nimport matplotlib.pyplot\
    \ as plt\nimport networkx as nx\nimport yaml\n\n\ndef read_file(file_path: Path)\
    \ ->Dict:\n    \"\"\"\"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open()\
    \ as f:\n        if file_type == 'json':\n            return json.load(f)\n  \
    \      if file_type == 'yaml':\n            return yaml.load(f, Loader=yaml.SafeLoader)\n\
    \        return {}\n\n\ndef write_file(data: Dict, file_path: Path) ->None:\n\
    \    \"\"\"\"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open('w')\
    \ as f:\n        if file_type == 'json':\n            json.dump(data, f, indent=4)\n\
    \        elif file_type == 'yaml':\n            yaml.SafeDumper.ignore_aliases\
    \ = lambda *args: True\n            yaml.dump(data, f, Dumper=yaml.SafeDumper,\
    \ sort_keys=False)\n\n\ndef convert_json_to_html(directory: str) ->None:\n   \
    \ \"\"\"\"\"\"\n\n    def preserve_spacing(text: str, tab_width: int=4) ->str:\n\
    \        \"\"\"\"\"\"\n        return text.replace(' ', '&nbsp;').replace('\\\
    t', '&nbsp;' * tab_width)\n    for json_file in Path(directory).rglob('*.json'):\n\
    \        dataset = read_file(json_file)\n        if not dataset:\n           \
    \ continue\n        html_content = \"\"\"\n        <html>\n        <head>\n  \
    \          <style>\n                table {border-collapse: collapse; width: 100%;\
    \ table-layout: fixed;}\n                th, td {\n                    border:\
    \ 1px solid black;\n                    padding: 8px;\n                    text-align:\
    \ left;\n                    white-space: pre-line;\n                    vertical-align:\
    \ top;\n                    word-wrap: break-word;\n                }\n      \
    \      </style>\n        </head>\n        <body>\n            <table>\n      \
    \          <thead>\n                    <tr>\n        \"\"\"\n        column_count\
    \ = len(dataset[0].keys())\n        column_width = 100 / column_count\n      \
    \  for key in dataset[0].keys():\n            html_content += f\"<th style='width:\
    \ {column_width}%;'>{key}</th>\"\n        html_content += \"\"\"\n           \
    \         </tr>\n                </thead>\n                <tbody>\n        \"\
    \"\"\n        for entry in dataset:\n            html_content += '<tr>'\n    \
    \        for key in entry:\n                value = escape(str(entry[key]))\n\
    \                value = preserve_spacing(value)\n                value = value.replace('\\\
    n', '<br/>')\n                html_content += f'<td>{value}</td>'\n          \
    \  html_content += '</tr>'\n        html_content += \"\"\"\n                </tbody>\n\
    \            </table>\n        </body>\n        </html>\n        \"\"\"\n    \
    \    html_file_path = json_file.with_suffix('.html')\n        try:\n         \
    \   with open(html_file_path, 'w', encoding='utf-8') as file:\n              \
    \  file.write(html_content)\n        except Exception:\n            logging.info(f'Failed\
    \ saving: {html_file_path}')\n\n\ndef combine_json_files(directory: str) ->Dict[str,\
    \ List[Dict]]:\n    \"\"\"\"\"\"\n\n    def remove_duplicate_dataset_entries(dataset:\
    \ List[Dict], key1: str,\n        key2: str) ->List[Dict]:\n        \"\"\"\"\"\
    \"\n        seen = set()\n        result = []\n        for item in dataset:\n\
    \            if (item[key1], item[key2]) not in seen:\n                seen.add((item[key1],\
    \ item[key2]))\n                result.append(item)\n        return result\n \
    \   instruct_data = []\n    for file_name in ['instruct.json']:\n        file_path\
    \ = Path(directory) / file_name\n        combined_data = []\n        for json_file\
    \ in Path(directory).rglob(f'*.{file_name}'):\n            json_file_data = read_file(json_file)\n\
    \            combined_data.extend(json_file_data)\n            combined_data =\
    \ remove_duplicate_dataset_entries(combined_data,\n                'instruction',\
    \ 'output')\n            instruct_data = combined_data.copy()\n            purpose_data\
    \ = [item for item in combined_data if item[\n                'instruction'].startswith('1)\
    \ DESCRIBE the purpose')]\n            graph_data = [item for item in combined_data\
    \ if item[\n                'instruction'].startswith('Call code graph')]\n  \
    \          code_output = []\n            graph_output = []\n            for item\
    \ in purpose_data:\n                instruction = (\n                    'Define\
    \ a Python code file that is described as follows:\\n'\n                     +\
    \ item['output'])\n                code_output.append({'instruction': instruction,\
    \ 'output':\n                    item['input']})\n            for item in graph_data:\n\
    \                instruction = (\n                    'Define the call code graph\
    \ for this Python file:\\n' +\n                    item['input'])\n          \
    \      graph_output.append({'instruction': instruction, 'output':\n          \
    \          item['output']})\n            code_graph_output = code_output + graph_output\n\
    \            write_file(code_graph_output, Path(directory) / 'training.json')\n\
    \        write_file(combined_data, file_path)\n    convert_json_to_html(directory)\n\
    \    return {'instruct_list': instruct_data}\n\n\ndef create_code_graph(file_details:\
    \ Dict, base_name: str, output_subdir: Path\n    ) ->None:\n    \"\"\"\"\"\"\n\
    \    graph_type = 'entire_code_graph'\n    output_file = output_subdir / f'{base_name}.{graph_type}.png'\n\
    \    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n\
    \    for edge in file_details['file_info'][graph_type]['edges']:\n        source,\
    \ target = edge['source'], edge['target']\n        if source in G.nodes and target\
    \ in G.nodes:\n            G.add_edge(source, target, **{k: v for k, v in edge.items()\
    \ if \n                k in ['target_inputs', 'target_returns']})\n    plt.figure(figsize=(20,\
    \ 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True, font_weight='bold',\
    \ font_size=8,\n        node_shape='s', node_size=500, width=1, arrowsize=12)\n\
    \    edge_labels = {}\n    for edge in G.edges(data=True):\n        label = []\n\
    \        if 'target_inputs' in edge[2] and edge[2]['target_inputs']:\n       \
    \     label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\")\n     \
    \   if 'target_returns' in edge[2] and edge[2]['target_returns']:\n          \
    \  label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\")\n   \
    \     edge_labels[edge[0], edge[1]] = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G,\
    \ pos, edge_labels=edge_labels, font_size=6)\n    plt.savefig(output_file)\n \
    \   plt.close()\n\n\ndef save_python_data(file_details: dict, instruct_list: list,\
    \ relative_path:\n    Path, output_dir: str) ->None:\n    \"\"\"\"\"\"\n    output_subdir\
    \ = Path(output_dir) / relative_path.parts[0]\n    output_subdir.mkdir(parents=True,\
    \ exist_ok=True)\n    base_name = '.'.join(part for part in relative_path.parts)\n\
    \    file_names = [f'{base_name}.instruct.json', f'{base_name}.details.yaml']\n\
    \    contents = [instruct_list, file_details]\n    for file_name, content in zip(file_names,\
    \ contents):\n        write_file(content, output_subdir / file_name)\n    try:\n\
    \        create_code_graph(file_details, base_name, output_subdir)\n    except\
    \ Exception as e:\n        logging.info(f'Error creating graph for {base_name}:\
    \ {e}')"
  entire_code_graph:
    nodes:
    - read_file
    - write_file
    - convert_json_to_html
    - preserve_spacing
    - combine_json_files
    - remove_duplicate_dataset_entries
    - create_code_graph
    - save_python_data
    - file_path.open
    - json.load
    - yaml.load
    - json.dump
    - yaml.dump
    - text.replace(' ', '&nbsp;').replace
    - text.replace
    - Path(directory).rglob
    - Path
    - len
    - dataset[0].keys
    - escape
    - str
    - value.replace
    - json_file.with_suffix
    - open
    - file.write
    - logging.info
    - set
    - seen.add
    - result.append
    - combined_data.extend
    - combined_data.copy
    - item['instruction'].startswith
    - code_output.append
    - graph_output.append
    - nx.DiGraph
    - G.add_nodes_from
    - G.add_edge
    - edge.items
    - plt.figure
    - nx.spring_layout
    - nx.draw
    - G.edges
    - label.append
    - ''', ''.join'
    - '''\n''.join'
    - nx.draw_networkx_edge_labels
    - plt.savefig
    - plt.close
    - output_subdir.mkdir
    - '''.''.join'
    - zip
    edges:
    - source: read_file
      target: file_path.open
      target_inputs: []
    - source: read_file
      target: json.load
      target_inputs:
      - f
    - source: read_file
      target: yaml.load
      target_inputs:
      - f
    - source: write_file
      target: file_path.open
      target_inputs:
      - '''w'''
    - source: write_file
      target: json.dump
      target_inputs:
      - data
      - f
    - source: write_file
      target: yaml.dump
      target_inputs:
      - data
      - f
    - source: convert_json_to_html
      target: text.replace(' ', '&nbsp;').replace
      target_inputs:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
    - source: convert_json_to_html
      target: text.replace
      target_inputs:
      - ''' '''
      - '''&nbsp;'''
    - source: convert_json_to_html
      target: Path(directory).rglob
      target_inputs:
      - '''*.json'''
    - source: convert_json_to_html
      target: Path
      target_inputs:
      - directory
    - source: convert_json_to_html
      target: read_file
      target_inputs:
      - json_file
      target_returns:
      - yaml.load(f, Loader=yaml.SafeLoader)
      - json.load(f)
      - '{}'
    - source: convert_json_to_html
      target: len
      target_inputs:
      - dataset[0].keys()
    - source: convert_json_to_html
      target: dataset[0].keys
      target_inputs: []
    - source: convert_json_to_html
      target: escape
      target_inputs:
      - str(entry[key])
    - source: convert_json_to_html
      target: str
      target_inputs:
      - entry[key]
    - source: convert_json_to_html
      target: preserve_spacing
      target_inputs:
      - value
      target_returns:
      - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    - source: convert_json_to_html
      target: value.replace
      target_inputs:
      - '''\n'''
      - '''<br/>'''
    - source: convert_json_to_html
      target: json_file.with_suffix
      target_inputs:
      - '''.html'''
    - source: convert_json_to_html
      target: open
      target_inputs:
      - html_file_path
      - '''w'''
    - source: convert_json_to_html
      target: file.write
      target_inputs:
      - html_content
    - source: convert_json_to_html
      target: logging.info
      target_inputs:
      - 'f''Failed saving: {html_file_path}'''
    - source: preserve_spacing
      target: text.replace(' ', '&nbsp;').replace
      target_inputs:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
    - source: preserve_spacing
      target: text.replace
      target_inputs:
      - ''' '''
      - '''&nbsp;'''
    - source: combine_json_files
      target: set
      target_inputs: []
    - source: combine_json_files
      target: seen.add
      target_inputs:
      - (item[key1], item[key2])
    - source: combine_json_files
      target: result.append
      target_inputs:
      - item
    - source: combine_json_files
      target: Path
      target_inputs:
      - directory
    - source: combine_json_files
      target: Path(directory).rglob
      target_inputs:
      - f'*.{file_name}'
    - source: combine_json_files
      target: read_file
      target_inputs:
      - json_file
      target_returns:
      - yaml.load(f, Loader=yaml.SafeLoader)
      - json.load(f)
      - '{}'
    - source: combine_json_files
      target: combined_data.extend
      target_inputs:
      - json_file_data
    - source: combine_json_files
      target: remove_duplicate_dataset_entries
      target_inputs:
      - combined_data
      - '''instruction'''
      - '''output'''
      target_returns:
      - result
    - source: combine_json_files
      target: combined_data.copy
      target_inputs: []
    - source: combine_json_files
      target: item['instruction'].startswith
      target_inputs:
      - '''Call code graph'''
    - source: combine_json_files
      target: code_output.append
      target_inputs:
      - '{''instruction'': instruction, ''output'': item[''input'']}'
    - source: combine_json_files
      target: graph_output.append
      target_inputs:
      - '{''instruction'': instruction, ''output'': item[''output'']}'
    - source: combine_json_files
      target: write_file
      target_inputs:
      - combined_data
      - file_path
      target_returns: []
    - source: combine_json_files
      target: convert_json_to_html
      target_inputs:
      - directory
      target_returns:
      - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    - source: remove_duplicate_dataset_entries
      target: set
      target_inputs: []
    - source: remove_duplicate_dataset_entries
      target: seen.add
      target_inputs:
      - (item[key1], item[key2])
    - source: remove_duplicate_dataset_entries
      target: result.append
      target_inputs:
      - item
    - source: create_code_graph
      target: nx.DiGraph
      target_inputs: []
    - source: create_code_graph
      target: G.add_nodes_from
      target_inputs:
      - file_details['file_info'][graph_type]['nodes']
    - source: create_code_graph
      target: G.add_edge
      target_inputs:
      - source
      - target
    - source: create_code_graph
      target: edge.items
      target_inputs: []
    - source: create_code_graph
      target: plt.figure
      target_inputs: []
    - source: create_code_graph
      target: nx.spring_layout
      target_inputs:
      - G
    - source: create_code_graph
      target: nx.draw
      target_inputs:
      - G
      - pos
    - source: create_code_graph
      target: G.edges
      target_inputs: []
    - source: create_code_graph
      target: label.append
      target_inputs:
      - 'f"\nReturns: {'', ''.join(edge[2][''target_returns''])}"'
    - source: create_code_graph
      target: ''', ''.join'
      target_inputs:
      - edge[2]['target_returns']
    - source: create_code_graph
      target: '''\n''.join'
      target_inputs:
      - label
    - source: create_code_graph
      target: nx.draw_networkx_edge_labels
      target_inputs:
      - G
      - pos
    - source: create_code_graph
      target: plt.savefig
      target_inputs:
      - output_file
    - source: create_code_graph
      target: plt.close
      target_inputs: []
    - source: save_python_data
      target: Path
      target_inputs:
      - output_dir
    - source: save_python_data
      target: output_subdir.mkdir
      target_inputs: []
    - source: save_python_data
      target: '''.''.join'
      target_inputs:
      - (part for part in relative_path.parts)
    - source: save_python_data
      target: zip
      target_inputs:
      - file_names
      - contents
    - source: save_python_data
      target: write_file
      target_inputs:
      - content
      - output_subdir / file_name
      target_returns: []
    - source: save_python_data
      target: create_code_graph
      target_inputs:
      - file_details
      - base_name
      - output_subdir
      target_returns: []
    - source: save_python_data
      target: logging.info
      target_inputs:
      - 'f''Error creating graph for {base_name}: {e}'''
functions:
  read_file:
    function_name: read_file
    function_code: "def read_file(file_path: Path) -> Dict:\n    \"\"\"\n    Reads\
      \ a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n\
      \        file_path (Path): The path to the file.\n    Returns:\n        The\
      \ contents of the file as a dictionary.\n    \"\"\"\n    file_type = file_path.suffix[1:]\n\
      \    with file_path.open() as f:\n        if file_type == 'json':\n        \
      \    return json.load(f)\n        if file_type == 'yaml':\n            return\
      \ yaml.load(f, Loader=yaml.SafeLoader)\n        return {}"
    function_ast: 'FunctionDef(name=''read_file'', args=arguments(posonlyargs=[],
      args=[arg(arg=''file_path'', annotation=Name(id=''Path'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Reads
      a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n        file_path
      (Path): The path to the file.\n    Returns:\n        The contents of the file
      as a dictionary.\n    '')), Assign(targets=[Name(id=''file_type'', ctx=Store())],
      value=Subscript(value=Attribute(value=Name(id=''file_path'', ctx=Load()), attr=''suffix'',
      ctx=Load()), slice=Slice(lower=Constant(value=1)), ctx=Load())), With(items=[withitem(context_expr=Call(func=Attribute(value=Name(id=''file_path'',
      ctx=Load()), attr=''open'', ctx=Load()), args=[], keywords=[]), optional_vars=Name(id=''f'',
      ctx=Store()))], body=[If(test=Compare(left=Name(id=''file_type'', ctx=Load()),
      ops=[Eq()], comparators=[Constant(value=''json'')]), body=[Return(value=Call(func=Attribute(value=Name(id=''json'',
      ctx=Load()), attr=''load'', ctx=Load()), args=[Name(id=''f'', ctx=Load())],
      keywords=[]))], orelse=[]), If(test=Compare(left=Name(id=''file_type'', ctx=Load()),
      ops=[Eq()], comparators=[Constant(value=''yaml'')]), body=[Return(value=Call(func=Attribute(value=Name(id=''yaml'',
      ctx=Load()), attr=''load'', ctx=Load()), args=[Name(id=''f'', ctx=Load())],
      keywords=[keyword(arg=''Loader'', value=Attribute(value=Name(id=''yaml'', ctx=Load()),
      attr=''SafeLoader'', ctx=Load()))]))], orelse=[]), Return(value=Dict(keys=[],
      values=[]))])], decorator_list=[], returns=Name(id=''Dict'', ctx=Load()))'
    function_docstring: "\n    Reads a JSON or YAML file and returns its contents\
      \ as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n\
      \    Returns:\n        The contents of the file as a dictionary.\n    "
    function_inputs:
    - file_path
    function_defaults: []
    function_returns:
    - '{}'
    - json.load(f)
    - yaml.load(f, Loader=yaml.SafeLoader)
    function_calls:
    - file_path.open
    - json.load
    - yaml.load
    function_call_inputs:
      file_path.open: []
      json.load:
      - f
      yaml.load:
      - f
    function_variables:
    - file_type
    function_decorators: []
    function_annotations: []
    function_properties: []
  write_file:
    function_name: write_file
    function_code: "def write_file(data: Dict, file_path: Path) -> None:\n    \"\"\
      \"\n    Writes a dictionary to a JSON or YAML file. \n    Args:\n        data\
      \ (Dict): The data to write to the file.\n        file_path (Path): The path\
      \ to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n\
      \    with file_path.open('w') as f:\n        if file_type == 'json':\n     \
      \       json.dump(data, f, indent=4)\n        elif file_type == 'yaml':\n  \
      \          yaml.SafeDumper.ignore_aliases = lambda *args: True\n           \
      \ yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)"
    function_ast: 'FunctionDef(name=''write_file'', args=arguments(posonlyargs=[],
      args=[arg(arg=''data'', annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''file_path'',
      annotation=Name(id=''Path'', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]),
      body=[Expr(value=Constant(value=''\n    Writes a dictionary to a JSON or YAML
      file. \n    Args:\n        data (Dict): The data to write to the file.\n        file_path
      (Path): The path to the file.\n    Returns:\n        None\n    '')), Assign(targets=[Name(id=''file_type'',
      ctx=Store())], value=Subscript(value=Attribute(value=Name(id=''file_path'',
      ctx=Load()), attr=''suffix'', ctx=Load()), slice=Slice(lower=Constant(value=1)),
      ctx=Load())), With(items=[withitem(context_expr=Call(func=Attribute(value=Name(id=''file_path'',
      ctx=Load()), attr=''open'', ctx=Load()), args=[Constant(value=''w'')], keywords=[]),
      optional_vars=Name(id=''f'', ctx=Store()))], body=[If(test=Compare(left=Name(id=''file_type'',
      ctx=Load()), ops=[Eq()], comparators=[Constant(value=''json'')]), body=[Expr(value=Call(func=Attribute(value=Name(id=''json'',
      ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''data'', ctx=Load()),
      Name(id=''f'', ctx=Load())], keywords=[keyword(arg=''indent'', value=Constant(value=4))]))],
      orelse=[If(test=Compare(left=Name(id=''file_type'', ctx=Load()), ops=[Eq()],
      comparators=[Constant(value=''yaml'')]), body=[Assign(targets=[Attribute(value=Attribute(value=Name(id=''yaml'',
      ctx=Load()), attr=''SafeDumper'', ctx=Load()), attr=''ignore_aliases'', ctx=Store())],
      value=Lambda(args=arguments(posonlyargs=[], args=[], vararg=arg(arg=''args''),
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=Constant(value=True))), Expr(value=Call(func=Attribute(value=Name(id=''yaml'',
      ctx=Load()), attr=''dump'', ctx=Load()), args=[Name(id=''data'', ctx=Load()),
      Name(id=''f'', ctx=Load())], keywords=[keyword(arg=''Dumper'', value=Attribute(value=Name(id=''yaml'',
      ctx=Load()), attr=''SafeDumper'', ctx=Load())), keyword(arg=''sort_keys'', value=Constant(value=False))]))],
      orelse=[])])])], decorator_list=[], returns=Constant(value=None))'
    function_docstring: "\n    Writes a dictionary to a JSON or YAML file. \n    Args:\n\
      \        data (Dict): The data to write to the file.\n        file_path (Path):\
      \ The path to the file.\n    Returns:\n        None\n    "
    function_inputs:
    - data
    - file_path
    function_defaults: []
    function_returns: []
    function_calls:
    - file_path.open
    - json.dump
    - yaml.dump
    function_call_inputs:
      file_path.open:
      - '''w'''
      json.dump:
      - data
      - f
      yaml.dump:
      - data
      - f
    function_variables:
    - file_type
    function_decorators: []
    function_annotations: []
    function_properties:
    - yaml.SafeDumper.ignore_aliases
  convert_json_to_html:
    function_name: convert_json_to_html
    function_code: "def convert_json_to_html(directory: str) -> None:\n    \"\"\"\n\
      \    Convert JSON files within a given directory to HTML format.\n    Args:\n\
      \        directory (str): The directory where the JSON files are located.\n\
      \    Returns:\n        None    \n    \"\"\"\n\n    def preserve_spacing(text:\
      \ str, tab_width: int=4) -> str:\n        \"\"\"Preserve spaces and tabs in\
      \ the provided text.\"\"\"\n        return text.replace(' ', '&nbsp;').replace('\\\
      t', '&nbsp;' * tab_width)\n    for json_file in Path(directory).rglob('*.json'):\n\
      \        dataset = read_file(json_file)\n        if not dataset:\n         \
      \   continue\n        html_content = '\\n        <html>\\n        <head>\\n\
      \            <style>\\n                table {border-collapse: collapse; width:\
      \ 100%; table-layout: fixed;}\\n                th, td {\\n                \
      \    border: 1px solid black;\\n                    padding: 8px;\\n       \
      \             text-align: left;\\n                    white-space: pre-line;\\\
      n                    vertical-align: top;\\n                    word-wrap: break-word;\\\
      n                }\\n            </style>\\n        </head>\\n        <body>\\\
      n            <table>\\n                <thead>\\n                    <tr>\\\
      n        '\n        column_count = len(dataset[0].keys())\n        column_width\
      \ = 100 / column_count\n        for key in dataset[0].keys():\n            html_content\
      \ += f\"<th style='width: {column_width}%;'>{key}</th>\"\n        html_content\
      \ += '\\n                    </tr>\\n                </thead>\\n           \
      \     <tbody>\\n        '\n        for entry in dataset:\n            html_content\
      \ += '<tr>'\n            for key in entry:\n                value = escape(str(entry[key]))\n\
      \                value = preserve_spacing(value)\n                value = value.replace('\\\
      n', '<br/>')\n                html_content += f'<td>{value}</td>'\n        \
      \    html_content += '</tr>'\n        html_content += '\\n                </tbody>\\\
      n            </table>\\n        </body>\\n        </html>\\n        '\n    \
      \    html_file_path = json_file.with_suffix('.html')\n        try:\n       \
      \     with open(html_file_path, 'w', encoding='utf-8') as file:\n          \
      \      file.write(html_content)\n        except Exception:\n            logging.info(f'Failed\
      \ saving: {html_file_path}')"
    function_ast: 'FunctionDef(name=''convert_json_to_html'', args=arguments(posonlyargs=[],
      args=[arg(arg=''directory'', annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Convert
      JSON files within a given directory to HTML format.\n    Args:\n        directory
      (str): The directory where the JSON files are located.\n    Returns:\n        None    \n    '')),
      FunctionDef(name=''preserve_spacing'', args=arguments(posonlyargs=[], args=[arg(arg=''text'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''tab_width'', annotation=Name(id=''int'',
      ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=4)]),
      body=[Expr(value=Constant(value=''Preserve spaces and tabs in the provided text.'')),
      Return(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id=''text'',
      ctx=Load()), attr=''replace'', ctx=Load()), args=[Constant(value='' ''), Constant(value=''&nbsp;'')],
      keywords=[]), attr=''replace'', ctx=Load()), args=[Constant(value=''\t''), BinOp(left=Constant(value=''&nbsp;''),
      op=Mult(), right=Name(id=''tab_width'', ctx=Load()))], keywords=[]))], decorator_list=[],
      returns=Name(id=''str'', ctx=Load())), For(target=Name(id=''json_file'', ctx=Store()),
      iter=Call(func=Attribute(value=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''directory'',
      ctx=Load())], keywords=[]), attr=''rglob'', ctx=Load()), args=[Constant(value=''*.json'')],
      keywords=[]), body=[Assign(targets=[Name(id=''dataset'', ctx=Store())], value=Call(func=Name(id=''read_file'',
      ctx=Load()), args=[Name(id=''json_file'', ctx=Load())], keywords=[])), If(test=UnaryOp(op=Not(),
      operand=Name(id=''dataset'', ctx=Load())), body=[Continue()], orelse=[]), Assign(targets=[Name(id=''html_content'',
      ctx=Store())], value=Constant(value=''\n        <html>\n        <head>\n            <style>\n                table
      {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th,
      td {\n                    border: 1px solid black;\n                    padding:
      8px;\n                    text-align: left;\n                    white-space:
      pre-line;\n                    vertical-align: top;\n                    word-wrap:
      break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        '')),
      Assign(targets=[Name(id=''column_count'', ctx=Store())], value=Call(func=Name(id=''len'',
      ctx=Load()), args=[Call(func=Attribute(value=Subscript(value=Name(id=''dataset'',
      ctx=Load()), slice=Constant(value=0), ctx=Load()), attr=''keys'', ctx=Load()),
      args=[], keywords=[])], keywords=[])), Assign(targets=[Name(id=''column_width'',
      ctx=Store())], value=BinOp(left=Constant(value=100), op=Div(), right=Name(id=''column_count'',
      ctx=Load()))), For(target=Name(id=''key'', ctx=Store()), iter=Call(func=Attribute(value=Subscript(value=Name(id=''dataset'',
      ctx=Load()), slice=Constant(value=0), ctx=Load()), attr=''keys'', ctx=Load()),
      args=[], keywords=[]), body=[AugAssign(target=Name(id=''html_content'', ctx=Store()),
      op=Add(), value=JoinedStr(values=[Constant(value="<th style=''width: "), FormattedValue(value=Name(id=''column_width'',
      ctx=Load()), conversion=-1), Constant(value="%;''>"), FormattedValue(value=Name(id=''key'',
      ctx=Load()), conversion=-1), Constant(value=''</th>'')]))], orelse=[]), AugAssign(target=Name(id=''html_content'',
      ctx=Store()), op=Add(), value=Constant(value=''\n                    </tr>\n                </thead>\n                <tbody>\n        '')),
      For(target=Name(id=''entry'', ctx=Store()), iter=Name(id=''dataset'', ctx=Load()),
      body=[AugAssign(target=Name(id=''html_content'', ctx=Store()), op=Add(), value=Constant(value=''<tr>'')),
      For(target=Name(id=''key'', ctx=Store()), iter=Name(id=''entry'', ctx=Load()),
      body=[Assign(targets=[Name(id=''value'', ctx=Store())], value=Call(func=Name(id=''escape'',
      ctx=Load()), args=[Call(func=Name(id=''str'', ctx=Load()), args=[Subscript(value=Name(id=''entry'',
      ctx=Load()), slice=Name(id=''key'', ctx=Load()), ctx=Load())], keywords=[])],
      keywords=[])), Assign(targets=[Name(id=''value'', ctx=Store())], value=Call(func=Name(id=''preserve_spacing'',
      ctx=Load()), args=[Name(id=''value'', ctx=Load())], keywords=[])), Assign(targets=[Name(id=''value'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''value'', ctx=Load()),
      attr=''replace'', ctx=Load()), args=[Constant(value=''\n''), Constant(value=''<br/>'')],
      keywords=[])), AugAssign(target=Name(id=''html_content'', ctx=Store()), op=Add(),
      value=JoinedStr(values=[Constant(value=''<td>''), FormattedValue(value=Name(id=''value'',
      ctx=Load()), conversion=-1), Constant(value=''</td>'')]))], orelse=[]), AugAssign(target=Name(id=''html_content'',
      ctx=Store()), op=Add(), value=Constant(value=''</tr>''))], orelse=[]), AugAssign(target=Name(id=''html_content'',
      ctx=Store()), op=Add(), value=Constant(value=''\n                </tbody>\n            </table>\n        </body>\n        </html>\n        '')),
      Assign(targets=[Name(id=''html_file_path'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''json_file'',
      ctx=Load()), attr=''with_suffix'', ctx=Load()), args=[Constant(value=''.html'')],
      keywords=[])), Try(body=[With(items=[withitem(context_expr=Call(func=Name(id=''open'',
      ctx=Load()), args=[Name(id=''html_file_path'', ctx=Load()), Constant(value=''w'')],
      keywords=[keyword(arg=''encoding'', value=Constant(value=''utf-8''))]), optional_vars=Name(id=''file'',
      ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id=''file'',
      ctx=Load()), attr=''write'', ctx=Load()), args=[Name(id=''html_content'', ctx=Load())],
      keywords=[]))])], handlers=[ExceptHandler(type=Name(id=''Exception'', ctx=Load()),
      body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'', ctx=Load()),
      attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Failed
      saving: ''), FormattedValue(value=Name(id=''html_file_path'', ctx=Load()), conversion=-1)])],
      keywords=[]))])], orelse=[], finalbody=[])], orelse=[])], decorator_list=[],
      returns=Constant(value=None))'
    function_docstring: "\n    Convert JSON files within a given directory to HTML\
      \ format.\n    Args:\n        directory (str): The directory where the JSON\
      \ files are located.\n    Returns:\n        None    \n    "
    function_inputs:
    - directory
    function_defaults: []
    function_returns:
    - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    function_calls:
    - text.replace(' ', '&nbsp;').replace
    - text.replace
    - Path(directory).rglob
    - Path
    - read_file
    - len
    - dataset[0].keys
    - escape
    - str
    - preserve_spacing
    - value.replace
    - json_file.with_suffix
    - open
    - file.write
    - logging.info
    function_call_inputs:
      text.replace(' ', '&nbsp;').replace:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
      text.replace:
      - ''' '''
      - '''&nbsp;'''
      Path(directory).rglob:
      - '''*.json'''
      Path:
      - directory
      read_file:
      - json_file
      len:
      - dataset[0].keys()
      dataset[0].keys: []
      escape:
      - str(entry[key])
      str:
      - entry[key]
      preserve_spacing:
      - value
      value.replace:
      - '''\n'''
      - '''<br/>'''
      json_file.with_suffix:
      - '''.html'''
      open:
      - html_file_path
      - '''w'''
      file.write:
      - html_content
      logging.info:
      - 'f''Failed saving: {html_file_path}'''
    function_variables:
    - html_content
    - column_count
    - column_width
    - value
    - dataset
    - html_file_path
    function_decorators: []
    function_annotations: []
    function_properties: []
  preserve_spacing:
    function_name: preserve_spacing
    function_code: "def preserve_spacing(text: str, tab_width: int=4) -> str:\n  \
      \  \"\"\"Preserve spaces and tabs in the provided text.\"\"\"\n    return text.replace('\
      \ ', '&nbsp;').replace('\\t', '&nbsp;' * tab_width)"
    function_ast: FunctionDef(name='preserve_spacing', args=arguments(posonlyargs=[],
      args=[arg(arg='text', annotation=Name(id='str', ctx=Load())), arg(arg='tab_width',
      annotation=Name(id='int', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=4)]),
      body=[Expr(value=Constant(value='Preserve spaces and tabs in the provided text.')),
      Return(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id='text',
      ctx=Load()), attr='replace', ctx=Load()), args=[Constant(value=' '), Constant(value='&nbsp;')],
      keywords=[]), attr='replace', ctx=Load()), args=[Constant(value='\t'), BinOp(left=Constant(value='&nbsp;'),
      op=Mult(), right=Name(id='tab_width', ctx=Load()))], keywords=[]))], decorator_list=[],
      returns=Name(id='str', ctx=Load()))
    function_docstring: Preserve spaces and tabs in the provided text.
    function_inputs:
    - text
    - tab_width
    function_defaults:
    - '4'
    function_returns:
    - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    function_calls:
    - text.replace(' ', '&nbsp;').replace
    - text.replace
    function_call_inputs:
      text.replace(' ', '&nbsp;').replace:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
      text.replace:
      - ''' '''
      - '''&nbsp;'''
    function_variables: []
    function_decorators: []
    function_annotations: []
    function_properties: []
  combine_json_files:
    function_name: combine_json_files
    function_code: "def combine_json_files(directory: str) -> Dict[str, List[Dict]]:\n\
      \    \"\"\"\n    Combine all JSON files in the output directory into 'instruct.json',\
      \ and \n    then remove duplicates.\n    Args:\n        directory (str): The\
      \ directory where the output files are located.\n    Returns:\n        A dictionary\
      \ containing the 'instruct_list' datasets.\n    \"\"\"\n\n    def remove_duplicate_dataset_entries(dataset:\
      \ List[Dict], key1: str, key2: str) -> List[Dict]:\n        \"\"\"\n       \
      \ Remove duplicate entries from the provided dataset based on the provided keys.\n\
      \        Args:\n            dataset (List[Dict]): The dataset to remove duplicates\
      \ from.\n            key1 (str): The first key to check for duplicates.\n  \
      \          key2 (str): The second key to check for duplicates.\n        Returns:\n\
      \            A dataset without duplicate entries.\n        \"\"\"\n        seen\
      \ = set()\n        result = []\n        for item in dataset:\n            if\
      \ (item[key1], item[key2]) not in seen:\n                seen.add((item[key1],\
      \ item[key2]))\n                result.append(item)\n        return result\n\
      \    instruct_data = []\n    for file_name in ['instruct.json']:\n        file_path\
      \ = Path(directory) / file_name\n        combined_data = []\n        for json_file\
      \ in Path(directory).rglob(f'*.{file_name}'):\n            json_file_data =\
      \ read_file(json_file)\n            combined_data.extend(json_file_data)\n \
      \           combined_data = remove_duplicate_dataset_entries(combined_data,\
      \ 'instruction', 'output')\n            instruct_data = combined_data.copy()\n\
      \            purpose_data = [item for item in combined_data if item['instruction'].startswith('1)\
      \ DESCRIBE the purpose')]\n            graph_data = [item for item in combined_data\
      \ if item['instruction'].startswith('Call code graph')]\n            code_output\
      \ = []\n            graph_output = []\n            for item in purpose_data:\n\
      \                instruction = 'Define a Python code file that is described\
      \ as follows:\\n' + item['output']\n                code_output.append({'instruction':\
      \ instruction, 'output': item['input']})\n            for item in graph_data:\n\
      \                instruction = 'Define the call code graph for this Python file:\\\
      n' + item['input']\n                graph_output.append({'instruction': instruction,\
      \ 'output': item['output']})\n            code_graph_output = code_output +\
      \ graph_output\n            write_file(code_graph_output, Path(directory) /\
      \ 'training.json')\n        write_file(combined_data, file_path)\n    convert_json_to_html(directory)\n\
      \    return {'instruct_list': instruct_data}"
    function_ast: 'FunctionDef(name=''combine_json_files'', args=arguments(posonlyargs=[],
      args=[arg(arg=''directory'', annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value="\n    Combine
      all JSON files in the output directory into ''instruct.json'', and \n    then
      remove duplicates.\n    Args:\n        directory (str): The directory where
      the output files are located.\n    Returns:\n        A dictionary containing
      the ''instruct_list'' datasets.\n    ")), FunctionDef(name=''remove_duplicate_dataset_entries'',
      args=arguments(posonlyargs=[], args=[arg(arg=''dataset'', annotation=Subscript(value=Name(id=''List'',
      ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())), arg(arg=''key1'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''key2'', annotation=Name(id=''str'',
      ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n        Remove
      duplicate entries from the provided dataset based on the provided keys.\n        Args:\n            dataset
      (List[Dict]): The dataset to remove duplicates from.\n            key1 (str):
      The first key to check for duplicates.\n            key2 (str): The second key
      to check for duplicates.\n        Returns:\n            A dataset without duplicate
      entries.\n        '')), Assign(targets=[Name(id=''seen'', ctx=Store())], value=Call(func=Name(id=''set'',
      ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id=''result'', ctx=Store())],
      value=List(elts=[], ctx=Load())), For(target=Name(id=''item'', ctx=Store()),
      iter=Name(id=''dataset'', ctx=Load()), body=[If(test=Compare(left=Tuple(elts=[Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key1'', ctx=Load()), ctx=Load()), Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key2'', ctx=Load()), ctx=Load())], ctx=Load()),
      ops=[NotIn()], comparators=[Name(id=''seen'', ctx=Load())]), body=[Expr(value=Call(func=Attribute(value=Name(id=''seen'',
      ctx=Load()), attr=''add'', ctx=Load()), args=[Tuple(elts=[Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key1'', ctx=Load()), ctx=Load()), Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key2'', ctx=Load()), ctx=Load())], ctx=Load())],
      keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''result'', ctx=Load()),
      attr=''append'', ctx=Load()), args=[Name(id=''item'', ctx=Load())], keywords=[]))],
      orelse=[])], orelse=[]), Return(value=Name(id=''result'', ctx=Load()))], decorator_list=[],
      returns=Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
      ctx=Load()), ctx=Load())), Assign(targets=[Name(id=''instruct_data'', ctx=Store())],
      value=List(elts=[], ctx=Load())), For(target=Name(id=''file_name'', ctx=Store()),
      iter=List(elts=[Constant(value=''instruct.json'')], ctx=Load()), body=[Assign(targets=[Name(id=''file_path'',
      ctx=Store())], value=BinOp(left=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''directory'',
      ctx=Load())], keywords=[]), op=Div(), right=Name(id=''file_name'', ctx=Load()))),
      Assign(targets=[Name(id=''combined_data'', ctx=Store())], value=List(elts=[],
      ctx=Load())), For(target=Name(id=''json_file'', ctx=Store()), iter=Call(func=Attribute(value=Call(func=Name(id=''Path'',
      ctx=Load()), args=[Name(id=''directory'', ctx=Load())], keywords=[]), attr=''rglob'',
      ctx=Load()), args=[JoinedStr(values=[Constant(value=''*.''), FormattedValue(value=Name(id=''file_name'',
      ctx=Load()), conversion=-1)])], keywords=[]), body=[Assign(targets=[Name(id=''json_file_data'',
      ctx=Store())], value=Call(func=Name(id=''read_file'', ctx=Load()), args=[Name(id=''json_file'',
      ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''combined_data'',
      ctx=Load()), attr=''extend'', ctx=Load()), args=[Name(id=''json_file_data'',
      ctx=Load())], keywords=[])), Assign(targets=[Name(id=''combined_data'', ctx=Store())],
      value=Call(func=Name(id=''remove_duplicate_dataset_entries'', ctx=Load()), args=[Name(id=''combined_data'',
      ctx=Load()), Constant(value=''instruction''), Constant(value=''output'')], keywords=[])),
      Assign(targets=[Name(id=''instruct_data'', ctx=Store())], value=Call(func=Attribute(value=Name(id=''combined_data'',
      ctx=Load()), attr=''copy'', ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id=''purpose_data'',
      ctx=Store())], value=ListComp(elt=Name(id=''item'', ctx=Load()), generators=[comprehension(target=Name(id=''item'',
      ctx=Store()), iter=Name(id=''combined_data'', ctx=Load()), ifs=[Call(func=Attribute(value=Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Constant(value=''instruction''), ctx=Load()), attr=''startswith'',
      ctx=Load()), args=[Constant(value=''1) DESCRIBE the purpose'')], keywords=[])],
      is_async=0)])), Assign(targets=[Name(id=''graph_data'', ctx=Store())], value=ListComp(elt=Name(id=''item'',
      ctx=Load()), generators=[comprehension(target=Name(id=''item'', ctx=Store()),
      iter=Name(id=''combined_data'', ctx=Load()), ifs=[Call(func=Attribute(value=Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Constant(value=''instruction''), ctx=Load()), attr=''startswith'',
      ctx=Load()), args=[Constant(value=''Call code graph'')], keywords=[])], is_async=0)])),
      Assign(targets=[Name(id=''code_output'', ctx=Store())], value=List(elts=[],
      ctx=Load())), Assign(targets=[Name(id=''graph_output'', ctx=Store())], value=List(elts=[],
      ctx=Load())), For(target=Name(id=''item'', ctx=Store()), iter=Name(id=''purpose_data'',
      ctx=Load()), body=[Assign(targets=[Name(id=''instruction'', ctx=Store())], value=BinOp(left=Constant(value=''Define
      a Python code file that is described as follows:\n''), op=Add(), right=Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Constant(value=''output''), ctx=Load()))), Expr(value=Call(func=Attribute(value=Name(id=''code_output'',
      ctx=Load()), attr=''append'', ctx=Load()), args=[Dict(keys=[Constant(value=''instruction''),
      Constant(value=''output'')], values=[Name(id=''instruction'', ctx=Load()), Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Constant(value=''input''), ctx=Load())])], keywords=[]))],
      orelse=[]), For(target=Name(id=''item'', ctx=Store()), iter=Name(id=''graph_data'',
      ctx=Load()), body=[Assign(targets=[Name(id=''instruction'', ctx=Store())], value=BinOp(left=Constant(value=''Define
      the call code graph for this Python file:\n''), op=Add(), right=Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Constant(value=''input''), ctx=Load()))), Expr(value=Call(func=Attribute(value=Name(id=''graph_output'',
      ctx=Load()), attr=''append'', ctx=Load()), args=[Dict(keys=[Constant(value=''instruction''),
      Constant(value=''output'')], values=[Name(id=''instruction'', ctx=Load()), Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Constant(value=''output''), ctx=Load())])], keywords=[]))],
      orelse=[]), Assign(targets=[Name(id=''code_graph_output'', ctx=Store())], value=BinOp(left=Name(id=''code_output'',
      ctx=Load()), op=Add(), right=Name(id=''graph_output'', ctx=Load()))), Expr(value=Call(func=Name(id=''write_file'',
      ctx=Load()), args=[Name(id=''code_graph_output'', ctx=Load()), BinOp(left=Call(func=Name(id=''Path'',
      ctx=Load()), args=[Name(id=''directory'', ctx=Load())], keywords=[]), op=Div(),
      right=Constant(value=''training.json''))], keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''write_file'',
      ctx=Load()), args=[Name(id=''combined_data'', ctx=Load()), Name(id=''file_path'',
      ctx=Load())], keywords=[]))], orelse=[]), Expr(value=Call(func=Name(id=''convert_json_to_html'',
      ctx=Load()), args=[Name(id=''directory'', ctx=Load())], keywords=[])), Return(value=Dict(keys=[Constant(value=''instruct_list'')],
      values=[Name(id=''instruct_data'', ctx=Load())]))], decorator_list=[], returns=Subscript(value=Name(id=''Dict'',
      ctx=Load()), slice=Tuple(elts=[Name(id=''str'', ctx=Load()), Subscript(value=Name(id=''List'',
      ctx=Load()), slice=Name(id=''Dict'', ctx=Load()), ctx=Load())], ctx=Load()),
      ctx=Load()))'
    function_docstring: "\n    Combine all JSON files in the output directory into\
      \ 'instruct.json', and \n    then remove duplicates.\n    Args:\n        directory\
      \ (str): The directory where the output files are located.\n    Returns:\n \
      \       A dictionary containing the 'instruct_list' datasets.\n    "
    function_inputs:
    - directory
    function_defaults: []
    function_returns:
    - '{''instruct_list'': instruct_data}'
    - result
    function_calls:
    - set
    - seen.add
    - result.append
    - Path
    - Path(directory).rglob
    - read_file
    - combined_data.extend
    - remove_duplicate_dataset_entries
    - combined_data.copy
    - item['instruction'].startswith
    - code_output.append
    - graph_output.append
    - write_file
    - convert_json_to_html
    function_call_inputs:
      set: []
      seen.add:
      - (item[key1], item[key2])
      result.append:
      - item
      Path:
      - directory
      Path(directory).rglob:
      - f'*.{file_name}'
      read_file:
      - json_file
      combined_data.extend:
      - json_file_data
      remove_duplicate_dataset_entries:
      - combined_data
      - '''instruction'''
      - '''output'''
      combined_data.copy: []
      item['instruction'].startswith:
      - '''Call code graph'''
      code_output.append:
      - '{''instruction'': instruction, ''output'': item[''input'']}'
      graph_output.append:
      - '{''instruction'': instruction, ''output'': item[''output'']}'
      write_file:
      - combined_data
      - file_path
      convert_json_to_html:
      - directory
    function_variables:
    - instruction
    - code_graph_output
    - result
    - graph_data
    - graph_output
    - purpose_data
    - seen
    - json_file_data
    - file_path
    - instruct_data
    - combined_data
    - code_output
    function_decorators: []
    function_annotations: []
    function_properties: []
  remove_duplicate_dataset_entries:
    function_name: remove_duplicate_dataset_entries
    function_code: "def remove_duplicate_dataset_entries(dataset: List[Dict], key1:\
      \ str, key2: str) -> List[Dict]:\n    \"\"\"\n        Remove duplicate entries\
      \ from the provided dataset based on the provided keys.\n        Args:\n   \
      \         dataset (List[Dict]): The dataset to remove duplicates from.\n   \
      \         key1 (str): The first key to check for duplicates.\n            key2\
      \ (str): The second key to check for duplicates.\n        Returns:\n       \
      \     A dataset without duplicate entries.\n        \"\"\"\n    seen = set()\n\
      \    result = []\n    for item in dataset:\n        if (item[key1], item[key2])\
      \ not in seen:\n            seen.add((item[key1], item[key2]))\n           \
      \ result.append(item)\n    return result"
    function_ast: 'FunctionDef(name=''remove_duplicate_dataset_entries'', args=arguments(posonlyargs=[],
      args=[arg(arg=''dataset'', annotation=Subscript(value=Name(id=''List'', ctx=Load()),
      slice=Name(id=''Dict'', ctx=Load()), ctx=Load())), arg(arg=''key1'', annotation=Name(id=''str'',
      ctx=Load())), arg(arg=''key2'', annotation=Name(id=''str'', ctx=Load()))], kwonlyargs=[],
      kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n        Remove
      duplicate entries from the provided dataset based on the provided keys.\n        Args:\n            dataset
      (List[Dict]): The dataset to remove duplicates from.\n            key1 (str):
      The first key to check for duplicates.\n            key2 (str): The second key
      to check for duplicates.\n        Returns:\n            A dataset without duplicate
      entries.\n        '')), Assign(targets=[Name(id=''seen'', ctx=Store())], value=Call(func=Name(id=''set'',
      ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id=''result'', ctx=Store())],
      value=List(elts=[], ctx=Load())), For(target=Name(id=''item'', ctx=Store()),
      iter=Name(id=''dataset'', ctx=Load()), body=[If(test=Compare(left=Tuple(elts=[Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key1'', ctx=Load()), ctx=Load()), Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key2'', ctx=Load()), ctx=Load())], ctx=Load()),
      ops=[NotIn()], comparators=[Name(id=''seen'', ctx=Load())]), body=[Expr(value=Call(func=Attribute(value=Name(id=''seen'',
      ctx=Load()), attr=''add'', ctx=Load()), args=[Tuple(elts=[Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key1'', ctx=Load()), ctx=Load()), Subscript(value=Name(id=''item'',
      ctx=Load()), slice=Name(id=''key2'', ctx=Load()), ctx=Load())], ctx=Load())],
      keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''result'', ctx=Load()),
      attr=''append'', ctx=Load()), args=[Name(id=''item'', ctx=Load())], keywords=[]))],
      orelse=[])], orelse=[]), Return(value=Name(id=''result'', ctx=Load()))], decorator_list=[],
      returns=Subscript(value=Name(id=''List'', ctx=Load()), slice=Name(id=''Dict'',
      ctx=Load()), ctx=Load()))'
    function_docstring: "\n        Remove duplicate entries from the provided dataset\
      \ based on the provided keys.\n        Args:\n            dataset (List[Dict]):\
      \ The dataset to remove duplicates from.\n            key1 (str): The first\
      \ key to check for duplicates.\n            key2 (str): The second key to check\
      \ for duplicates.\n        Returns:\n            A dataset without duplicate\
      \ entries.\n        "
    function_inputs:
    - dataset
    - key1
    - key2
    function_defaults: []
    function_returns:
    - result
    function_calls:
    - set
    - seen.add
    - result.append
    function_call_inputs:
      set: []
      seen.add:
      - (item[key1], item[key2])
      result.append:
      - item
    function_variables:
    - seen
    - result
    function_decorators: []
    function_annotations: []
    function_properties: []
  create_code_graph:
    function_name: create_code_graph
    function_code: "def create_code_graph(file_details: Dict, base_name: str, output_subdir:\
      \ Path) -> None:\n    \"\"\"\n    Generate graphs from the file_details and\
      \ save them as PNG images.\n    Args:\n        file_details (dict): The details\
      \ extracted from the Python file.\n        base_name (str): The base name of\
      \ the output files.\n        output_subdir (Path): The subdirectory where the\
      \ output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    graph_type\
      \ = 'entire_code_graph'\n    output_file = output_subdir / f'{base_name}.{graph_type}.png'\n\
      \    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n\
      \    for edge in file_details['file_info'][graph_type]['edges']:\n        source,\
      \ target = (edge['source'], edge['target'])\n        if source in G.nodes and\
      \ target in G.nodes:\n            G.add_edge(source, target, **{k: v for k,\
      \ v in edge.items() if k in ['target_inputs', 'target_returns']})\n    plt.figure(figsize=(20,\
      \ 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True,\
      \ font_weight='bold', font_size=8, node_shape='s', node_size=500, width=1, arrowsize=12)\n\
      \    edge_labels = {}\n    for edge in G.edges(data=True):\n        label =\
      \ []\n        if 'target_inputs' in edge[2] and edge[2]['target_inputs']:\n\
      \            label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\"\
      )\n        if 'target_returns' in edge[2] and edge[2]['target_returns']:\n \
      \           label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\"\
      )\n        edge_labels[edge[0], edge[1]] = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G,\
      \ pos, edge_labels=edge_labels, font_size=6)\n    plt.savefig(output_file)\n\
      \    plt.close()"
    function_ast: 'FunctionDef(name=''create_code_graph'', args=arguments(posonlyargs=[],
      args=[arg(arg=''file_details'', annotation=Name(id=''Dict'', ctx=Load())), arg(arg=''base_name'',
      annotation=Name(id=''str'', ctx=Load())), arg(arg=''output_subdir'', annotation=Name(id=''Path'',
      ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Generate
      graphs from the file_details and save them as PNG images.\n    Args:\n        file_details
      (dict): The details extracted from the Python file.\n        base_name (str):
      The base name of the output files.\n        output_subdir (Path): The subdirectory
      where the output files will be saved.\n    Returns:\n        None\n    '')),
      Assign(targets=[Name(id=''graph_type'', ctx=Store())], value=Constant(value=''entire_code_graph'')),
      Assign(targets=[Name(id=''output_file'', ctx=Store())], value=BinOp(left=Name(id=''output_subdir'',
      ctx=Load()), op=Div(), right=JoinedStr(values=[FormattedValue(value=Name(id=''base_name'',
      ctx=Load()), conversion=-1), Constant(value=''.''), FormattedValue(value=Name(id=''graph_type'',
      ctx=Load()), conversion=-1), Constant(value=''.png'')]))), Assign(targets=[Name(id=''G'',
      ctx=Store())], value=Call(func=Attribute(value=Name(id=''nx'', ctx=Load()),
      attr=''DiGraph'', ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''G'',
      ctx=Load()), attr=''add_nodes_from'', ctx=Load()), args=[Subscript(value=Subscript(value=Subscript(value=Name(id=''file_details'',
      ctx=Load()), slice=Constant(value=''file_info''), ctx=Load()), slice=Name(id=''graph_type'',
      ctx=Load()), ctx=Load()), slice=Constant(value=''nodes''), ctx=Load())], keywords=[])),
      For(target=Name(id=''edge'', ctx=Store()), iter=Subscript(value=Subscript(value=Subscript(value=Name(id=''file_details'',
      ctx=Load()), slice=Constant(value=''file_info''), ctx=Load()), slice=Name(id=''graph_type'',
      ctx=Load()), ctx=Load()), slice=Constant(value=''edges''), ctx=Load()), body=[Assign(targets=[Tuple(elts=[Name(id=''source'',
      ctx=Store()), Name(id=''target'', ctx=Store())], ctx=Store())], value=Tuple(elts=[Subscript(value=Name(id=''edge'',
      ctx=Load()), slice=Constant(value=''source''), ctx=Load()), Subscript(value=Name(id=''edge'',
      ctx=Load()), slice=Constant(value=''target''), ctx=Load())], ctx=Load())), If(test=BoolOp(op=And(),
      values=[Compare(left=Name(id=''source'', ctx=Load()), ops=[In()], comparators=[Attribute(value=Name(id=''G'',
      ctx=Load()), attr=''nodes'', ctx=Load())]), Compare(left=Name(id=''target'',
      ctx=Load()), ops=[In()], comparators=[Attribute(value=Name(id=''G'', ctx=Load()),
      attr=''nodes'', ctx=Load())])]), body=[Expr(value=Call(func=Attribute(value=Name(id=''G'',
      ctx=Load()), attr=''add_edge'', ctx=Load()), args=[Name(id=''source'', ctx=Load()),
      Name(id=''target'', ctx=Load())], keywords=[keyword(value=DictComp(key=Name(id=''k'',
      ctx=Load()), value=Name(id=''v'', ctx=Load()), generators=[comprehension(target=Tuple(elts=[Name(id=''k'',
      ctx=Store()), Name(id=''v'', ctx=Store())], ctx=Store()), iter=Call(func=Attribute(value=Name(id=''edge'',
      ctx=Load()), attr=''items'', ctx=Load()), args=[], keywords=[]), ifs=[Compare(left=Name(id=''k'',
      ctx=Load()), ops=[In()], comparators=[List(elts=[Constant(value=''target_inputs''),
      Constant(value=''target_returns'')], ctx=Load())])], is_async=0)]))]))], orelse=[])],
      orelse=[]), Expr(value=Call(func=Attribute(value=Name(id=''plt'', ctx=Load()),
      attr=''figure'', ctx=Load()), args=[], keywords=[keyword(arg=''figsize'', value=Tuple(elts=[Constant(value=20),
      Constant(value=20)], ctx=Load()))])), Assign(targets=[Name(id=''pos'', ctx=Store())],
      value=Call(func=Attribute(value=Name(id=''nx'', ctx=Load()), attr=''spring_layout'',
      ctx=Load()), args=[Name(id=''G'', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''nx'',
      ctx=Load()), attr=''draw'', ctx=Load()), args=[Name(id=''G'', ctx=Load()), Name(id=''pos'',
      ctx=Load())], keywords=[keyword(arg=''with_labels'', value=Constant(value=True)),
      keyword(arg=''font_weight'', value=Constant(value=''bold'')), keyword(arg=''font_size'',
      value=Constant(value=8)), keyword(arg=''node_shape'', value=Constant(value=''s'')),
      keyword(arg=''node_size'', value=Constant(value=500)), keyword(arg=''width'',
      value=Constant(value=1)), keyword(arg=''arrowsize'', value=Constant(value=12))])),
      Assign(targets=[Name(id=''edge_labels'', ctx=Store())], value=Dict(keys=[],
      values=[])), For(target=Name(id=''edge'', ctx=Store()), iter=Call(func=Attribute(value=Name(id=''G'',
      ctx=Load()), attr=''edges'', ctx=Load()), args=[], keywords=[keyword(arg=''data'',
      value=Constant(value=True))]), body=[Assign(targets=[Name(id=''label'', ctx=Store())],
      value=List(elts=[], ctx=Load())), If(test=BoolOp(op=And(), values=[Compare(left=Constant(value=''target_inputs''),
      ops=[In()], comparators=[Subscript(value=Name(id=''edge'', ctx=Load()), slice=Constant(value=2),
      ctx=Load())]), Subscript(value=Subscript(value=Name(id=''edge'', ctx=Load()),
      slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_inputs''),
      ctx=Load())]), body=[Expr(value=Call(func=Attribute(value=Name(id=''label'',
      ctx=Load()), attr=''append'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Inputs:
      ''), FormattedValue(value=Call(func=Attribute(value=Constant(value='', ''),
      attr=''join'', ctx=Load()), args=[Subscript(value=Subscript(value=Name(id=''edge'',
      ctx=Load()), slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_inputs''),
      ctx=Load())], keywords=[]), conversion=-1)])], keywords=[]))], orelse=[]), If(test=BoolOp(op=And(),
      values=[Compare(left=Constant(value=''target_returns''), ops=[In()], comparators=[Subscript(value=Name(id=''edge'',
      ctx=Load()), slice=Constant(value=2), ctx=Load())]), Subscript(value=Subscript(value=Name(id=''edge'',
      ctx=Load()), slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_returns''),
      ctx=Load())]), body=[Expr(value=Call(func=Attribute(value=Name(id=''label'',
      ctx=Load()), attr=''append'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''\nReturns:
      ''), FormattedValue(value=Call(func=Attribute(value=Constant(value='', ''),
      attr=''join'', ctx=Load()), args=[Subscript(value=Subscript(value=Name(id=''edge'',
      ctx=Load()), slice=Constant(value=2), ctx=Load()), slice=Constant(value=''target_returns''),
      ctx=Load())], keywords=[]), conversion=-1)])], keywords=[]))], orelse=[]), Assign(targets=[Subscript(value=Name(id=''edge_labels'',
      ctx=Load()), slice=Tuple(elts=[Subscript(value=Name(id=''edge'', ctx=Load()),
      slice=Constant(value=0), ctx=Load()), Subscript(value=Name(id=''edge'', ctx=Load()),
      slice=Constant(value=1), ctx=Load())], ctx=Load()), ctx=Store())], value=Call(func=Attribute(value=Constant(value=''\n''),
      attr=''join'', ctx=Load()), args=[Name(id=''label'', ctx=Load())], keywords=[]))],
      orelse=[]), Expr(value=Call(func=Attribute(value=Name(id=''nx'', ctx=Load()),
      attr=''draw_networkx_edge_labels'', ctx=Load()), args=[Name(id=''G'', ctx=Load()),
      Name(id=''pos'', ctx=Load())], keywords=[keyword(arg=''edge_labels'', value=Name(id=''edge_labels'',
      ctx=Load())), keyword(arg=''font_size'', value=Constant(value=6))])), Expr(value=Call(func=Attribute(value=Name(id=''plt'',
      ctx=Load()), attr=''savefig'', ctx=Load()), args=[Name(id=''output_file'', ctx=Load())],
      keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=''plt'', ctx=Load()),
      attr=''close'', ctx=Load()), args=[], keywords=[]))], decorator_list=[], returns=Constant(value=None))'
    function_docstring: "\n    Generate graphs from the file_details and save them\
      \ as PNG images.\n    Args:\n        file_details (dict): The details extracted\
      \ from the Python file.\n        base_name (str): The base name of the output\
      \ files.\n        output_subdir (Path): The subdirectory where the output files\
      \ will be saved.\n    Returns:\n        None\n    "
    function_inputs:
    - file_details
    - base_name
    - output_subdir
    function_defaults: []
    function_returns: []
    function_calls:
    - nx.DiGraph
    - G.add_nodes_from
    - G.add_edge
    - edge.items
    - plt.figure
    - nx.spring_layout
    - nx.draw
    - G.edges
    - label.append
    - ''', ''.join'
    - '''\n''.join'
    - nx.draw_networkx_edge_labels
    - plt.savefig
    - plt.close
    function_call_inputs:
      nx.DiGraph: []
      G.add_nodes_from:
      - file_details['file_info'][graph_type]['nodes']
      G.add_edge:
      - source
      - target
      edge.items: []
      plt.figure: []
      nx.spring_layout:
      - G
      nx.draw:
      - G
      - pos
      G.edges: []
      label.append:
      - 'f"\nReturns: {'', ''.join(edge[2][''target_returns''])}"'
      ''', ''.join':
      - edge[2]['target_returns']
      '''\n''.join':
      - label
      nx.draw_networkx_edge_labels:
      - G
      - pos
      plt.savefig:
      - output_file
      plt.close: []
    function_variables:
    - G
    - graph_type
    - pos
    - edge_labels
    - label
    - output_file
    function_decorators: []
    function_annotations: []
    function_properties: []
  save_python_data:
    function_name: save_python_data
    function_code: "def save_python_data(file_details: dict, instruct_list: list,\
      \ relative_path: Path, output_dir: str) -> None:\n    \"\"\"\n    Save Python\
      \ file details as a YAML file, the instruction data as a JSON file, and code\
      \ graphs.\n    Args:\n        file_details (dict): The details extracted from\
      \ the Python file.\n        instruct_list (list): The instruction data extracted\
      \ from the Python file.\n        relative_path (Path): The relative path to\
      \ the Python file.\n        output_dir (str): The directory where the output\
      \ files will be saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir\
      \ = Path(output_dir) / relative_path.parts[0]\n    output_subdir.mkdir(parents=True,\
      \ exist_ok=True)\n    base_name = '.'.join((part for part in relative_path.parts))\n\
      \    file_names = [f'{base_name}.instruct.json', f'{base_name}.details.yaml']\n\
      \    contents = [instruct_list, file_details]\n    for file_name, content in\
      \ zip(file_names, contents):\n        write_file(content, output_subdir / file_name)\n\
      \    try:\n        create_code_graph(file_details, base_name, output_subdir)\n\
      \    except Exception as e:\n        logging.info(f'Error creating graph for\
      \ {base_name}: {e}')"
    function_ast: 'FunctionDef(name=''save_python_data'', args=arguments(posonlyargs=[],
      args=[arg(arg=''file_details'', annotation=Name(id=''dict'', ctx=Load())), arg(arg=''instruct_list'',
      annotation=Name(id=''list'', ctx=Load())), arg(arg=''relative_path'', annotation=Name(id=''Path'',
      ctx=Load())), arg(arg=''output_dir'', annotation=Name(id=''str'', ctx=Load()))],
      kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=''\n    Save
      Python file details as a YAML file, the instruction data as a JSON file, and
      code graphs.\n    Args:\n        file_details (dict): The details extracted
      from the Python file.\n        instruct_list (list): The instruction data extracted
      from the Python file.\n        relative_path (Path): The relative path to the
      Python file.\n        output_dir (str): The directory where the output files
      will be saved.\n    Returns:\n        None\n    '')), Assign(targets=[Name(id=''output_subdir'',
      ctx=Store())], value=BinOp(left=Call(func=Name(id=''Path'', ctx=Load()), args=[Name(id=''output_dir'',
      ctx=Load())], keywords=[]), op=Div(), right=Subscript(value=Attribute(value=Name(id=''relative_path'',
      ctx=Load()), attr=''parts'', ctx=Load()), slice=Constant(value=0), ctx=Load()))),
      Expr(value=Call(func=Attribute(value=Name(id=''output_subdir'', ctx=Load()),
      attr=''mkdir'', ctx=Load()), args=[], keywords=[keyword(arg=''parents'', value=Constant(value=True)),
      keyword(arg=''exist_ok'', value=Constant(value=True))])), Assign(targets=[Name(id=''base_name'',
      ctx=Store())], value=Call(func=Attribute(value=Constant(value=''.''), attr=''join'',
      ctx=Load()), args=[GeneratorExp(elt=Name(id=''part'', ctx=Load()), generators=[comprehension(target=Name(id=''part'',
      ctx=Store()), iter=Attribute(value=Name(id=''relative_path'', ctx=Load()), attr=''parts'',
      ctx=Load()), ifs=[], is_async=0)])], keywords=[])), Assign(targets=[Name(id=''file_names'',
      ctx=Store())], value=List(elts=[JoinedStr(values=[FormattedValue(value=Name(id=''base_name'',
      ctx=Load()), conversion=-1), Constant(value=''.instruct.json'')]), JoinedStr(values=[FormattedValue(value=Name(id=''base_name'',
      ctx=Load()), conversion=-1), Constant(value=''.details.yaml'')])], ctx=Load())),
      Assign(targets=[Name(id=''contents'', ctx=Store())], value=List(elts=[Name(id=''instruct_list'',
      ctx=Load()), Name(id=''file_details'', ctx=Load())], ctx=Load())), For(target=Tuple(elts=[Name(id=''file_name'',
      ctx=Store()), Name(id=''content'', ctx=Store())], ctx=Store()), iter=Call(func=Name(id=''zip'',
      ctx=Load()), args=[Name(id=''file_names'', ctx=Load()), Name(id=''contents'',
      ctx=Load())], keywords=[]), body=[Expr(value=Call(func=Name(id=''write_file'',
      ctx=Load()), args=[Name(id=''content'', ctx=Load()), BinOp(left=Name(id=''output_subdir'',
      ctx=Load()), op=Div(), right=Name(id=''file_name'', ctx=Load()))], keywords=[]))],
      orelse=[]), Try(body=[Expr(value=Call(func=Name(id=''create_code_graph'', ctx=Load()),
      args=[Name(id=''file_details'', ctx=Load()), Name(id=''base_name'', ctx=Load()),
      Name(id=''output_subdir'', ctx=Load())], keywords=[]))], handlers=[ExceptHandler(type=Name(id=''Exception'',
      ctx=Load()), name=''e'', body=[Expr(value=Call(func=Attribute(value=Name(id=''logging'',
      ctx=Load()), attr=''info'', ctx=Load()), args=[JoinedStr(values=[Constant(value=''Error
      creating graph for ''), FormattedValue(value=Name(id=''base_name'', ctx=Load()),
      conversion=-1), Constant(value='': ''), FormattedValue(value=Name(id=''e'',
      ctx=Load()), conversion=-1)])], keywords=[]))])], orelse=[], finalbody=[])],
      decorator_list=[], returns=Constant(value=None))'
    function_docstring: "\n    Save Python file details as a YAML file, the instruction\
      \ data as a JSON file, and code graphs.\n    Args:\n        file_details (dict):\
      \ The details extracted from the Python file.\n        instruct_list (list):\
      \ The instruction data extracted from the Python file.\n        relative_path\
      \ (Path): The relative path to the Python file.\n        output_dir (str): The\
      \ directory where the output files will be saved.\n    Returns:\n        None\n\
      \    "
    function_inputs:
    - file_details
    - instruct_list
    - relative_path
    - output_dir
    function_defaults: []
    function_returns: []
    function_calls:
    - Path
    - output_subdir.mkdir
    - '''.''.join'
    - zip
    - write_file
    - create_code_graph
    - logging.info
    function_call_inputs:
      Path:
      - output_dir
      output_subdir.mkdir: []
      '''.''.join':
      - (part for part in relative_path.parts)
      zip:
      - file_names
      - contents
      write_file:
      - content
      - output_subdir / file_name
      create_code_graph:
      - file_details
      - base_name
      - output_subdir
      logging.info:
      - 'f''Error creating graph for {base_name}: {e}'''
    function_variables:
    - output_subdir
    - file_names
    - contents
    - base_name
    function_decorators: []
    function_annotations: []
    function_properties: []
classes: {}
